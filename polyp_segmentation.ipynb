{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "link github untuk AOL https://github.com/huyquoctrinh/MetaPolyp-CBMS2023.git"
      ],
      "metadata": {
        "id": "I_yS6VXvxX0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvDU-awvOF5-",
        "outputId": "d4029f7e-1565-4dc2-84e1-2b24a1a8d142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MetaPolyp-CBMS2023'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 99 (delta 48), reused 18 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (99/99), 2.24 MiB | 6.30 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huyquoctrinh/MetaPolyp-CBMS2023.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U cython\n",
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmWIeM9BjCBv",
        "outputId": "a4f650d0-12e4-4001-e363-78731ddd370a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.6)\n",
            "Collecting git+https://github.com/lucasb-eyer/pydensecrf.git\n",
            "  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-req-build-fv_08chr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lucasb-eyer/pydensecrf.git /tmp/pip-req-build-fv_08chr\n",
            "  Resolved https://github.com/lucasb-eyer/pydensecrf.git to commit dd070546eda51e21ab772ee6f14807c7f5b1548b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pydensecrf\n",
            "  Building wheel for pydensecrf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydensecrf: filename=pydensecrf-1.0-cp310-cp310-linux_x86_64.whl size=3405481 sha256=32e6a81079de44f83782675f2d567e0a8dcfd8d32081b422a9d3a3ed3b9d5193\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t7zyalua/wheels/01/5b/61/87443ed3bf03dd2940375cf2f8b6fba88efece935465e490b0\n",
            "Successfully built pydensecrf\n",
            "Installing collected packages: pydensecrf\n",
            "Successfully installed pydensecrf-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq_GKgT8OTlF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "194dac59-f505-4d0e-e260-8844ba446e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r /content/MetaPolyp-CBMS2023/requirements.txt (line 1)) (4.8.0.76)\n",
            "Collecting tensorflow==2.11.0 (from -r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m738.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r /content/MetaPolyp-CBMS2023/requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/MetaPolyp-CBMS2023/requirements.txt (line 4)) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r /content/MetaPolyp-CBMS2023/requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/MetaPolyp-CBMS2023/requirements.txt (line 6)) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/MetaPolyp-CBMS2023/requirements.txt (line 7)) (3.7.1)\n",
            "Collecting keras-cv-attention-models==1.3.9 (from -r /content/MetaPolyp-CBMS2023/requirements.txt (line 8))\n",
            "  Downloading keras_cv_attention_models-1.3.9-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.5/572.5 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (1.59.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (3.9.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (23.2)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (1.16.0)\n",
            "Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (0.34.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (4.9.3)\n",
            "Collecting tensorflow-addons (from keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8))\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 5)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 7)) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 7)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (2.31.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2))\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (3.0.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8))\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (0.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (2.3)\n",
            "INFO: pip is looking at multiple versions of tensorflow-datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-datasets (from keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8))\n",
            "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_datasets-4.9.1-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (0.10.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (3.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8)) (1.61.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets->keras-cv-attention-models==1.3.9->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 8))\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
            "  Downloading tensorflow_metadata-1.13.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r /content/MetaPolyp-CBMS2023/requirements.txt (line 2)) (3.2.2)\n",
            "Installing collected packages: tensorboard-plugin-wit, typeguard, tensorflow-estimator, tensorboard-data-server, protobuf, keras, gast, tensorflow-addons, tensorflow-metadata, google-auth-oauthlib, tensorflow-datasets, tensorboard, tensorflow, keras-cv-attention-models\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.14.0\n",
            "    Uninstalling tensorflow-metadata-1.14.0:\n",
            "      Successfully uninstalled tensorflow-metadata-1.14.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.9.3\n",
            "    Uninstalling tensorflow-datasets-4.9.3:\n",
            "      Successfully uninstalled tensorflow-datasets-4.9.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.11.0 keras-cv-attention-models-1.3.9 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-addons-0.23.0 tensorflow-datasets-4.9.0 tensorflow-estimator-2.11.0 tensorflow-metadata-1.13.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r /content/MetaPolyp-CBMS2023/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYng9TjMIF1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ef88d0-9e14-4f66-9085-5c9fa0fe8a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "import numpy as np\n",
        "\n",
        "from keras.utils import get_custom_objects\n",
        "import os\n",
        "# from supervision.dataloader import build_augmenter, build_dataset, build_decoder\n",
        "import os\n",
        "import tensorflow_addons as tfa\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKuNDcFVISeI"
      },
      "source": [
        "#Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW0vMr1RIZLY"
      },
      "outputs": [],
      "source": [
        "def dice_coeff(y_true, y_pred):\n",
        "\n",
        "    _epsilon = 10 ** -7\n",
        "    intersections = tf.reduce_sum(y_true * y_pred)\n",
        "    unions = tf.reduce_sum(y_true + y_pred)\n",
        "    dice_scores = (2.0 * intersections + _epsilon) / (unions + _epsilon)\n",
        "\n",
        "    return dice_scores\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def total_loss(y_true, y_pred):\n",
        "    return 0.5*binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "def IoU(y_true, y_pred, eps=1e-6):\n",
        "\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n",
        "\n",
        "    return K.mean( (intersection + eps) / (union + eps), axis=0)\n",
        "\n",
        "def zero_IoU(y_true, y_pred):\n",
        "\n",
        "    return IoU(1-y_true, 1-y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKrsF-nsIVR5"
      },
      "source": [
        "#Util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcnfowpHIvhB"
      },
      "outputs": [],
      "source": [
        "def default_augment_seg(input_image, input_mask):\n",
        "\n",
        "    input_image = tf.image.random_brightness(input_image, 0.1)\n",
        "    input_image = tf.image.random_contrast(input_image, 0.9, 1.1)\n",
        "    input_image = tf.image.random_saturation(input_image, 0.9, 1.1)\n",
        "    input_image = tf.image.random_hue(input_image, 0.01)\n",
        "\n",
        "    # flipping random horizontal or vertical\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_up_down(input_image)\n",
        "        input_mask = tf.image.flip_up_down(input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "def BatchAdvAugmentSeg(imagesT, masksT):\n",
        "\n",
        "    images, masks = default_augment_seg(imagesT, masksT)\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "def build_decoder(with_labels=True, target_size=(256, 256), ext='png', segment=False, ext2='png'):\n",
        "\n",
        "    def decode(path):\n",
        "        file_bytes = tf.io.read_file(path)\n",
        "        if ext == 'png':\n",
        "            img = tf.image.decode_png(file_bytes, channels=3, dct_method='INTEGER_ACCURATE')\n",
        "        elif ext in ['jpg', 'jpeg']:\n",
        "            img = tf.image.decode_jpeg(file_bytes, channels=3, dct_method='INTEGER_ACCURATE')\n",
        "        else:\n",
        "            raise ValueError(\"Image extension not supported\")\n",
        "\n",
        "        img = tf.image.resize(img, target_size)\n",
        "        # img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "        return img\n",
        "\n",
        "    def decode_mask(path, gray=True):\n",
        "        file_bytes = tf.io.read_file(path)\n",
        "        if ext2 == 'png':\n",
        "            img = tf.image.decode_png(file_bytes, channels=3)\n",
        "        elif ext2 in ['jpg', 'jpeg']:\n",
        "            img = tf.image.decode_jpeg(file_bytes, channels=3)\n",
        "        else:\n",
        "            raise ValueError(\"Image extension not supported\")\n",
        "\n",
        "        img = tf.image.rgb_to_grayscale(img) if gray else img\n",
        "        img = tf.image.resize(img, target_size)\n",
        "        img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "        return img\n",
        "\n",
        "    def decode_with_labels(path, label):\n",
        "        return decode(path), label\n",
        "\n",
        "    def decode_with_segments(path, path2, gray=True):\n",
        "        return decode(path), decode_mask(path2, gray)\n",
        "\n",
        "    if segment:\n",
        "        return decode_with_segments\n",
        "\n",
        "    return decode_with_labels if with_labels else decode\n",
        "\n",
        "\n",
        "def build_augmenter(with_labels=True):\n",
        "    def augment(img):\n",
        "\n",
        "        img = tf.image.random_flip_up_down(img)\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "#         img = tf.image.rot90(img, k=tf.random.uniform([],0,4,tf.int32))\n",
        "\n",
        "        img = tf.image.random_brightness(img, 0.1)\n",
        "        img = tf.image.random_contrast(img, 0.9, 1.1)\n",
        "        img = tf.image.random_saturation(img, 0.9, 1.1)\n",
        "        img = tf.image.random_hue(img, 0.02)\n",
        "\n",
        "        # img = transform_mat(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def augment_with_labels(img, label):\n",
        "        return augment(img), label\n",
        "\n",
        "    return augment_with_labels if with_labels else augment\n",
        "\n",
        "\n",
        "def build_dataset(paths, labels=None, bsize=32, cache=True,\n",
        "                  decode_fn=None, augment_fn=None,\n",
        "                  augment=True, augmentAdv=False, augmentAdvSeg=False, repeat=True, shuffle=1024,\n",
        "                  cache_dir=\"\"):\n",
        "    if cache_dir != \"\" and cache is True:\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "    if decode_fn is None:\n",
        "        decode_fn = build_decoder(labels is not None)\n",
        "\n",
        "    if augment_fn is None:\n",
        "        augment_fn = build_augmenter(labels is not None)\n",
        "\n",
        "    AUTO = tf.data.experimental.AUTOTUNE\n",
        "    slices = paths if labels is None else (paths, labels)\n",
        "\n",
        "    dset = tf.data.Dataset.from_tensor_slices(slices)\n",
        "    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n",
        "    dset = dset.cache(cache_dir) if cache else dset\n",
        "    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n",
        "    #dset = dset.repeat() if repeat else dset\n",
        "    dset = dset.shuffle(shuffle) if shuffle else dset\n",
        "    dset = dset.batch(bsize)\n",
        "    # dset = dset.map(BatchAdvAugment, num_parallel_calls=AUTO) if augmentAdv else dset\n",
        "    dset = dset.map(BatchAdvAugmentSeg, num_parallel_calls=AUTO) if augmentAdvSeg else dset\n",
        "    dset = dset.prefetch(AUTO)\n",
        "\n",
        "    return dset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O61uMWIOJidB"
      },
      "source": [
        "#*layers*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ-C7YMYJkj4"
      },
      "outputs": [],
      "source": [
        "#upsampling\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "def bn_act(inputs, activation='swish'):\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()(inputs)\n",
        "    if activation:\n",
        "        x = tf.keras.layers.Activation(activation)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decode(input_tensor, filters, scale = 2, activation = 'relu'):\n",
        "\n",
        "    x1 = tf.keras.layers.Conv2D(filters, (1, 1), activation=activation, use_bias=False,\n",
        "                                kernel_initializer='he_normal', padding = 'same')(input_tensor)\n",
        "\n",
        "    x2 = tf.keras.layers.Conv2D(filters, (3, 3), activation=activation,\n",
        "                                use_bias=False, padding = 'same')(input_tensor)\n",
        "\n",
        "    merge = tf.keras.layers.Add()([x1, x2])\n",
        "    x = tf.keras.layers.UpSampling2D((scale, scale))(merge)\n",
        "\n",
        "    skip_feature = tf.keras.layers.Conv2D(filters, (3, 3), activation=activation, use_bias=False,\n",
        "                                        kernel_initializer='he_normal', padding = 'same')(merge)\n",
        "\n",
        "    skip_feature = tf.keras.layers.Conv2D(filters, (1, 1), activation=activation, use_bias=False,\n",
        "                                        kernel_initializer='he_normal', padding = 'same')(skip_feature)\n",
        "\n",
        "    merge = tf.keras.layers.Add()([merge, skip_feature])\n",
        "\n",
        "    x = bn_act(x, activation = activation)\n",
        "\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idRcgtInKMii"
      },
      "outputs": [],
      "source": [
        "#util_layer\n",
        "def conv_bn_act(inputs, filters, kernel_size, strides=(1, 1), activation='relu', padding='same'):\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=kernel_size, padding=padding)(inputs)\n",
        "    x = bn_act(x, activation=activation)\n",
        "\n",
        "    return x\n",
        "\n",
        "def merge(l, filters=None):\n",
        "    if filters is None:\n",
        "        channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "        filters = l[0].shape[channel_axis]\n",
        "\n",
        "    x = tf.keras.layers.Add()([l[0],l[1]])\n",
        "\n",
        "    # x = block(x, filters)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToRrDJlxJrOw"
      },
      "outputs": [],
      "source": [
        "#convformer\n",
        "def convformer(input_tensor, filters, padding = \"same\"):\n",
        "\n",
        "    x = tf.keras.layers.LayerNormalization()(input_tensor)\n",
        "    x = tf.keras.layers.SeparableConv2D(filters, kernel_size = (3,3), padding = padding)(x)\n",
        "    # x = x1 + x2 + x3\n",
        "    x = tf.keras.layers.Attention()([x, x, x])\n",
        "    out = tf.keras.layers.Add()([x, input_tensor])\n",
        "\n",
        "    x1 = tf.keras.layers.Dense(filters, activation = \"gelu\")(out)\n",
        "    x1 = tf.keras.layers.Dense(filters)(x1)\n",
        "    out_tensor = tf.keras.layers.Add()([out, x1])\n",
        "    return out_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X76K_LhNJsXY"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7vzce35JKxA"
      },
      "outputs": [],
      "source": [
        "from keras_cv_attention_models import caformer\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "def build_model(img_size = 256, num_classes = 1):\n",
        "    backbone = caformer.CAFormerS18(input_shape=(256, 256, 3), pretrained=\"imagenet\", num_classes = 0)\n",
        "\n",
        "    layer_names = ['stack4_block3_mlp_Dense_1', 'stack3_block9_mlp_Dense_1', 'stack2_block3_mlp_Dense_1', 'stack1_block3_mlp_Dense_1']\n",
        "    layers = [backbone.get_layer(x).output for x in layer_names]\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    h_axis, w_axis = [2, 3] if K.image_data_format() == \"channels_first\" else [1, 2]\n",
        "\n",
        "    x = layers[0]\n",
        "\n",
        "    upscale_feature = decode(x, scale = 4, filters = x.shape[channel_axis])\n",
        "\n",
        "    for i, layer in enumerate(layers[1:]):\n",
        "\n",
        "        x = decode(x, scale = 2, filters = layer.shape[channel_axis])\n",
        "\n",
        "        layer_fusion = convformer(layer, layer.shape[channel_axis])\n",
        "\n",
        "        ## Doing multi-level concatenation\n",
        "        if (i%2 == 1):\n",
        "            upscale_feature = tf.keras.layers.Conv2D(layer.shape[channel_axis], (1, 1), activation = \"relu\", padding = \"same\")(upscale_feature)\n",
        "            x = tf.keras.layers.Add()([x, upscale_feature])\n",
        "            x = tf.keras.layers.Conv2D(x.shape[channel_axis], (1, 1), activation = \"relu\", padding = \"same\")(x)\n",
        "\n",
        "        x = merge([x, layer_fusion], layer.shape[channel_axis])\n",
        "        x = conv_bn_act(x, layer.shape[channel_axis], (1, 1))\n",
        "\n",
        "        ## Upscale for next level feature\n",
        "        if (i%2 == 1):\n",
        "            upscale_feature = decode(x, scale = 8, filters = layer.shape[channel_axis])\n",
        "\n",
        "    filters = x.shape[channel_axis] //2\n",
        "    upscale_feature = conv_bn_act(upscale_feature, filters, 1)\n",
        "    x = decode(x, filters, 4)\n",
        "    x = tf.keras.layers.Add()([x, upscale_feature])\n",
        "    x = conv_bn_act(x, filters, 1)\n",
        "    x = Conv2D(num_classes, kernel_size=1, padding='same', activation='sigmoid')(x)\n",
        "    model = Model(backbone.input, x)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6jKeXTstuNi"
      },
      "source": [
        "#callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck8R3OIntunh"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def cosine_annealing_with_warmup(epochIdx):\n",
        "    aMax, aMin = max_lr, min_lr\n",
        "    warmupEpochs, stagnateEpochs, cosAnnealingEpochs = 0, 0, cos_anne_ep\n",
        "    epochIdx = epochIdx % (warmupEpochs + stagnateEpochs + cosAnnealingEpochs)\n",
        "    if(epochIdx < warmupEpochs):\n",
        "        return aMin + (aMax - aMin) / (warmupEpochs - 1) * epochIdx\n",
        "    else:\n",
        "        epochIdx -= warmupEpochs\n",
        "    if(epochIdx < stagnateEpochs):\n",
        "        return aMax\n",
        "    else:\n",
        "        epochIdx -= stagnateEpochs\n",
        "    return aMin + 0.5 * (aMax - aMin) * (1 + math.cos((epochIdx + 1) / (cosAnnealingEpochs + 1) * math.pi))\n",
        "\n",
        "def plt_lr(step, schedulers):\n",
        "    x = range(step)\n",
        "    y = [schedulers(_) for _ in x]\n",
        "\n",
        "    plt.plot(x, y)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.legend()\n",
        "\n",
        "def get_callbacks(monitor, mode, save_path, _max_lr, _min_lr, _cos_anne_ep, save_weights_only):\n",
        "    global max_lr\n",
        "    max_lr = _max_lr\n",
        "    global min_lr\n",
        "    min_lr = _min_lr\n",
        "    global cos_anne_ep\n",
        "    cos_anne_ep = _cos_anne_ep\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=monitor,\n",
        "        patience=60,\n",
        "        restore_best_weights=True,\n",
        "        mode=mode\n",
        "    )\n",
        "\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=monitor,\n",
        "        factor=0.2,\n",
        "        patience=30,\n",
        "        verbose=1,\n",
        "        mode=mode,\n",
        "        min_lr=1e-5,\n",
        "    )\n",
        "\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=save_path,\n",
        "        monitor=monitor,\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=save_weights_only,\n",
        "        mode=mode,\n",
        "        save_freq=\"epoch\",\n",
        "    )\n",
        "\n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(cosine_annealing_with_warmup, verbose=0)\n",
        "\n",
        "    csv_logger = tf.keras.callbacks.CSVLogger('training.csv')\n",
        "\n",
        "    callbacks = [checkpoint, csv_logger, reduce_lr]\n",
        "# , reduce_lr\n",
        "    return callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYLRnhg5Lfza"
      },
      "source": [
        "#Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWQ3SMyJLC6q"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE5cqjsuLjEX"
      },
      "outputs": [],
      "source": [
        "#parameter\n",
        "img_size = 256\n",
        "BATCH_SIZE = 16\n",
        "SEED = 42\n",
        "save_path = \"best_model.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHAKIN-5LpoX"
      },
      "outputs": [],
      "source": [
        "valid_size = 0.1\n",
        "test_size = 0.1\n",
        "epochs = 350\n",
        "save_weights_only = True\n",
        "max_lr = 1e-4\n",
        "min_lr = 1e-6\n",
        "\n",
        "decay_steps = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPR3tqcHOEau"
      },
      "outputs": [],
      "source": [
        "def myprint(s):\n",
        "    with open('modelsummary.txt','a') as f:\n",
        "        print(s, file=f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(img_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo3dZRKKZmVQ",
        "outputId": "5e8e9d78-abf1-4191-ffab-ad234aa6e310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Load pretrained from: /root/.keras/models/caformer_s18_224_imagenet.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rvI6fwFP20V"
      },
      "outputs": [],
      "source": [
        "model.summary(print_fn=myprint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3cP5JOJP6F9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5fab062-7b26-471e-a47d-f01036e3a636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " stem_ (ZeroPadding2D)          (None, 260, 260, 3)  0           ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 64, 64, 64)   9472        ['stem_[0][0]']                  \n",
            "                                                                                                  \n",
            " stem_ln (LayerNormalization)   (None, 64, 64, 64)   64          ['stem_conv[0][0]']              \n",
            "                                                                                                  \n",
            " stack1_block1_attn_ln (LayerNo  (None, 64, 64, 64)  64          ['stem_ln[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_sep_1_dense   (None, 64, 64, 128)  8192       ['stack1_block1_attn_ln[0][0]']  \n",
            " (Dense)                                                                                          \n",
            "                                                                                                  \n",
            " tf.nn.relu_120 (TFOpLambda)    (None, 64, 64, 128)  0           ['stack1_block1_mlp_sep_1_dense[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " tf.math.pow_120 (TFOpLambda)   (None, 64, 64, 128)  0           ['tf.nn.relu_120[0][0]']         \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_sep_star_rel  (None, 64, 64, 128)  2          ['tf.math.pow_120[0][0]']        \n",
            " u (ZeroInitGain)                                                                                 \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_sep_mid_dw_p  (None, 70, 70, 128)  0          ['stack1_block1_mlp_sep_star_relu\n",
            " ad (ZeroPadding2D)                                              [0][0]']                         \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_sep_mid_dw_c  (None, 64, 64, 128)  6272       ['stack1_block1_mlp_sep_mid_dw_pa\n",
            " onv (DepthwiseConv2D)                                           d[0][0]']                        \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_sep_2_dense   (None, 64, 64, 64)  8192        ['stack1_block1_mlp_sep_mid_dw_co\n",
            " (Dense)                                                         nv[0][0]']                       \n",
            "                                                                                                  \n",
            " stack1_block1_attn_output (Add  (None, 64, 64, 64)  0           ['stem_ln[0][0]',                \n",
            " )                                                                'stack1_block1_mlp_sep_2_dense[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_ln (LayerNor  (None, 64, 64, 64)  64          ['stack1_block1_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_Dense_0 (Den  (None, 64, 64, 256)  16384      ['stack1_block1_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_121 (TFOpLambda)    (None, 64, 64, 256)  0           ['stack1_block1_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_121 (TFOpLambda)   (None, 64, 64, 256)  0           ['tf.nn.relu_121[0][0]']         \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_star_relu (Z  (None, 64, 64, 256)  2          ['tf.math.pow_121[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_Dense_1 (Den  (None, 64, 64, 64)  16384       ['stack1_block1_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack1_block1_mlp_output (Add)  (None, 64, 64, 64)  0           ['stack1_block1_attn_output[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'stack1_block1_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack1_block2_attn_ln (LayerNo  (None, 64, 64, 64)  64          ['stack1_block1_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_sep_1_dense   (None, 64, 64, 128)  8192       ['stack1_block2_attn_ln[0][0]']  \n",
            " (Dense)                                                                                          \n",
            "                                                                                                  \n",
            " tf.nn.relu_122 (TFOpLambda)    (None, 64, 64, 128)  0           ['stack1_block2_mlp_sep_1_dense[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " tf.math.pow_122 (TFOpLambda)   (None, 64, 64, 128)  0           ['tf.nn.relu_122[0][0]']         \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_sep_star_rel  (None, 64, 64, 128)  2          ['tf.math.pow_122[0][0]']        \n",
            " u (ZeroInitGain)                                                                                 \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_sep_mid_dw_p  (None, 70, 70, 128)  0          ['stack1_block2_mlp_sep_star_relu\n",
            " ad (ZeroPadding2D)                                              [0][0]']                         \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_sep_mid_dw_c  (None, 64, 64, 128)  6272       ['stack1_block2_mlp_sep_mid_dw_pa\n",
            " onv (DepthwiseConv2D)                                           d[0][0]']                        \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_sep_2_dense   (None, 64, 64, 64)  8192        ['stack1_block2_mlp_sep_mid_dw_co\n",
            " (Dense)                                                         nv[0][0]']                       \n",
            "                                                                                                  \n",
            " stack1_block2_attn_output (Add  (None, 64, 64, 64)  0           ['stack1_block1_mlp_output[0][0]'\n",
            " )                                                               , 'stack1_block2_mlp_sep_2_dense[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_ln (LayerNor  (None, 64, 64, 64)  64          ['stack1_block2_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_Dense_0 (Den  (None, 64, 64, 256)  16384      ['stack1_block2_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_123 (TFOpLambda)    (None, 64, 64, 256)  0           ['stack1_block2_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_123 (TFOpLambda)   (None, 64, 64, 256)  0           ['tf.nn.relu_123[0][0]']         \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_star_relu (Z  (None, 64, 64, 256)  2          ['tf.math.pow_123[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_Dense_1 (Den  (None, 64, 64, 64)  16384       ['stack1_block2_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack1_block2_mlp_output (Add)  (None, 64, 64, 64)  0           ['stack1_block2_attn_output[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'stack1_block2_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack1_block3_attn_ln (LayerNo  (None, 64, 64, 64)  64          ['stack1_block2_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_sep_1_dense   (None, 64, 64, 128)  8192       ['stack1_block3_attn_ln[0][0]']  \n",
            " (Dense)                                                                                          \n",
            "                                                                                                  \n",
            " tf.nn.relu_124 (TFOpLambda)    (None, 64, 64, 128)  0           ['stack1_block3_mlp_sep_1_dense[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " tf.math.pow_124 (TFOpLambda)   (None, 64, 64, 128)  0           ['tf.nn.relu_124[0][0]']         \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_sep_star_rel  (None, 64, 64, 128)  2          ['tf.math.pow_124[0][0]']        \n",
            " u (ZeroInitGain)                                                                                 \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_sep_mid_dw_p  (None, 70, 70, 128)  0          ['stack1_block3_mlp_sep_star_relu\n",
            " ad (ZeroPadding2D)                                              [0][0]']                         \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_sep_mid_dw_c  (None, 64, 64, 128)  6272       ['stack1_block3_mlp_sep_mid_dw_pa\n",
            " onv (DepthwiseConv2D)                                           d[0][0]']                        \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_sep_2_dense   (None, 64, 64, 64)  8192        ['stack1_block3_mlp_sep_mid_dw_co\n",
            " (Dense)                                                         nv[0][0]']                       \n",
            "                                                                                                  \n",
            " stack1_block3_attn_output (Add  (None, 64, 64, 64)  0           ['stack1_block2_mlp_output[0][0]'\n",
            " )                                                               , 'stack1_block3_mlp_sep_2_dense[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_ln (LayerNor  (None, 64, 64, 64)  64          ['stack1_block3_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_Dense_0 (Den  (None, 64, 64, 256)  16384      ['stack1_block3_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_125 (TFOpLambda)    (None, 64, 64, 256)  0           ['stack1_block3_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_125 (TFOpLambda)   (None, 64, 64, 256)  0           ['tf.nn.relu_125[0][0]']         \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_star_relu (Z  (None, 64, 64, 256)  2          ['tf.math.pow_125[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_Dense_1 (Den  (None, 64, 64, 64)  16384       ['stack1_block3_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack1_block3_mlp_output (Add)  (None, 64, 64, 64)  0           ['stack1_block3_attn_output[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'stack1_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack2_downsample_ln (LayerNor  (None, 64, 64, 64)  64          ['stack1_block3_mlp_output[0][0]'\n",
            " malization)                                                     ]                                \n",
            "                                                                                                  \n",
            " stack2_downsample_pad (ZeroPad  (None, 66, 66, 64)  0           ['stack2_downsample_ln[0][0]']   \n",
            " ding2D)                                                                                          \n",
            "                                                                                                  \n",
            " stack2_downsample_conv (Conv2D  (None, 32, 32, 128)  73856      ['stack2_downsample_pad[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " stack2_block1_attn_ln (LayerNo  (None, 32, 32, 128)  128        ['stack2_downsample_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_sep_1_dense   (None, 32, 32, 256)  32768      ['stack2_block1_attn_ln[0][0]']  \n",
            " (Dense)                                                                                          \n",
            "                                                                                                  \n",
            " tf.nn.relu_126 (TFOpLambda)    (None, 32, 32, 256)  0           ['stack2_block1_mlp_sep_1_dense[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " tf.math.pow_126 (TFOpLambda)   (None, 32, 32, 256)  0           ['tf.nn.relu_126[0][0]']         \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_sep_star_rel  (None, 32, 32, 256)  2          ['tf.math.pow_126[0][0]']        \n",
            " u (ZeroInitGain)                                                                                 \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_sep_mid_dw_p  (None, 38, 38, 256)  0          ['stack2_block1_mlp_sep_star_relu\n",
            " ad (ZeroPadding2D)                                              [0][0]']                         \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_sep_mid_dw_c  (None, 32, 32, 256)  12544      ['stack2_block1_mlp_sep_mid_dw_pa\n",
            " onv (DepthwiseConv2D)                                           d[0][0]']                        \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_sep_2_dense   (None, 32, 32, 128)  32768      ['stack2_block1_mlp_sep_mid_dw_co\n",
            " (Dense)                                                         nv[0][0]']                       \n",
            "                                                                                                  \n",
            " stack2_block1_attn_output (Add  (None, 32, 32, 128)  0          ['stack2_downsample_conv[0][0]', \n",
            " )                                                                'stack2_block1_mlp_sep_2_dense[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_ln (LayerNor  (None, 32, 32, 128)  128        ['stack2_block1_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_Dense_0 (Den  (None, 32, 32, 512)  65536      ['stack2_block1_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_127 (TFOpLambda)    (None, 32, 32, 512)  0           ['stack2_block1_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_127 (TFOpLambda)   (None, 32, 32, 512)  0           ['tf.nn.relu_127[0][0]']         \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_star_relu (Z  (None, 32, 32, 512)  2          ['tf.math.pow_127[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_Dense_1 (Den  (None, 32, 32, 128)  65536      ['stack2_block1_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack2_block1_mlp_output (Add)  (None, 32, 32, 128)  0          ['stack2_block1_attn_output[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'stack2_block1_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack2_block2_attn_ln (LayerNo  (None, 32, 32, 128)  128        ['stack2_block1_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_sep_1_dense   (None, 32, 32, 256)  32768      ['stack2_block2_attn_ln[0][0]']  \n",
            " (Dense)                                                                                          \n",
            "                                                                                                  \n",
            " tf.nn.relu_128 (TFOpLambda)    (None, 32, 32, 256)  0           ['stack2_block2_mlp_sep_1_dense[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " tf.math.pow_128 (TFOpLambda)   (None, 32, 32, 256)  0           ['tf.nn.relu_128[0][0]']         \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_sep_star_rel  (None, 32, 32, 256)  2          ['tf.math.pow_128[0][0]']        \n",
            " u (ZeroInitGain)                                                                                 \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_sep_mid_dw_p  (None, 38, 38, 256)  0          ['stack2_block2_mlp_sep_star_relu\n",
            " ad (ZeroPadding2D)                                              [0][0]']                         \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_sep_mid_dw_c  (None, 32, 32, 256)  12544      ['stack2_block2_mlp_sep_mid_dw_pa\n",
            " onv (DepthwiseConv2D)                                           d[0][0]']                        \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_sep_2_dense   (None, 32, 32, 128)  32768      ['stack2_block2_mlp_sep_mid_dw_co\n",
            " (Dense)                                                         nv[0][0]']                       \n",
            "                                                                                                  \n",
            " stack2_block2_attn_output (Add  (None, 32, 32, 128)  0          ['stack2_block1_mlp_output[0][0]'\n",
            " )                                                               , 'stack2_block2_mlp_sep_2_dense[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_ln (LayerNor  (None, 32, 32, 128)  128        ['stack2_block2_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_Dense_0 (Den  (None, 32, 32, 512)  65536      ['stack2_block2_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_129 (TFOpLambda)    (None, 32, 32, 512)  0           ['stack2_block2_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_129 (TFOpLambda)   (None, 32, 32, 512)  0           ['tf.nn.relu_129[0][0]']         \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_star_relu (Z  (None, 32, 32, 512)  2          ['tf.math.pow_129[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_Dense_1 (Den  (None, 32, 32, 128)  65536      ['stack2_block2_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack2_block2_mlp_output (Add)  (None, 32, 32, 128)  0          ['stack2_block2_attn_output[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'stack2_block2_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack2_block3_attn_ln (LayerNo  (None, 32, 32, 128)  128        ['stack2_block2_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_sep_1_dense   (None, 32, 32, 256)  32768      ['stack2_block3_attn_ln[0][0]']  \n",
            " (Dense)                                                                                          \n",
            "                                                                                                  \n",
            " tf.nn.relu_130 (TFOpLambda)    (None, 32, 32, 256)  0           ['stack2_block3_mlp_sep_1_dense[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " tf.math.pow_130 (TFOpLambda)   (None, 32, 32, 256)  0           ['tf.nn.relu_130[0][0]']         \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_sep_star_rel  (None, 32, 32, 256)  2          ['tf.math.pow_130[0][0]']        \n",
            " u (ZeroInitGain)                                                                                 \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_sep_mid_dw_p  (None, 38, 38, 256)  0          ['stack2_block3_mlp_sep_star_relu\n",
            " ad (ZeroPadding2D)                                              [0][0]']                         \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_sep_mid_dw_c  (None, 32, 32, 256)  12544      ['stack2_block3_mlp_sep_mid_dw_pa\n",
            " onv (DepthwiseConv2D)                                           d[0][0]']                        \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_sep_2_dense   (None, 32, 32, 128)  32768      ['stack2_block3_mlp_sep_mid_dw_co\n",
            " (Dense)                                                         nv[0][0]']                       \n",
            "                                                                                                  \n",
            " stack2_block3_attn_output (Add  (None, 32, 32, 128)  0          ['stack2_block2_mlp_output[0][0]'\n",
            " )                                                               , 'stack2_block3_mlp_sep_2_dense[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_ln (LayerNor  (None, 32, 32, 128)  128        ['stack2_block3_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_Dense_0 (Den  (None, 32, 32, 512)  65536      ['stack2_block3_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_131 (TFOpLambda)    (None, 32, 32, 512)  0           ['stack2_block3_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_131 (TFOpLambda)   (None, 32, 32, 512)  0           ['tf.nn.relu_131[0][0]']         \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_star_relu (Z  (None, 32, 32, 512)  2          ['tf.math.pow_131[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_Dense_1 (Den  (None, 32, 32, 128)  65536      ['stack2_block3_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack2_block3_mlp_output (Add)  (None, 32, 32, 128)  0          ['stack2_block3_attn_output[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'stack2_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_downsample_ln (LayerNor  (None, 32, 32, 128)  128        ['stack2_block3_mlp_output[0][0]'\n",
            " malization)                                                     ]                                \n",
            "                                                                                                  \n",
            " stack3_downsample_pad (ZeroPad  (None, 34, 34, 128)  0          ['stack3_downsample_ln[0][0]']   \n",
            " ding2D)                                                                                          \n",
            "                                                                                                  \n",
            " stack3_downsample_conv (Conv2D  (None, 16, 16, 320)  368960     ['stack3_downsample_pad[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " stack3_block1_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_downsample_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " stack3_block1_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block1_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_300 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block1_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_60 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_300[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_301 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_60[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_302 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_60[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_240 (TF  (None, 10, 256, 32)  0          ['tf.reshape_301[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_241 (TF  (None, 10, 32, 256)  0          ['tf.reshape_302[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_120 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_240[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_241[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_60 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_120[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_303 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_60[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block1_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_60[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_242 (TF  (None, 10, 256, 32)  0          ['tf.reshape_303[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_121 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block1_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_242[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_243 (TF  (None, 256, 10, 32)  0          ['lambda_121[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_304 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_243[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block1_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_downsample_conv[0][0]'] \n",
            " ChannelAffine)                                                                                   \n",
            "                                                                                                  \n",
            " stack3_block1_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_304[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block1_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block1_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block1_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block1_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block1_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block1_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block1_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_132 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block1_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_132 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_132[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block1_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_132[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block1_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block1_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block1_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block1_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block1_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block1_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block1_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block2_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_block1_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack3_block2_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block2_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_305 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block2_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_61 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_305[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_306 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_61[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_307 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_61[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_244 (TF  (None, 10, 256, 32)  0          ['tf.reshape_306[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_245 (TF  (None, 10, 32, 256)  0          ['tf.reshape_307[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_122 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_244[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_245[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_61 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_122[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_308 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_61[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block2_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_61[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_246 (TF  (None, 10, 256, 32)  0          ['tf.reshape_308[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_123 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block2_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_246[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_247 (TF  (None, 256, 10, 32)  0          ['lambda_123[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_309 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_247[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block2_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_block1_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack3_block2_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_309[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block2_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block2_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block2_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block2_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block2_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block2_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block2_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_133 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block2_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_133 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_133[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block2_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_133[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block2_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block2_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block2_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block2_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block2_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block2_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block2_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block3_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_block2_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack3_block3_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block3_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_310 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block3_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_62 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_310[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_311 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_62[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_312 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_62[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_248 (TF  (None, 10, 256, 32)  0          ['tf.reshape_311[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_249 (TF  (None, 10, 32, 256)  0          ['tf.reshape_312[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_124 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_248[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_249[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_62 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_124[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_313 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_62[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block3_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_62[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_250 (TF  (None, 10, 256, 32)  0          ['tf.reshape_313[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_125 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block3_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_250[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_251 (TF  (None, 256, 10, 32)  0          ['lambda_125[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_314 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_251[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block3_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_block2_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack3_block3_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_314[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block3_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block3_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block3_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block3_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block3_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block3_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block3_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_134 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block3_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_134 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_134[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block3_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_134[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block3_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block3_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block3_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block3_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block3_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block3_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block4_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_block3_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack3_block4_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block4_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_315 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block4_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_63 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_315[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_316 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_63[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_317 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_63[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_252 (TF  (None, 10, 256, 32)  0          ['tf.reshape_316[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_253 (TF  (None, 10, 32, 256)  0          ['tf.reshape_317[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_126 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_252[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_253[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_63 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_126[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_318 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_63[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block4_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_63[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_254 (TF  (None, 10, 256, 32)  0          ['tf.reshape_318[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_127 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block4_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_254[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_255 (TF  (None, 256, 10, 32)  0          ['lambda_127[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_319 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_255[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block4_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_block3_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack3_block4_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_319[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block4_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block4_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block4_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block4_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block4_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block4_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block4_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_135 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block4_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_135 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_135[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block4_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_135[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block4_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block4_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block4_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block4_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block4_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block4_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block4_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block5_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_block4_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack3_block5_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block5_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_320 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block5_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_64 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_320[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_321 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_64[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_322 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_64[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_256 (TF  (None, 10, 256, 32)  0          ['tf.reshape_321[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_257 (TF  (None, 10, 32, 256)  0          ['tf.reshape_322[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_128 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_256[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_257[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_64 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_128[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_323 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_64[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block5_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_64[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_258 (TF  (None, 10, 256, 32)  0          ['tf.reshape_323[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_129 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block5_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_258[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_259 (TF  (None, 256, 10, 32)  0          ['lambda_129[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_324 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_259[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block5_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_block4_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack3_block5_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_324[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block5_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block5_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block5_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block5_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block5_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block5_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block5_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_136 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block5_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_136 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_136[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block5_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_136[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block5_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block5_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block5_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block5_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block5_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block5_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block5_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block6_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_block5_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack3_block6_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block6_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_325 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block6_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_65 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_325[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_326 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_65[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_327 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_65[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_260 (TF  (None, 10, 256, 32)  0          ['tf.reshape_326[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_261 (TF  (None, 10, 32, 256)  0          ['tf.reshape_327[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_130 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_260[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_261[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_65 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_130[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_328 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_65[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block6_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_65[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_262 (TF  (None, 10, 256, 32)  0          ['tf.reshape_328[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_131 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block6_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_262[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_263 (TF  (None, 256, 10, 32)  0          ['lambda_131[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_329 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_263[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block6_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_block5_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack3_block6_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_329[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block6_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block6_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block6_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block6_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block6_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block6_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block6_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_137 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block6_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_137 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_137[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block6_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_137[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block6_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block6_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block6_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block6_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block6_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block6_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block6_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block7_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_block6_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack3_block7_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block7_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_330 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block7_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_66 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_330[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_331 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_66[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_332 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_66[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_264 (TF  (None, 10, 256, 32)  0          ['tf.reshape_331[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_265 (TF  (None, 10, 32, 256)  0          ['tf.reshape_332[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_132 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_264[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_265[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_66 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_132[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_333 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_66[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block7_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_66[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_266 (TF  (None, 10, 256, 32)  0          ['tf.reshape_333[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_133 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block7_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_266[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_267 (TF  (None, 256, 10, 32)  0          ['lambda_133[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_334 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_267[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block7_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_block6_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack3_block7_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_334[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block7_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block7_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block7_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block7_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block7_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block7_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block7_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_138 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block7_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_138 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_138[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block7_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_138[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block7_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block7_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block7_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block7_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block7_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block7_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block7_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block8_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_block7_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack3_block8_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block8_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_335 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block8_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_67 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_335[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_336 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_67[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_337 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_67[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_268 (TF  (None, 10, 256, 32)  0          ['tf.reshape_336[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_269 (TF  (None, 10, 32, 256)  0          ['tf.reshape_337[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_134 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_268[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_269[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_67 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_134[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_338 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_67[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block8_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_67[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_270 (TF  (None, 10, 256, 32)  0          ['tf.reshape_338[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_135 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block8_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_270[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_271 (TF  (None, 256, 10, 32)  0          ['lambda_135[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_339 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_271[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block8_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_block7_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack3_block8_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_339[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block8_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block8_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block8_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block8_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block8_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block8_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block8_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_139 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block8_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_139 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_139[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block8_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_139[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block8_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block8_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block8_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block8_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block8_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block8_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block8_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block9_attn_ln (LayerNo  (None, 16, 16, 320)  320        ['stack3_block8_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack3_block9_mhsa_qkv (Dense)  (None, 16, 16, 960)  307200     ['stack3_block9_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_340 (TFOpLambda)    (None, 256, 960)     0           ['stack3_block9_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_68 (TFOpLambda)       [(None, 256, 320),   0           ['tf.reshape_340[0][0]']         \n",
            "                                 (None, 256, 320),                                                \n",
            "                                 (None, 256, 320)]                                                \n",
            "                                                                                                  \n",
            " tf.reshape_341 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_68[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_342 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_68[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_272 (TF  (None, 10, 256, 32)  0          ['tf.reshape_341[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_273 (TF  (None, 10, 32, 256)  0          ['tf.reshape_342[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_136 (Lambda)            (None, 10, 256, 256  0           ['tf.compat.v1.transpose_272[0][0\n",
            "                                )                                ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_273[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_68 (TFOpLambd  (None, 10, 256, 256  0          ['lambda_136[0][0]']             \n",
            " a)                             )                                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_343 (TFOpLambda)    (None, 256, 10, 32)  0           ['tf.split_68[0][2]']            \n",
            "                                                                                                  \n",
            " stack3_block9_mhsa_attention_s  (None, 10, 256, 256  0          ['tf.math.multiply_68[0][0]']    \n",
            " cores (Softmax)                )                                                                 \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_274 (TF  (None, 10, 256, 32)  0          ['tf.reshape_343[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_137 (Lambda)            (None, 10, 256, 32)  0           ['stack3_block9_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_274[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_275 (TF  (None, 256, 10, 32)  0          ['lambda_137[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_344 (TFOpLambda)    (None, 16, 16, 320)  0           ['tf.compat.v1.transpose_275[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack3_block9_attn_res_gamma (  (None, 16, 16, 320)  320        ['stack3_block8_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack3_block9_mhsa_output (Den  (None, 16, 16, 320)  102400     ['tf.reshape_344[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack3_block9_attn_output (Add  (None, 16, 16, 320)  0          ['stack3_block9_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack3_block9_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack3_block9_mlp_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block9_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack3_block9_mlp_Dense_0 (Den  (None, 16, 16, 1280  409600     ['stack3_block9_mlp_ln[0][0]']   \n",
            " se)                            )                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_140 (TFOpLambda)    (None, 16, 16, 1280  0           ['stack3_block9_mlp_Dense_0[0][0]\n",
            "                                )                                ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_140 (TFOpLambda)   (None, 16, 16, 1280  0           ['tf.nn.relu_140[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block9_mlp_star_relu (Z  (None, 16, 16, 1280  2          ['tf.math.pow_140[0][0]']        \n",
            " eroInitGain)                   )                                                                 \n",
            "                                                                                                  \n",
            " stack3_block9_mlp_res_gamma (C  (None, 16, 16, 320)  320        ['stack3_block9_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack3_block9_mlp_Dense_1 (Den  (None, 16, 16, 320)  409600     ['stack3_block9_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack3_block9_mlp_output (Add)  (None, 16, 16, 320)  0          ['stack3_block9_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack3_block9_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack4_downsample_ln (LayerNor  (None, 16, 16, 320)  320        ['stack3_block9_mlp_output[0][0]'\n",
            " malization)                                                     ]                                \n",
            "                                                                                                  \n",
            " stack4_downsample_pad (ZeroPad  (None, 18, 18, 320)  0          ['stack4_downsample_ln[0][0]']   \n",
            " ding2D)                                                                                          \n",
            "                                                                                                  \n",
            " stack4_downsample_conv (Conv2D  (None, 8, 8, 512)   1475072     ['stack4_downsample_pad[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " stack4_block1_attn_ln (LayerNo  (None, 8, 8, 512)   512         ['stack4_downsample_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " stack4_block1_mhsa_qkv (Dense)  (None, 8, 8, 1536)  786432      ['stack4_block1_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_345 (TFOpLambda)    (None, 64, 1536)     0           ['stack4_block1_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_69 (TFOpLambda)       [(None, 64, 512),    0           ['tf.reshape_345[0][0]']         \n",
            "                                 (None, 64, 512),                                                 \n",
            "                                 (None, 64, 512)]                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_346 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_69[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_347 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_69[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_276 (TF  (None, 16, 64, 32)  0           ['tf.reshape_346[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_277 (TF  (None, 16, 32, 64)  0           ['tf.reshape_347[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_138 (Lambda)            (None, 16, 64, 64)   0           ['tf.compat.v1.transpose_276[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_277[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_69 (TFOpLambd  (None, 16, 64, 64)  0           ['lambda_138[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.reshape_348 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_69[0][2]']            \n",
            "                                                                                                  \n",
            " stack4_block1_mhsa_attention_s  (None, 16, 64, 64)  0           ['tf.math.multiply_69[0][0]']    \n",
            " cores (Softmax)                                                                                  \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_278 (TF  (None, 16, 64, 32)  0           ['tf.reshape_348[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_139 (Lambda)            (None, 16, 64, 32)   0           ['stack4_block1_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_278[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_279 (TF  (None, 64, 16, 32)  0           ['lambda_139[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_349 (TFOpLambda)    (None, 8, 8, 512)    0           ['tf.compat.v1.transpose_279[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack4_block1_attn_res_gamma (  (None, 8, 8, 512)   512         ['stack4_downsample_conv[0][0]'] \n",
            " ChannelAffine)                                                                                   \n",
            "                                                                                                  \n",
            " stack4_block1_mhsa_output (Den  (None, 8, 8, 512)   262144      ['tf.reshape_349[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack4_block1_attn_output (Add  (None, 8, 8, 512)   0           ['stack4_block1_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack4_block1_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack4_block1_mlp_ln (LayerNor  (None, 8, 8, 512)   512         ['stack4_block1_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack4_block1_mlp_Dense_0 (Den  (None, 8, 8, 2048)  1048576     ['stack4_block1_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_141 (TFOpLambda)    (None, 8, 8, 2048)   0           ['stack4_block1_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_141 (TFOpLambda)   (None, 8, 8, 2048)   0           ['tf.nn.relu_141[0][0]']         \n",
            "                                                                                                  \n",
            " stack4_block1_mlp_star_relu (Z  (None, 8, 8, 2048)  2           ['tf.math.pow_141[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " stack4_block1_mlp_res_gamma (C  (None, 8, 8, 512)   512         ['stack4_block1_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack4_block1_mlp_Dense_1 (Den  (None, 8, 8, 512)   1048576     ['stack4_block1_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack4_block1_mlp_output (Add)  (None, 8, 8, 512)   0           ['stack4_block1_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack4_block1_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack4_block2_attn_ln (LayerNo  (None, 8, 8, 512)   512         ['stack4_block1_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack4_block2_mhsa_qkv (Dense)  (None, 8, 8, 1536)  786432      ['stack4_block2_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_350 (TFOpLambda)    (None, 64, 1536)     0           ['stack4_block2_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_70 (TFOpLambda)       [(None, 64, 512),    0           ['tf.reshape_350[0][0]']         \n",
            "                                 (None, 64, 512),                                                 \n",
            "                                 (None, 64, 512)]                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_351 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_70[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_352 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_70[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_280 (TF  (None, 16, 64, 32)  0           ['tf.reshape_351[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_281 (TF  (None, 16, 32, 64)  0           ['tf.reshape_352[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_140 (Lambda)            (None, 16, 64, 64)   0           ['tf.compat.v1.transpose_280[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_281[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_70 (TFOpLambd  (None, 16, 64, 64)  0           ['lambda_140[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.reshape_353 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_70[0][2]']            \n",
            "                                                                                                  \n",
            " stack4_block2_mhsa_attention_s  (None, 16, 64, 64)  0           ['tf.math.multiply_70[0][0]']    \n",
            " cores (Softmax)                                                                                  \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_282 (TF  (None, 16, 64, 32)  0           ['tf.reshape_353[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_141 (Lambda)            (None, 16, 64, 32)   0           ['stack4_block2_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_282[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_283 (TF  (None, 64, 16, 32)  0           ['lambda_141[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_354 (TFOpLambda)    (None, 8, 8, 512)    0           ['tf.compat.v1.transpose_283[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack4_block2_attn_res_gamma (  (None, 8, 8, 512)   512         ['stack4_block1_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack4_block2_mhsa_output (Den  (None, 8, 8, 512)   262144      ['tf.reshape_354[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack4_block2_attn_output (Add  (None, 8, 8, 512)   0           ['stack4_block2_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack4_block2_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack4_block2_mlp_ln (LayerNor  (None, 8, 8, 512)   512         ['stack4_block2_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack4_block2_mlp_Dense_0 (Den  (None, 8, 8, 2048)  1048576     ['stack4_block2_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_142 (TFOpLambda)    (None, 8, 8, 2048)   0           ['stack4_block2_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_142 (TFOpLambda)   (None, 8, 8, 2048)   0           ['tf.nn.relu_142[0][0]']         \n",
            "                                                                                                  \n",
            " stack4_block2_mlp_star_relu (Z  (None, 8, 8, 2048)  2           ['tf.math.pow_142[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " stack4_block2_mlp_res_gamma (C  (None, 8, 8, 512)   512         ['stack4_block2_attn_output[0][0]\n",
            " hannelAffine)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack4_block2_mlp_Dense_1 (Den  (None, 8, 8, 512)   1048576     ['stack4_block2_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " stack4_block2_mlp_output (Add)  (None, 8, 8, 512)   0           ['stack4_block2_mlp_res_gamma[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'stack4_block2_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack4_block3_attn_ln (LayerNo  (None, 8, 8, 512)   512         ['stack4_block2_mlp_output[0][0]'\n",
            " rmalization)                                                    ]                                \n",
            "                                                                                                  \n",
            " stack4_block3_mhsa_qkv (Dense)  (None, 8, 8, 1536)  786432      ['stack4_block3_attn_ln[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape_355 (TFOpLambda)    (None, 64, 1536)     0           ['stack4_block3_mhsa_qkv[0][0]'] \n",
            "                                                                                                  \n",
            " tf.split_71 (TFOpLambda)       [(None, 64, 512),    0           ['tf.reshape_355[0][0]']         \n",
            "                                 (None, 64, 512),                                                 \n",
            "                                 (None, 64, 512)]                                                 \n",
            "                                                                                                  \n",
            " tf.reshape_356 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_71[0][0]']            \n",
            "                                                                                                  \n",
            " tf.reshape_357 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_71[0][1]']            \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_284 (TF  (None, 16, 64, 32)  0           ['tf.reshape_356[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_285 (TF  (None, 16, 32, 64)  0           ['tf.reshape_357[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_142 (Lambda)            (None, 16, 64, 64)   0           ['tf.compat.v1.transpose_284[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.compat.v1.transpose_285[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_71 (TFOpLambd  (None, 16, 64, 64)  0           ['lambda_142[0][0]']             \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.reshape_358 (TFOpLambda)    (None, 64, 16, 32)   0           ['tf.split_71[0][2]']            \n",
            "                                                                                                  \n",
            " stack4_block3_mhsa_attention_s  (None, 16, 64, 64)  0           ['tf.math.multiply_71[0][0]']    \n",
            " cores (Softmax)                                                                                  \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_286 (TF  (None, 16, 64, 32)  0           ['tf.reshape_358[0][0]']         \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " lambda_143 (Lambda)            (None, 16, 64, 32)   0           ['stack4_block3_mhsa_attention_sc\n",
            "                                                                 ores[0][0]',                     \n",
            "                                                                  'tf.compat.v1.transpose_286[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.transpose_287 (TF  (None, 64, 16, 32)  0           ['lambda_143[0][0]']             \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " tf.reshape_359 (TFOpLambda)    (None, 8, 8, 512)    0           ['tf.compat.v1.transpose_287[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " stack4_block3_attn_res_gamma (  (None, 8, 8, 512)   512         ['stack4_block2_mlp_output[0][0]'\n",
            " ChannelAffine)                                                  ]                                \n",
            "                                                                                                  \n",
            " stack4_block3_mhsa_output (Den  (None, 8, 8, 512)   262144      ['tf.reshape_359[0][0]']         \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " stack4_block3_attn_output (Add  (None, 8, 8, 512)   0           ['stack4_block3_attn_res_gamma[0]\n",
            " )                                                               [0]',                            \n",
            "                                                                  'stack4_block3_mhsa_output[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " stack4_block3_mlp_ln (LayerNor  (None, 8, 8, 512)   512         ['stack4_block3_attn_output[0][0]\n",
            " malization)                                                     ']                               \n",
            "                                                                                                  \n",
            " stack4_block3_mlp_Dense_0 (Den  (None, 8, 8, 2048)  1048576     ['stack4_block3_mlp_ln[0][0]']   \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " tf.nn.relu_143 (TFOpLambda)    (None, 8, 8, 2048)   0           ['stack4_block3_mlp_Dense_0[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " tf.math.pow_143 (TFOpLambda)   (None, 8, 8, 2048)   0           ['tf.nn.relu_143[0][0]']         \n",
            "                                                                                                  \n",
            " stack4_block3_mlp_star_relu (Z  (None, 8, 8, 2048)  2           ['tf.math.pow_143[0][0]']        \n",
            " eroInitGain)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 16, 16, 320)  640        ['stack3_block9_mlp_Dense_1[0][0]\n",
            " ormalization)                                                   ']                               \n",
            "                                                                                                  \n",
            " stack4_block3_mlp_Dense_1 (Den  (None, 8, 8, 512)   1048576     ['stack4_block3_mlp_star_relu[0][\n",
            " se)                                                             0]']                             \n",
            "                                                                                                  \n",
            " separable_conv2d_15 (Separable  (None, 16, 16, 320)  105600     ['layer_normalization_15[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 8, 8, 320)    163840      ['stack4_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 8, 8, 320)    1474560     ['stack4_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " attention_15 (Attention)       (None, 16, 16, 320)  0           ['separable_conv2d_15[0][0]',    \n",
            "                                                                  'separable_conv2d_15[0][0]',    \n",
            "                                                                  'separable_conv2d_15[0][0]']    \n",
            "                                                                                                  \n",
            " add_117 (Add)                  (None, 8, 8, 320)    0           ['conv2d_164[0][0]',             \n",
            "                                                                  'conv2d_165[0][0]']             \n",
            "                                                                                                  \n",
            " add_119 (Add)                  (None, 16, 16, 320)  0           ['attention_15[0][0]',           \n",
            "                                                                  'stack3_block9_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " up_sampling2d_31 (UpSampling2D  (None, 16, 16, 320)  0          ['add_117[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_30 (Dense)               (None, 16, 16, 320)  102720      ['add_119[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 16, 16, 320)  1280       ['up_sampling2d_31[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_31 (Dense)               (None, 16, 16, 320)  102720      ['dense_30[0][0]']               \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 16, 16, 320)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " add_120 (Add)                  (None, 16, 16, 320)  0           ['add_119[0][0]',                \n",
            "                                                                  'dense_31[0][0]']               \n",
            "                                                                                                  \n",
            " add_121 (Add)                  (None, 16, 16, 320)  0           ['activation_56[0][0]',          \n",
            "                                                                  'add_120[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 16, 16, 320)  102720      ['add_121[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 16, 16, 320)  1280       ['conv2d_168[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 16, 16, 320)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 8, 8, 512)    262144      ['stack4_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 8, 8, 512)    2359296     ['stack4_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 16, 16, 128)  40960       ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 16, 16, 128)  368640      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " add_115 (Add)                  (None, 8, 8, 512)    0           ['conv2d_160[0][0]',             \n",
            "                                                                  'conv2d_161[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_16 (LayerN  (None, 32, 32, 128)  256        ['stack2_block3_mlp_Dense_1[0][0]\n",
            " ormalization)                                                   ']                               \n",
            "                                                                                                  \n",
            " add_122 (Add)                  (None, 16, 16, 128)  0           ['conv2d_169[0][0]',             \n",
            "                                                                  'conv2d_170[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_30 (UpSampling2D  (None, 32, 32, 512)  0          ['add_115[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_16 (Separable  (None, 32, 32, 128)  17664      ['layer_normalization_16[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " up_sampling2d_32 (UpSampling2D  (None, 32, 32, 128)  0          ['add_122[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 32, 32, 512)  2048       ['up_sampling2d_30[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " attention_16 (Attention)       (None, 32, 32, 128)  0           ['separable_conv2d_16[0][0]',    \n",
            "                                                                  'separable_conv2d_16[0][0]',    \n",
            "                                                                  'separable_conv2d_16[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 32, 32, 128)  512        ['up_sampling2d_32[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " add_124 (Add)                  (None, 32, 32, 128)  0           ['attention_16[0][0]',           \n",
            "                                                                  'stack2_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 32, 32, 128)  65664       ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 32, 32, 128)  16512       ['add_124[0][0]']                \n",
            "                                                                                                  \n",
            " add_126 (Add)                  (None, 32, 32, 128)  0           ['activation_58[0][0]',          \n",
            "                                                                  'conv2d_173[0][0]']             \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 32, 32, 128)  16512       ['dense_32[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 32, 32, 128)  16512       ['add_126[0][0]']                \n",
            "                                                                                                  \n",
            " add_125 (Add)                  (None, 32, 32, 128)  0           ['add_124[0][0]',                \n",
            "                                                                  'dense_33[0][0]']               \n",
            "                                                                                                  \n",
            " add_127 (Add)                  (None, 32, 32, 128)  0           ['conv2d_174[0][0]',             \n",
            "                                                                  'add_125[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 32, 32, 128)  16512       ['add_127[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 32, 32, 128)  512        ['conv2d_175[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " layer_normalization_17 (LayerN  (None, 64, 64, 64)  128         ['stack1_block3_mlp_Dense_1[0][0]\n",
            " ormalization)                                                   ']                               \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " separable_conv2d_17 (Separable  (None, 64, 64, 64)  4736        ['layer_normalization_17[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 32, 32, 64)   8192        ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 32, 32, 64)   73728       ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " attention_17 (Attention)       (None, 64, 64, 64)   0           ['separable_conv2d_17[0][0]',    \n",
            "                                                                  'separable_conv2d_17[0][0]',    \n",
            "                                                                  'separable_conv2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " add_130 (Add)                  (None, 32, 32, 64)   0           ['conv2d_180[0][0]',             \n",
            "                                                                  'conv2d_181[0][0]']             \n",
            "                                                                                                  \n",
            " add_132 (Add)                  (None, 64, 64, 64)   0           ['attention_17[0][0]',           \n",
            "                                                                  'stack1_block3_mlp_Dense_1[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " up_sampling2d_34 (UpSampling2D  (None, 64, 64, 64)  0           ['add_130[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_34 (Dense)               (None, 64, 64, 64)   4160        ['add_132[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 64, 64, 64)  256         ['up_sampling2d_34[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_35 (Dense)               (None, 64, 64, 64)   4160        ['dense_34[0][0]']               \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " add_133 (Add)                  (None, 64, 64, 64)   0           ['add_132[0][0]',                \n",
            "                                                                  'dense_35[0][0]']               \n",
            "                                                                                                  \n",
            " add_134 (Add)                  (None, 64, 64, 64)   0           ['activation_61[0][0]',          \n",
            "                                                                  'add_133[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 64, 64, 64)   4160        ['add_134[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 32, 32, 128)  16384       ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 32, 32, 128)  147456      ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 64, 64, 64)  256         ['conv2d_184[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_128 (Add)                  (None, 32, 32, 128)  0           ['conv2d_176[0][0]',             \n",
            "                                                                  'conv2d_177[0][0]']             \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_33 (UpSampling2D  (None, 256, 256, 12  0          ['add_128[0][0]']                \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 64, 64, 32)   2048        ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 64, 64, 32)   18432       ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 256, 256, 12  512        ['up_sampling2d_33[0][0]']       \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " add_135 (Add)                  (None, 64, 64, 32)   0           ['conv2d_186[0][0]',             \n",
            "                                                                  'conv2d_187[0][0]']             \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_60[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_35 (UpSampling2D  (None, 256, 256, 32  0          ['add_135[0][0]']                \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 256, 256, 32  4128        ['activation_60[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 256, 256, 32  128        ['up_sampling2d_35[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 256, 256, 32  128        ['conv2d_185[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_64[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_63[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_137 (Add)                  (None, 256, 256, 32  0           ['activation_64[0][0]',          \n",
            "                                )                                 'activation_63[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_190 (Conv2D)            (None, 256, 256, 32  1056        ['add_137[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 256, 256, 32  128        ['conv2d_190[0][0]']             \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_65[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_191 (Conv2D)            (None, 256, 256, 1)  33          ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,765,713\n",
            "Trainable params: 28,762,193\n",
            "Non-trainable params: 3,520\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecVDVjVyQD91"
      },
      "outputs": [],
      "source": [
        "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    max_lr,\n",
        "    decay_steps,\n",
        "    min_lr,\n",
        "    power=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbCoa3LzQNEF"
      },
      "outputs": [],
      "source": [
        "opts = tfa.optimizers.AdamW(learning_rate = 1e-4, weight_decay = learning_rate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQOS-mQZQPx8"
      },
      "outputs": [],
      "source": [
        "get_custom_objects().update({\"dice\": dice_loss})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z32tLE37QfFl"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA0UP3cdQhzN",
        "outputId": "be648872-c388-4d05-9a4b-9cd0ad1775e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1GtJGmfd-2d5eAFzhpa3Hp2FY_ccurpAS kvasir-seg.zip\n",
            "Processing file 1VO3kohakS_ldOsghnktO5L-6iikwUh1K metadata.csv\n",
            "Building directory structure completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GtJGmfd-2d5eAFzhpa3Hp2FY_ccurpAS\n",
            "To: /content/Kvasir-SEG/kvasir-seg.zip\n",
            "100%|██████████| 46.2M/46.2M [00:00<00:00, 61.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VO3kohakS_ldOsghnktO5L-6iikwUh1K\n",
            "To: /content/Kvasir-SEG/metadata.csv\n",
            "0.00B [00:00, ?B/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Kvasir-SEG/kvasir-seg.zip\n",
            "  inflating: Kvasir-SEG/kavsir_bboxes.json  \n",
            "   creating: Kvasir-SEG/images/\n",
            "  inflating: Kvasir-SEG/images/ck2bxiswtxuw80838qkisqjwz.jpg  \n",
            "  inflating: Kvasir-SEG/images/ck2bxknhjvs1x0794iogrq49k.jpg  \n",
            "  inflating: Kvasir-SEG/images/ck2bxlujamu330725szlc2jdu.jpg  \n",
            "  inflating: Kvasir-SEG/images/ck2bxpfgxu2mk0748gsh7xelu.jpg  \n",
            "  inflating: Kvasir-SEG/images/ck2bxqz3evvg20794iiyv5v2m.jpg  \n",
            "  inflating: Kvasir-SEG/images/ck2bxskgxxzfv08386xkqtqdy.jpg  \n",
            "  inflating: Kvasir-SEG/images/ck2bxw18mmz1k0725litqq2mc.jpg  \n",
            "  inflating: Kvasir-SEG/images/ck2395w2mb4vu07480otsu6tw.jpg  \n",
            "  inflating: Kvasir-SEG/images/ck2da7fwcjfis07218r1rvm95.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzjzssvd8pq0838f4nolj5l.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzk8qieoboa0848ogj51wwm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5hi52odyf90817prvcwg45.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5hjxaae3i40850h5z2laf5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5hl8nee8a40755fm8qjj0o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5hqz50e7o90850e0prlpa0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ht88gedbu0755xrcuddcx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5huurrecm70801y680y13m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5hwonqedw10801vsd3w6kk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5hyi9yegob0755ho3do8en.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5i39mreass0817au8p22zy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5i5oh2efg60987ez6cpf72.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5jx7jzf7c90871c2i9aiov.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5jz5fff8c50871hbe6108f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5k3j3uf6de0817hszzfr7n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5k503sfa5f0871lx0rpu5y.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5k7r0yf98c09878csbxb4d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5klveuff6w0871wbibgh3m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5knbbqfipk080128cggukq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6xmqd9w0250817l5kxfnsk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6ywm40wdbo0987pbftsvtg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5kre09fhka0850h7b1898j.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ktjwofed70817eg58ef7u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5nxkujgscq0817l9gss626.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5nyu31gv8e0871zpk74a2n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5o1vu9gz8a0818eyy92bns.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5o4pk9h0720755lgp9jq8m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5tenjojp1j0755ms4949h2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5tgbzhjllu08174ca41eus.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5thdbrjp1108715xdfx356.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5u4pywk81x0817vn9pe14z.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5u6wf0kh1t0755bg1ssixv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5u8gz4kj5b07552e2wpkwp.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5udcufki0s09874ll1dbr5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ufn3skquf0818dhapnhba.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5uget8krjy0818kvywd0zu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5uhrdwkmsu0817ervv91l8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ukkg6kv7u08011x2b6zl5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5uxjnol2r509871qv2yeia.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5uzmaol56l0817flxh4w9p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5v8pgplg6k0755rvi2t63h.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5vbo6jldrt0871jf6f1700.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5vcmrqla7i0817x4sp4pqw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5vgawslbe30987ndeepc1b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5vi4nxlc530817uoqm2m7a.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5von04litr08718j8po40a.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5vutu7ll8w0871dfp92n9p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5vwbr4lhqn0987a1pji0ux.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5vxuc5loxw0818u8xgf45p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5vzjoslpj708186z2fusmz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5w7xn0lrkq0801f9k0htgx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5waeduln160817w0agirve.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wcc90lu020850mjrxppv6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wi6bqlxy90755bu227nvb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wj0faly5008187n6530af.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wkonqlrl409877y8zvnub.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wmvsdlx1j0871npgj8j4b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5woy82m07m08505dmjg7g1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wphwwlu3m0987hh3ltg88.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wqonpm0e60801z88ewmy1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wrapcm2290818jsh26ppb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wrrs0m2af0818vmnajbtw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0qkwl35piu0993l0dewei2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0qoxqj9q6s0835b43399p4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0qx73cjw570799j4n5cjze.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0roawvklrq0799vmjorwfv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0rx1idathl0835detmsp84.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0s2a9ekvms080138tjjpxr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0s690hkp960855tjuaqvv0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0sr5ghl0nd08789uzf1raf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0sxqiclckk08551ycbwhno.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0t4oil7vzk099370nun5h9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0tl3uz8blh0993wxvn7ly3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0u2g7pmnux0801vkk47ivj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0u82z3cuma0835wlxrnrjv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0ue769mxii08019zqgdbxn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju0vtox5ain6099360pu62rp.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju13cgqmnhwn0988yrainhcp.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju13fwthn9mq0835gacxgy01.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju13hp5rnbjx0835bf0jowgx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju14g8o4xui30878gkgbrvqj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju14hjh2ob2o0835ouz3r5aa.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju14pxbaoksp0835qzorx6g6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju15czxqp3lv0835jvhgzurz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wtdu4m0im0871mix0yvc0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5wuhm1lwm40987vugqn3vv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5x00l6m5j608503k78ptee.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5x15djm7ae0755h8czf6nt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5x28nzm7t907558ocq4bt7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5x7iskmad90818frchyfwd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5xjn5mm78b09871spyqhhr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5xkwzxmf0z0818gk4xabdm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5xneamme2p0801qdf7fdwv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6yxyt0wh080871sqpepu47.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6yywx1whbb0871ksgfgf9f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5xopi0md7q0871r1sjc1av.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5xq3tdm9fn0987pbedxdg5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5y4hgqmk0i08180rjhbwvp.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5y7buemcw80987p0r30g9f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5y84q3mdv50817eyp82xf3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5yclrymlgj0818k426ud6z.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5yeqiwmkgl0801fzv2douc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ygh1zmmdi0755uod5e17i.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5yhgznmkzb0801cji2vi8j.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5yimthmlv80850zhoc90c2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5yjq1pmlgc0801z0t24bly.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ymyd8mmdc0801ry3by1xr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6ur9l9v9jq0755paud9uka.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6us80mv1b50871ebyq2wxa.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6ut4l8va6y0755tyw3vfqq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6uy20suzbl0987rzuhz7z9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6uzxk0v83p0801rcwnexdu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6v1m1xv07w09870ah3njy1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6v3bb2v7xo085090blubyw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6v4szov55u0871qmqz3v8n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6v5ilsv8hk0850rb5sgh6o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6v6g6kvdw007552x6mb0po.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6vgdmivcvb08018fra5lnv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6vifjlv55z0987un6y4zdo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6vqarjv7yo0987q4b1btk1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6vrs1ov8cr098788h8gs6j.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6vta3kvazg0817qbeppjtm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6vucxvvlda0755j7msqnya.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6vvb8svhed0801jjcquh5e.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6vvxsev9y30987kespucdg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju15jr8jz8sb0855ukmkswkz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju15l5ubz9yh0855b3ivdpse.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju15mhjczc8z0801kit5c6di.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju15ptjtppz40988odsm9azx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju15wdt3zla10801odjiw7sy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju160wshltz10993i1gmqxbe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju16ach3m1da0993r1dq3sn2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju16b6ynq8e40988m8vx0xnj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju16d65tzw9d0799ouslsw25.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju16fpvhzypl0799p9phnlx6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju16jgnyzp970878melv7r25.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju16whaj0e7n0855q7b6cjkm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju171py4qiha0835u8sl59ds.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju175facms5f0993a5tjikvt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju17bz250pgd0799u1hqkj5u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju17g6ykn1cs0993dww6qdi8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju17hw9hr9c5098800fu4u8e.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju17otoe119u0799nqcbl8n1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju17r8il13910799dr2wme2e.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju17v6ih0u7808783zcbg1jy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6w733bveoz0817e600tw72.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju17x0j4nfc10993y31pvlgs.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju17z0qongpa0993de4boim4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1819curo000988pd5xcqme.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju183od81ff608017ekzif89.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1871y11d6r0799k6cw4yze.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju18849rrsgr0988p90hkygb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju18gzrq18zw0878wbf4ftw6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju18ibp219ub08783i6o98g7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju18kevfrojc0835bn90f1in.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1alwgo30z60855fm3y23sm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1amqw6p8pw0993d9gc5crl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1aqqv02qwz0878a5cyhr67.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1ats0y372e08011yazcsxm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1b0y2e396p08558ois175d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1b3zgj3d8e0801kpolea6c.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1b75x63ddl0799sdp0i2j3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1bhnfitmge0835ynls0l6b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1bm8063nmh07996rsjjemq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1brhsj3rls0855a1vgdlen.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1c0qb4tzi308355wtsnp0y.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1c3218411b08014g9f6gig.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1c4fcu40hl07992b8gj0c8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1c6yfz42md08550zgoz3pw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1c8ffau5770835g0g343o8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cbokpuiw70988j4lq1fpi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cdxvz48hw0801i0fjwcnk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cfhyg48bb0799cl5pr2jh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cj3f0qi5n0993ut8f49rj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cnnziug1l0835yh4ropyg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cqc7n4gpy0855jt246k68.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1csmlc4ht10799b8ymmghg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cu1u2474n0878tt7v4tdr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6wi3akvn8r0801px8eligc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6wjm81vgsc0987enk9n3pr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6wll7wvo3y08502pagos8m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cvkfwqrec0993wbp1jlzm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1cyjb5qtie0993njqne9m3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1d31sp4d4k0878r3fr02ul.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1d50a94qf50855wsowacrc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1d96gsv62d09881b3wecw2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1ddr6p4k5z08780uuuzit2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1dfeupuzlw0835gnxip369.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1dg44i4z3w0801nyz4p6zf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1dhfok4mhe0878jlgrag0h.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1dia8hvc6v098827mgffnm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1djtprvd7b0988thwwrg09.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1dnz61vfp40988e78bkjga.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1dq3x1vgx109889c7wyirg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1drnhbrb9409935wi7vkhg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1efbr0rqxz09931z0lf4vf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1egh885m1l0855ci1lt37c.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1egx9pvz2n0988eoy8jp23.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1ejj7dvqfa0835ra184v5m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1erep75us208553i4ofwwe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1euant5l960878iqj5vvto.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1euuc65wm00799m4sjdnnn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1ewnoh5z030855vpex9uzt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1expq45zst0855rjqwwj4m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1f15k3w4ct0835cmde6ypo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1f320ewfyu0988ndz6blh5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1f5x1164xv08555654c24r.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1f79yhsb5w0993txub59ol.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1f8w0t65en0799m9oacq0q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1fb9236a110801yvg0fwju.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1ffnjn6ctm08015perkg37.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1fj6axwfp30835ukhuzhw9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1fjsb4sipq09931lvd8e41.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1fm3id6gl50801r3fok20c.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1fmsyf6gxb0801cimx2gle.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1fr4etsmrr09933u4t4aql.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1ftaji6isw0855108yqcse.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1fuoa4wmc50835qfd11sp9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1fyb1d69et0878muzdak9u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1g20bdwq6u0835e16xugcd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1g4nsb6ngy0799l4ezm8ab.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1gghyjwxt80835vx0wgxw0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1gi7jlwyld0835cdf6g6qz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1gkndf6yi10801o1qnje19.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1gv7106qd008784gk603mg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1h5w4wxajx0835mc954kxy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1h89h6xbnx08352k2790o9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1haab178i70799tk9z8y8x.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1hhj6mxfp90835n3wofrap.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1hirfi7ekp0855q0vgm9qq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1hmff8tkp809931jps6fbr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1hp9i2xu8e0988u2dazk7m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1hs0za7jha0855vj0mdrjt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju1hyolc7aqu0878rrkfn1lr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hdr06v2bq0799mbm3bks1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hewssldzx0835ep795xu0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hfqnmhisa0993gpleeldd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hgsptlfam0835o3b59h1o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hjrqcvi2j0801bx1i6gxg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hlm19vjjf0801o69qnber.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hos57llxm08359g92p6jj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hqt33lmra0988fr5ijv8j.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2htabevq9108015qjei0x7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hugv9vget0799hhk7ksvg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hw5gjlr5h0988so2qqres.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2hx006vidl0799igm81vmh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2i03ptvkiu0799xbbd4det.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2i3hzclw3o0988rrgh911i.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2i6acqvo6l0799u20fift8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2i8br1vqtd08784u6vmcjk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2iatlki5u309930zmgkv6h.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2igw4gvxds0878808qj398.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ij9uiic2l09933ljiv6gm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2lberzkdzm09938cl40pog.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2lcyfgkf5809932fn9gucn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2lejzcy4pc0878c9rlonot.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2lyynuymli0855g7fxgbhe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2lz8vqktne0993fuym6drw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2m56cryvqd0801gtn2yp8t.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2m71z2ywwv080131bcrsd3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ma647l0nj0993ot4deq2q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2mfjndoz700988b9lc3zeq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2mh8t6p07008350e01tx2a.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2nbdpmlmcj0993s1cht0dz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2nd7l7z98o0799gfjvyfmw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2nfnvxzdkd0878399axlco.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2nguelpmlj0835rojdn097.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2nnqrqzp580855z8mhzgd6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2np2k9zi3v079992ypxqkn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2nqapmzvk20801f9us40dx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2nsmwjlzyl0993jl80chvz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ntxtdzlvu0799xl3j9pan.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2nyc5f02m40801ojqbtiea.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2oi8sq0i2y0801mektzvw8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6wn57mvooj0850rp78hhy7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2okvco06xc0799kxe5n1qh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2omjpeqj5a0988pjdlb8l1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2oo0wh0bqy0878biujeyhe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2oq5570avm079959o20op1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2osuru0ki00855txo0n3uu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2otvvv0l7z0855x7we8cb0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ouil2mssu0993hvxsed6d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2p0eveqtdc0835gpi3p93i.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2p4ddkmzxj0993p94o62av.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2p91qir00k08350ddfif0w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2pag1f0s4r0878h52uq83s.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2phaksnahz0993yxogjcpv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2pjb9v0ywn0878j5g5n69j.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2pkwt3r8b90988v2ywq1px.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2pmhtr17a00855cvpelzb0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qdj95ru8g09886gfi9rsz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qfie4rvz508357kad9z5o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qh5le1ock0878oahaql7d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qn2fzs1vy0988l243cvzy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qozsk20cq0855ugrg3cri.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qqn5ys4uo0988ewrt2ip2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qs32r1vys07999conmbvx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qtee81yd708787bsjr75d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qu37qobl50993aw7ghcfq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qvuj1s9ok0835tp2k4ozh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qxxko229x08786gvxxhur.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2qz06823a40878ojcz9ccx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2r11x7sdgx0988o8ule0wl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2r2obh2bjm08553kng0rh7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2r6mt2om21099352pny5gw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2r7h21sj9608354gzks3ae.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2r91dg2k090801bh0xzbxk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2raxlosl630988jdbfy9b0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rga4psq9n09881z519xx0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ricdv2iys0878sv1adh0u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rkjfwoxys0993x768l1j2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rlqdnoz9k0993cpjae3x0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rmd2rsw9g09888hh1efu0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rn0hasxri0835nfy3buay.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rnkt22xep0801as160g9t.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ro5jqsy680988pi6qsujw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rpa30t07b0835im0erql0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rqo702wpx0855fn7d5cxh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rxm8rpbaf0993o3qr2oph.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rz4k434s70855wwx3ddtx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2rzpsmtb0f0835jabkbao1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2s16zp317h0799gr67jqc2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2s2527pfyr0993l3h1149a.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2s9g11pnra0993gn4eh793.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2saez63gxl08559ucjq3kt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6wt9jvvn500871hjn3t3g0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2sevf53lkx08558h5bpaig.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2sggy13na70855tbeoqgha.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2spdagu1l50835da1f46fr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2srvy5440s0801y1ba9akr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2sszfq3uye0878sucelzk2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2suk42469908015ngmq6f2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2sxf3iqbpv09937iksn8ep.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2syxa93yw40799x2iuwabz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2t16vuucaq0835xcpsivn2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2t2ivz43i10878zeg8r1br.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2t3ibkuecr0835o7si16zv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2t62nq45jl0799odpufwx6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2t9tdwuk700835kv0ljmtl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ti1du4idn0878giuozonw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2tjrog4jy30878pawyazqc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2top2ruxxy0988p1svx36g.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2tpfa5uyx408359datxqqj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2tqfgw4oat0799rn0g5b2z.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2trbpkv0c00988hxla5dzz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2trtjf4qjd0878a2zle9v9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2tvrvm53ws0801a0jfjdxg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2txjfzv60w098839dcimys.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2tzypl4wss0799ow05oxb9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2u2b9o4zvp08788qb9nqxj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2u4pymvc720988wsxrmi84.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2u73dj53oz0878486k8k4b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ueb6j5ado0878vf5md13o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ulk385h170799rlklxob0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2uokeg5jm20799xwgsyz89.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2upu4evw7g08358guwozxv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2urqpwvxw70835rvndvtsi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2uwz9f5yf1085506cfamfx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2uy8ox62jo0801g88hh42z.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2uzabhs6er0993x3aaf87p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2wtwj87kys0855kx6mddzw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2wve9v7esz0878mxsdcy04.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2wx0gh7fpz0878wwyd9ep8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2wxv0hxs2f09884w48v8fi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2wzu8wxtgu09880ku9x1pg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2x7vw87mu30878hye2ca0m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xa3i4y0160988i679zsqd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xbk0080y80801eghyddi2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xd75m82720801q4s4ik3n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xf8e5y2wm08359vcgk09b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xjz2ju8pe0993ysv9wg17.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xlcqxy9c60988vjacdznb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xs6na81t20878pt6nkfip.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xwm1s84l50799i60mq0pu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6wuojavt740818b5qcv3iw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2xyd9vyi7m098831qcucse.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2y0z6g87p10878fpk5d3rq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2y26c588bo07993ksd8eoz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2y40d8ulqo0993q0adtgtb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2y5zas8m7f0801d34g5owq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2y8s56ymqr083541ggdsml.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2yb31a8e8u0878wdashg7o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ycp1u8g2r0799jslnp7cz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2yg5ht8i4p087800js8hp4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2yi9tz8vky0801yqip0xyl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2yljr0yzhw0988ecf271ly.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2yo1j1v0qz09934o0e683p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2ysg748ru80878sp6j0gm0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2yv4imv6cz099314jveiib.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2yw4s7z7p20988lmf2gdgd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2yyhsp933j0855hp32e012.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2z1nxlzaj40835wj81s1iy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2z2x3nvd3c099350zgty7w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2z45kuzf6d0988nz2c819m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2z6ez69g4u0801qwt088lw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2z9vlp9j0w0801oag91sy9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zblxw9848087853csbrx1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zdhsczmn50988z64qwg2q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zdvjn9h7r08553cp4eed5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zgbj9zmrw0835nnlzxj4c.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zi4l09f5807991s8do2b2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zjcvj9qma0801dk71hhi0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zkpdl9h7t0799ix60teqg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zm0axztpe0988r8s9twjr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zo0fwzv580988qlijd2xa.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zp89k9q1g0855k1x0f1xa.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zpw4q9vzr0801p0lysjdl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zr3c3vwb00993jn06bbaz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zrojo9kcd0878ld2epejq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zwg05a0oy0801yr73ig7g.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zxja9w1eh09933609ho9z.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju2zy1e49pqk0878t6ncqn12.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju300m3s04fg0988uzupuf7z.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju302fqq9spc0878rrygyzzz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju303j5r062k098835zxfds5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30525w04r10835ygp257sb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju306x7w05nb0835cunv799x.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30ajhw09sx0988qyahx9s8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30bmab08bi0835mvlr6e0r.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30df2j09dd08351ayx2t6w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30ftgja7170855xl9bkdm0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30gxjq0djk0988jytm49rs.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30ia8da2bq0799klnehml2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30j1rgadut0801vuyrsnt8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30k2z40ds308353kdew70n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30lncba3ny0878jwnous8n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6x0yqbvxqt0755dhxislgb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30mm25a53s0799qa5wiqe8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30nyxe0gfb0835p256yoju.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30ov1oah920801mi8thuyg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30qbm1ad3x0855znuhpz9u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30u1hbakn808019g15nb8b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30xqmh0ni00835ix3batv1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju30ywtc0oar0835bp2en7ec.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju310f6val1v0855xo8tc3gu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3128yi0rpu0988o4oo5n8n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju31rb7vb6110801p9rhacuw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju31t8xd17bk0835rnb893jk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju31ugmfb3dz0855xtqshki6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju31w6goazci0799n014ly1q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju31y80qbawn0801twwm2l5s.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju320gyvbch60801v2amdi2g.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju323ypb1fbb0988gx5rzudb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju324q101fhe08350wae9cif.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju326h4v1gxw08352px40p7r.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3280wv1ir009882jze27tc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32a52lb9rc0799xi40qs00.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32csyfblyh080170aa3x5p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32fhnhbds40799broyoptc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32gzs6xo8x0993r8tedbpb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32jcdabepz0878d0cznmfe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32l161bi1v07990vm376in.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32phw2bv130801yj7bkouq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32pzh9bpw10855q4vaxfhe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32qr9tbvsj08013pkpjenq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32srle1xfq083575i3fl75.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32upim1z7u0988l883nqp6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju32zhbnc1oy0801iyv1ix6p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju330ofbc2l30801th5g3hw6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33231uy4gi0993qc7b1jch.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju334jzo261t0835yqudnfs1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju336l68y7if0993wf092166.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3381d8bz3h07991xtl7ra0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33belnbyhm0878yxl42233.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33eqwbcch208012jikwdky.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33jon3ygbj0993pu22a4k6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33mirdc8mj0799k33wzoes.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33o12x2jm50988944mxq0v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33qpdvc9g0087825jhf3s9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33w4sdcivk0855x879zht7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33x0f22peh0988g0ln7w5v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33yemn2qb20988wfjxximx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju33za6l2qy70988jhrlp2ev.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34aozyyy830993bn16u32n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34c1xfyz920993itxkkfad.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34ds2531520988qjpqt6e3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34eqjpcpm508788b3lhp97.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34fojcctcf0799ebolbvkn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34i3qvcyog0855qiejxx5w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34m7h536wq0988xz7gx79v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34o6dbd2lo0855aqlcy1hs.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34ouumcznz07996gg1xq7v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34repocy5208780gswillm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34sh43d8zm08019xbwhc0o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34uhepd3dd0799hs8782ad.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34xspwzenf0993cyzajv9n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34ymm8d6700799uop0cw33.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju34zivp3fq80988opxbaqyn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3518w2d838079939fqztbc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3521y5d5mq0878t3ezsu4p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju353d1eda8c07992afde611.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35740hzm0g0993zl5ic246.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju357rxxdaz30878y2esjpjt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju358pwtdby20878cg7nm0np.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35a77vdj4n08556jj2lgmc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35atpxdjot0855q46aqrd0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35c4wzdhow0799h6eq4sgs.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35eg0tdmjt085525sb4bua.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35fxqyzt5p0993vusm54qz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35i2e63uxr0835h7zgkg9k.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35k2fr3vc50988c85qkrwg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35ldepdtlm0801yv79y8vu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35mdz73x890835eynq1h9v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju35oyvd3y850988km12hdz1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3tp94kfstl08181awh6z49.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3tsh4lfsok0987w6x3a0v1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3ttznuftyf09875t11850w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3tvffffx5f0818t5ov22al.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3tx1qyg0c907552fglumhc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3u1c8tfyqx08503iedc3mx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3u39fog1bo0871lxjrabks.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3u4lxmg59o0755rz42b9en.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3u815rg4ek0850vvhtcvcm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3ua8u0g9rg0801uayhdxhu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3uhb79gcgr0871orbrbi3x.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3ul8dogf1z09872y2ecowp.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3umoh1geet0817cmpef5am.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3uwz6ogsp10801h2r3bj5l.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3uz4o6gr9z0850lhxyxvsj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3v0fl3gwce0755qkjhzmd4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3v11mrgwwb0755u242ygye.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3v3ac9gyz30755hfqwyp1i.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3v56bwgy8v0871w14pz8fx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3v664kh0px0818y4y7wolf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3v72v5h1qz0818fggilwtq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3wstckialg0871xs0vevsj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3x2s11ibzi0817kk284k0j.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3x4blzieu30850x10uuvbm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3x5u2tiihx0818914gzxy1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3x7xsaijq80818f0psavav.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6x35ervu2808015c7eoqe4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3x9lttikfb0818a0g104zn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xeexgii1j0817zs68tb4g.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xga12iixg0817dijbvjxw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xhpvvimda0987ygrpzni2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xiic0ilzp0850lusrb42j.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xjqtpikx50817tppy6g84.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xl264ingx0850rcf0rshj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xtufwiv9c0818djsc4cqd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xuj20ivgp0818mij8bjrd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xvoo2iqlc0817eku2r3wl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xwpgviwlx0871rwm15q7v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3xzvnzj0hd0755xprz39nj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3y0pjrj1c30755nxekxccj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3y21quj0ir0818kgjagr15.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3y54kwj3nr0801biidlb4e.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3y79ofj3va0871uqfb1mzo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3y9difj6th0801kd1rqm3w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3ya7goj6at0818v2l5ay7f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3yb47cj1xq0817zfotbni4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3yht87j83m08507yk1u1fg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju3ykamdj9u208503pygyuc8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40jl7skiuo0817p0smlgg8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40m0rjkpw80871z6n6yg1u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40poe4kt9s0755f9cnm3h5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40r6jrksyk0871wg98zgho.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40sdwukv3k0755y99ug1k8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40taxlkrho0987smigg0x0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40u30gkuzc0871rq7t666d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40w3hbkwpn08015rbs3wko.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju40wto5kxwi0755it190f2k.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju410dnfl0960755y8lu8d79.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju412uwlkva50850d1ps1ww7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju414lf2l1lt0801rl3hjllj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju418rckl3ur08012psrx1r1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju41kd7yl4nm0850gil5qqwh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju41lojblbs307555jdci937.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju41nz76lcxu0755cya2qefx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju41p90plcsx08018cnzpndc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju41r6v2lcww0871ps8k8pf5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju41s6nbleqy0755e2mslg0b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju41z76wlgbz0801qdetlvby.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju422cm8lfxn0818ojicxejb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju424hy5lckr085073fva1ok.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju426tomlhll0818fc0i7nvh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju428k5fldt108177s6g6f45.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42dwedlmk60871jbgu4ehi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42g865lorv07552ytz6xxa.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42m60jlpcm08186kqppzqv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42nm68lpyo0818xvvqmupq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42py9mlqyd0818u3d1d7ga.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6x4t13vyw60755gtcf9ndu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6x97w4vwua0850x0997r0a.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42qet0lsq90871e50xbnuv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42romflni20817etb9a0fl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42tauqlo5p08171l3cuo4b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42u5bjlvi10801dc13sskp.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42wamblrqn098798r2yyok.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju42xpi8lw4w0871ve317a1p.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju430pm2lz0y0755jkhcc3d1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju439oazm2fu0871ma0vvrft.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43b8daly4408170e5ev06g.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43c92lm5cj0755lorsorfg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43eigtm6ev0801mv0m96t1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43gfosm63n08714rpih8pe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43h43am1dy08176gwfhmnt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43in5fm22c08175rxziqrk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43jcqim2cp08172dvjvyui.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43kj2pm34f0850l28ahpni.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43lcnum9y10755bjs7z87f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43mkj9m8wb0871qiadahub.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju43o6n7m9nk087191ijwqq9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45jpvfn6c809873pv1i34s.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45lbgznahl08180xz1h7u6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45n0oxn5vu08500yfrt9jn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45ofd9ne1j0801ri8dup7t.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45pm27n80u08174kyow1gj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45qbf3n9sa0987oonbkly9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45rj7ln8980850a7821fov.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45t5ddnbio0987qtqzx762.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45ty6zn9oz0850qy4qnck1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju45v0pungu40871acnwtmu5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5b9oyda4yr0850g9viziyv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5bbtwsa8cl0987wgfsqpao.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5bdwa3aatx0818b79i18zf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5bf6hxa6m50817rbwettgu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5bhv81abur0850ean02atv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5bj926aiec07559rshy4wa.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5bmhdcafs909878qfzrqzi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5boicjagt20871b1fotkh4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5buy2bal250818ipl6fqwv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5bwhapakm90987c1v4z46a.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5bycdkalkb09875f7bfrvx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5c5xc7algd0817pb1ej5yo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5c7oijaqmq09878qwgqv8n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ca9hcatkc0801jzwe7tfx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ccpvqash50850kb4bs22k.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5cetivauok0987ok3e5bre.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5chrxxawka0871qcj171yz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5cjh3xattc0817j2vbulzi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5cky5xb0ay0801oxet697t.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5clr68b48r0755cmuvponm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5cu8qkb84x08186jwo8yin.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6xa0qmvzun0818xjukgncj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6xifswvwbo0987nibtdr50.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6xlygpw7bs0818n691jsq4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ddda9bkkt0850enzwatb1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5eftctcdbj08712gdp989f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ekty5ckzf07550c9u3ckk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5enq1tcn1i0755hnkon787.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5eq8c8ck690850vix98hv3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5es375cnzy0801nkq35ffs.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ew4h9cqaf0818rrczkmqh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5eyfe9cpk90987laa7tsl3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5f0dezct4q08183ydw11dx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5f26ebcuai0818xlwh6116.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5f8hxdcxxn08188obby0ea.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5fb86jd1jp0755b1ukbhq5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5fi0yxd3ei0801v7u0yudn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5fs6j6d8350801vglraq4u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5ft6mcd5q40987rhjgbrr6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5fu081d8gc0818l3yylujk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5fw37edaae0801vkwvocn7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5fydrud94708507vo6oy21.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5g163vd6mt0817uccuga6u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5gucasds9d0801019axylx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju5h57xedz5h0755mjpc8694.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6z1bzbwfq50817b2alatvr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6z2616wqbk07555bvnuyr1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6z600qwh4z081700qimgl9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6z7e4bwgdd0987ogkzq9kt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju6z9a9kwsl007552s49rx6i.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju76erapykj30871x5eaxh4q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju76l27oyrw907551ri2a7fl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju76lsehyia10987u54vn8rb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju76o55nymqd0871h31sph9w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77196iyshb0850ycbto50a.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju772304yw5t0818vbw8kkjf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju773hsyyosz0817pk1e7sjq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju774fmayxif0818u2g79usw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7787c5yy3l080159mwqsnj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77afzlz3kp07550x5nafzs.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77b3wyz4160755qis4ljsb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77bvg0yv4r0987yh60xmjo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77g99iyxc00817zqi2ppor.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77idwfz36d0871tzfzz51i.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77j66ez52p08019xygi0co.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77k828z46w0871r0avuoo9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77q10sz9ug0801449wu1nu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77re6fz5bb0817vp9redjg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77t0razbvm080106o56289.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77u1sjz77b0817ft44r3fk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju77vvcwzcm50850lzoykuva.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju783tmkzkqu081803g7q5vk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju784jpdzeae0987q5ypq883.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju785htizjzo08017tvlhtg4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju787jnjzjuj0871p94nck9g.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7adqyj1jcx08712r1ro5gx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ae7bq1f820987toc8si1d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7aez2x1jtj0871ztezs3oi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7afqon1ip40850ue2308b6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7agj961l2r0818z29iq8yn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ahtkb1jr90801jck4kbds.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7aifyo1p3n07552nxjx51f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ajnbo1gvm098749rdouk0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7aklv31h4309871m29l4e7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7alcgr1lsr0871riqk84z7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7amjna1ly40871ugiokehb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ap09p1kz10850ldccjebj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7apr0c1qqm0755s7msqot4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7aqkue1i2k09879uzcpt8r.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7arvfe1ldu0850erdmphgj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7atnm31if40817pqclnjer.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7avvi51iox0817ym55y6tt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7awzmu1ncs0871hziy65zx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7azuu31mia0801pf9ib5ed.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7b10ce1mnm08011c5bwyr4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7b1ygu1msd0801hywhy0mc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7b2l561oas0871decgslaf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7b3f5h1sm40755i572jden.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7b4mtw1n9n080186209f3d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7b5afm1nfw0801xqm8bf8q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7b9vcs1luz0987ta60j1dy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7bb3ss1uoo0755pmhyco7t.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7bc95p1mdm0817yqj5jc6j.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7bd1qu1mx409877xjxibox.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7bduyq1rjf08719giru9ho.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7bf1lp1shi081835vs84lc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7bfx651qr80801cs7epotb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7bgnvb1sf808717qa799ir.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7bmi1v1pnj0987pa52jjok.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7cl8zm1xcu0817ado0jpas.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7cp6dw244p0818gncdol4m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7cq6su27qv075574dir0r3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7crgxa28550755wbsgqkel.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7csvlb22fr0850lvm45n3x.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ctvqn25dy08186g442m1r.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7cue9b232j0801qdzk1ykj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7cufm7298k0755j09uf3of.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d1tvt25bu08019dvw3uff.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d2q1k27nf08715zshsckt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d3oc82cho0755dajlwldz.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d4jk723eu0817bqz2n39m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d5m0p23kn09871rk7pu3v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d6ux323ze0987xos3srkx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d7aut2a2p0818z4uxc6cd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d7tly27h408016fyp5nr7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d8m3b2e210755l8fj1yph.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7d9seq29zd0871nzl2uu5m.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dbppn28nx085097654msi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7da88w2eod0755wejzynvt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7db7lp2f400755tntd1ohf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dda8w2br20818zhsuz8s7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ddtz729960801uazp1knc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7deifq2fzn0755lc8idyh8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dff9529h208503w60lbil.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dglf226g50987ohbthl19.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dhpsc2dnn0818025m6857.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dizi82h2i0755doucgnt3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dlk532dsh0871zvr6qz0r.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dmlgf2ebw0871ieqas5fh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dn24o296i09871qfxb8s2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7do8c72dbo0801vxfzxdc4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dp3dw2k4n0755zhe003ad.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dqcwi2dz00850gcmr2ert.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7druhp2gp308715i6km7be.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dsrtb2f8i085064kwugfk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dtb1e2j0t0818deq51ib3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dubap2g0w0801fgl42mg9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dvl5m2n4t0755hlnnjjet.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dwe282dc309876rco45ts.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dxffn2eam0817qxosfwch.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dymur2od30755eg8yv2ht.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7dz5yy2i7z0801ausi7rna.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7eea9b2m0z0801ynqv1fqu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ea4om2l910801bohqjccy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ebe962hr409872ovibahw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ecl9i2i060987xawjp4l0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7efffp2ivf0817etg3jehl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ehljc2or70871261br8ai.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ejm2l2ncl0801wq6y84nw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ekbo32pft0871fv7kzwb9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7el6xv2k520817qxx9wdr5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7emdni2py40871ivhxjtut.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7eotqi2qea0871y8yc7tqh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7epwj82koz098713apjnzo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7er4kc2opa0801anuxc0eb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7es23b2vcp0755gpbm9s7v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7et17a2vjk0755e743npl1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7etr3y2p4t0801cdzjj8ab.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7eueum2oqn0850rodmx8zo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ev2b12owa08500bpfpwyw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7evxt12m730987rxivne3x.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ey10f2rvf0871bwbi9x82.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ez7r22qbc08015xfoz2wb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ezs7g2mxm098787atbran.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7f0ec32txj08184asb8w5f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7f4sc62xqj075597xpmuoy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7f5ghb2r5s0801chwkxxh9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7f6cqy2ur20818t1saazbm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7f900s2o0k08175gl1giid.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7f9umg2olj0987fj5y285w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fazv92ywx0755xov2erga.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fbndk2sl608015ravktum.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fcgbe2z3p07550vaflqdb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fd6yt2p740987wkr8exo1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fen322ou10817ziqkob4k.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7ff97z2ow40817u2r83my5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7flevb2wii08188otgs9p2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fmvpk2q170987v6i3ola8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fnfv02tt90801djnix9m8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fob3x301u0755x985pmmq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fpfzq2wyf0818xxd1oziv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7fq7mm2pw508176uk5ugtx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7frtqu2xa20818wq8r9fzf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju7g7ba42z310987bqzbi2bq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83h9ysjwe808716nt35oah.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83ipu3jwpx0801z5pvguf8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83k8fyjsxr0817d6nxs6r4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83kxitjv340987z09m0ezy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83mki1jv5w0817kubxm31r.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83nwu1jxte0987h1krpfmv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83qd0yjyht0817ktkfl268.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83rcnzkbsj0755x5anfrcg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83syhdk6gs0801rf1rekdl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83u9ftk3ni0987qnhlcinv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83yddek68q0850d2x7zfkm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8402x1kcy70801t6kz6bdi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8418jhkf7d0818ga2v0xq0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83vvmik9wa08710yeh7cuk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju83wwn1k55e0850kw6i2d81.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8432cmkgq90871cxe4iptl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju843yjskhq30818qre4rwm2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju846ec0kj7z08012o10klrb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju847pxykriq0755268ktrk2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju849c23kgnk0817cgv2hw1e.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju84aoa3ktwn0755pfl4gfwd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju84dsvaklpx098750hp83x4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju84ffdzkrjn08183jh1fxmb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju84gpefknwm098714oq8q61.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju84hibuktj80871u519o71q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju84ih17kp5l09876bkooocl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju84jdl9kv0i0871eog9b3i9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju84kplnl1y30755ropua1b0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8567gdlcbq0801dwwyo2jt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju857ad0l88m0817qx4cwxnf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju858eswlepn0871pzvdrhj1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85a8h8llwm07559wxg4t5w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85bf1algsq0871y9gtlq97.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85c2d4ln1b0755zz1z3onx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85citjlnfm0755i4rk5tqj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85dx63lic408017f0l0400.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85fc11ljr40818edpb0inh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85hguellg50818kwu3s8d1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85ia1slh220987y7c20sm2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85je7vlht70817c9jcjwi4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85l4yjlops0801fvmnwptf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85mpuglq8k0818d2it6hzb.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85nr8elly209872w9n5m0s.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85omszllp30850b6rm9mi3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85plp7lmkw0850rx42jdpf.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85qefyln6v0850szeb9byi.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju85rkbnlo1c08503uxcpax1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87kbcen2av0987usezo8kn.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87li0zn3yb0817kbwgjiz8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87mrypnb1e0818scv1mxxg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87nkyrnb970801q84m47yt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87ox0kncom0801b98hqnd2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87q6yoneim0871dl4phvkd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87r56lnkyp0755hz30leew.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87tyddnnad0755bj0wxahe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87vqa0ndwg0850onjdz7ol.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87xn2snfmv0987sc3d9xnq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87z6o6nh73085045bzsx6o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju87zv8lni0o0850hbbecbq6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8828oxnool0801qno9luhr.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju884985nlmx0817vzpax3y4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju885ikhnmkn09878s2lqtuh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju886ryxnsl50801r93jai7q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju887ftknop008177nnjt46y.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju888fr7nveu0818r9uwtiit.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88aq6vo1ij0755c2ey7z7n.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88cddensj00987788yotmg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88evxanv9r08176zkeovec.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88fpm4o0tl0871w1i6a4ds.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88gx09o2vk0818610zody3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88itqbny720987hxizbj5y.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88k75inzyb0850ccv5x3vk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88l66no10s0850rsda7ej1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88msmoo3470817m441j4sg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88nroho44508500129f1nh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88oh0po9gq0801nge4tgr1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88q6h6obpd0871ckmiabbo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88rl5eo94l0850kf5wtrm1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88t4fvokxf07558ymyh281.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88trl3ogi208716qvti51b.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88v2f9oi8w0871hx9auh01.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88vx2uoocy075531lc63n3.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88y1mwoln50871emyfny1g.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju88z8bson4h0871nnd7fdxo.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju890guyoiti098753yg6cdu.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8914beokbf0850isxpocrk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju892fesoq2g0801n0e0jyia.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju893jmdompz0817xn3g1w4h.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju89y9h0puti0818i5yw29e6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju89z6pqpqfx0817mfv8ixjc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8a1jtvpt9m081712iwkca7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8a2itsq4dv0755ntlovpxe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8a3nhbpwnb0850d37fo2na.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8a56vxpy780850r45yu4wk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8a84g0q76m0818hwiggkod.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8abobpqbir08189u01huru.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8adb60qbiu080188mxpf8d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8aeei7q8k308173n9y4klv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8aj01yqeqm0850lhdz3xdw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8alhigqn2h0801zksudldd.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8amfdtqi4x09871tygrgqe.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8ando2qqdo0818ck7i1be1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8apjewqrk00801k5d71gky.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8aqq8uqmoq0987hphto9gg.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8arof2qpf20850ifr1bnqj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8ashhnquqr0801rwduzt7d.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8at3s1qqqx0850hcq8nmnq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8auylgqx0z0871u4o4db7o.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8aw9n1qyg10801jkjlmors.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8axq24r4an0755yhv9d4ly.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8ayeq7r1fb0818z1junacy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8azmhcr66e0755t61atz72.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b0jr0r2oi0801jiquetd5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b1v3br45u087189kku66u.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b2rmgr52s0801p54eyflx.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b3ka8r64u0801fh18hk7l.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b4ja9r2s808509d45ma86.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b542nr81x0871uxnkm9ih.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b5p40r2c60987ofa0mu03.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b6rp0r5st0850184f79xt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b7aqtr4a00987coba14b7.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8b8yair65w09878pyqtr96.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bafgqrf4x0818twisk3ea.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bbznkrf5g0871jncffynk.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bff9nrfi10850fmfzbf8v.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bgdmqrksy0801tozdmraa.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bh8surexp0987o5pzklk1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bi8q7rlmn0871abc5ch8k.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bj2ssrmlm0871gc2ug2rs.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bk8oirjhw0817hgkua2w8.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bljw9rqk20801kr54akrl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bm24yrrdp081829mbo8ic.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bn7m2rmm70817hgxpb1uq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bop5jrsid08716i24fqda.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bpctzrqkr0850zeldv9kt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bqxxurs6i0850mu7mtef9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8brv16rx7f0818uf5n89pv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bssulrrcy0987h1vq5060.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8buos5rz9b08715lfr0f4f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bw697rwg308177tg8huas.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bysfgrzkl081786jwac09.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8bzzy2s66m08016z6mouqt.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c1a0ws7o208181c6lbsom.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c2rqzs5t80850d0zky5dy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c3xs7sauj0801ieyzezr5.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c5223s8j80850b4kealt4.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c5mxls96t0850wvkvsity.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c5zcbsdfz0801o5t6jag1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c6hnxsdvr0801wn0vrsa6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c82iosagu0817l74s4m5g.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8c9akjsdjj0850s67uzlxq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8ca4geseia0850i2ru11hw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8cattbsivm0818p446wgel.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8cbsyssiqj0871gr4jedjp.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8cdeazsm8h0801jxifmzur.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8ceacrsqkr0755hdz145es.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8cgi2kspp308011nxdtjp6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8chdlqsu620755azjty1tj.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8chxndsre008015uisl4si.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8cj10qsrau0871o2dr6ai1.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8clorgsuwn08714toqb7v6.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8cwy02t9eq08185qn12c02.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8czvnztbf40871b4m7t78w.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8d2q30tfhs0801n7lx77xl.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8d4jgatgpj0871q2ophhkm.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8dic9mtppa0987swn23wbc.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8djdqztu6408506pzhlo18.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8dk7eztzup08182yxko5zh.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8dm2cau2km0818jsv9eeq2.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8dn0c3u2v50801k8rvq02f.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8doa16u5gh0818w1ywda3q.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8dpa89u6l80818dj6lldh9.jpg  \n",
            "  inflating: Kvasir-SEG/images/cju8dqkrqu83i0818ev74qpxq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzkmjy8evns070165gf9dmq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzkpsbjdsjq07211dfi4sru.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzurzvohqnr0794es1itzek.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzl833ndne80838pzuq6ila.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzlw7f9faqr070129au64sq.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyztzaqtrv430848l8xgcerw.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzu3reghjya0794w7pwoi50.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzu9th0qt4r0a46pyl4zik0.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzufihqquiw0a46jatrbwln.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzuio1qgh040763k56deohv.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjyzul1qggwwj07216mhiv5sy.jpg  \n",
            "  inflating: Kvasir-SEG/images/cjz14qsk2wci60794un9ozwmw.jpg  \n",
            "   creating: Kvasir-SEG/masks/\n",
            "  inflating: Kvasir-SEG/masks/ck2bxiswtxuw80838qkisqjwz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/ck2bxknhjvs1x0794iogrq49k.jpg  \n",
            "  inflating: Kvasir-SEG/masks/ck2bxlujamu330725szlc2jdu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/ck2bxpfgxu2mk0748gsh7xelu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/ck2bxqz3evvg20794iiyv5v2m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/ck2bxskgxxzfv08386xkqtqdy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/ck2bxw18mmz1k0725litqq2mc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/ck2395w2mb4vu07480otsu6tw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/ck2da7fwcjfis07218r1rvm95.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzurzvohqnr0794es1itzek.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5hi52odyf90817prvcwg45.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5hjxaae3i40850h5z2laf5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5hl8nee8a40755fm8qjj0o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5hqz50e7o90850e0prlpa0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ht88gedbu0755xrcuddcx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5huurrecm70801y680y13m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5hwonqedw10801vsd3w6kk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5hyi9yegob0755ho3do8en.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5i39mreass0817au8p22zy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5i5oh2efg60987ez6cpf72.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5jx7jzf7c90871c2i9aiov.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5jz5fff8c50871hbe6108f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5k3j3uf6de0817hszzfr7n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5k503sfa5f0871lx0rpu5y.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5k7r0yf98c09878csbxb4d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5klveuff6w0871wbibgh3m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6xmqd9w0250817l5kxfnsk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5knbbqfipk080128cggukq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5kre09fhka0850h7b1898j.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ktjwofed70817eg58ef7u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5nxkujgscq0817l9gss626.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5nyu31gv8e0871zpk74a2n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5o1vu9gz8a0818eyy92bns.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzjzssvd8pq0838f4nolj5l.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5o4pk9h0720755lgp9jq8m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5tenjojp1j0755ms4949h2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5tgbzhjllu08174ca41eus.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5thdbrjp1108715xdfx356.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5u4pywk81x0817vn9pe14z.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5u6wf0kh1t0755bg1ssixv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5u8gz4kj5b07552e2wpkwp.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5udcufki0s09874ll1dbr5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ufn3skquf0818dhapnhba.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5uget8krjy0818kvywd0zu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5uhrdwkmsu0817ervv91l8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ukkg6kv7u08011x2b6zl5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5uxjnol2r509871qv2yeia.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5uzmaol56l0817flxh4w9p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5v8pgplg6k0755rvi2t63h.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5vbo6jldrt0871jf6f1700.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5vcmrqla7i0817x4sp4pqw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5vgawslbe30987ndeepc1b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5vi4nxlc530817uoqm2m7a.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5von04litr08718j8po40a.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5vutu7ll8w0871dfp92n9p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5vwbr4lhqn0987a1pji0ux.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5vxuc5loxw0818u8xgf45p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5vzjoslpj708186z2fusmz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5w7xn0lrkq0801f9k0htgx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5waeduln160817w0agirve.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wcc90lu020850mjrxppv6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wi6bqlxy90755bu227nvb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wj0faly5008187n6530af.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wkonqlrl409877y8zvnub.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wmvsdlx1j0871npgj8j4b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5woy82m07m08505dmjg7g1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wphwwlu3m0987hh3ltg88.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wqonpm0e60801z88ewmy1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wrapcm2290818jsh26ppb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wrrs0m2af0818vmnajbtw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0qkwl35piu0993l0dewei2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0qoxqj9q6s0835b43399p4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0qx73cjw570799j4n5cjze.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0roawvklrq0799vmjorwfv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0rx1idathl0835detmsp84.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0s2a9ekvms080138tjjpxr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0s690hkp960855tjuaqvv0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0sr5ghl0nd08789uzf1raf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0sxqiclckk08551ycbwhno.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0t4oil7vzk099370nun5h9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0tl3uz8blh0993wxvn7ly3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0u2g7pmnux0801vkk47ivj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0u82z3cuma0835wlxrnrjv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0ue769mxii08019zqgdbxn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju0vtox5ain6099360pu62rp.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju13cgqmnhwn0988yrainhcp.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju13fwthn9mq0835gacxgy01.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju13hp5rnbjx0835bf0jowgx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju14g8o4xui30878gkgbrvqj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju14hjh2ob2o0835ouz3r5aa.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju14pxbaoksp0835qzorx6g6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wtdu4m0im0871mix0yvc0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5wuhm1lwm40987vugqn3vv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5x00l6m5j608503k78ptee.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5x15djm7ae0755h8czf6nt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5x28nzm7t907558ocq4bt7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5x7iskmad90818frchyfwd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5xjn5mm78b09871spyqhhr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5xkwzxmf0z0818gk4xabdm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6ywm40wdbo0987pbftsvtg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6yxyt0wh080871sqpepu47.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6yywx1whbb0871ksgfgf9f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5xneamme2p0801qdf7fdwv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5xopi0md7q0871r1sjc1av.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5xq3tdm9fn0987pbedxdg5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5y4hgqmk0i08180rjhbwvp.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5y7buemcw80987p0r30g9f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5y84q3mdv50817eyp82xf3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5yclrymlgj0818k426ud6z.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5yeqiwmkgl0801fzv2douc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ygh1zmmdi0755uod5e17i.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5yhgznmkzb0801cji2vi8j.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5yimthmlv80850zhoc90c2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5yjq1pmlgc0801z0t24bly.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ymyd8mmdc0801ry3by1xr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6ur9l9v9jq0755paud9uka.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6us80mv1b50871ebyq2wxa.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6ut4l8va6y0755tyw3vfqq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6uy20suzbl0987rzuhz7z9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6uzxk0v83p0801rcwnexdu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6v1m1xv07w09870ah3njy1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6v3bb2v7xo085090blubyw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6v4szov55u0871qmqz3v8n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6v5ilsv8hk0850rb5sgh6o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6v6g6kvdw007552x6mb0po.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6vgdmivcvb08018fra5lnv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6vifjlv55z0987un6y4zdo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6vqarjv7yo0987q4b1btk1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6vrs1ov8cr098788h8gs6j.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6vta3kvazg0817qbeppjtm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6vucxvvlda0755j7msqnya.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6vvb8svhed0801jjcquh5e.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6vvxsev9y30987kespucdg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju15czxqp3lv0835jvhgzurz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju15jr8jz8sb0855ukmkswkz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju15l5ubz9yh0855b3ivdpse.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju15mhjczc8z0801kit5c6di.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju15ptjtppz40988odsm9azx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju15wdt3zla10801odjiw7sy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju160wshltz10993i1gmqxbe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju16ach3m1da0993r1dq3sn2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju16b6ynq8e40988m8vx0xnj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju16d65tzw9d0799ouslsw25.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju16fpvhzypl0799p9phnlx6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju16jgnyzp970878melv7r25.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju16whaj0e7n0855q7b6cjkm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju171py4qiha0835u8sl59ds.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju175facms5f0993a5tjikvt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju17bz250pgd0799u1hqkj5u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju17g6ykn1cs0993dww6qdi8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju17hw9hr9c5098800fu4u8e.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju17otoe119u0799nqcbl8n1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju17r8il13910799dr2wme2e.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6w733bveoz0817e600tw72.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju17v6ih0u7808783zcbg1jy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju17x0j4nfc10993y31pvlgs.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju17z0qongpa0993de4boim4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1819curo000988pd5xcqme.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju183od81ff608017ekzif89.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1871y11d6r0799k6cw4yze.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju18849rrsgr0988p90hkygb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju18gzrq18zw0878wbf4ftw6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju18ibp219ub08783i6o98g7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju18kevfrojc0835bn90f1in.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1alwgo30z60855fm3y23sm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1amqw6p8pw0993d9gc5crl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1aqqv02qwz0878a5cyhr67.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1ats0y372e08011yazcsxm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1b0y2e396p08558ois175d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1b3zgj3d8e0801kpolea6c.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1b75x63ddl0799sdp0i2j3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1bhnfitmge0835ynls0l6b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1bm8063nmh07996rsjjemq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1brhsj3rls0855a1vgdlen.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1c0qb4tzi308355wtsnp0y.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1c3218411b08014g9f6gig.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1c4fcu40hl07992b8gj0c8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1c6yfz42md08550zgoz3pw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1c8ffau5770835g0g343o8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cbokpuiw70988j4lq1fpi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cdxvz48hw0801i0fjwcnk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cfhyg48bb0799cl5pr2jh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cj3f0qi5n0993ut8f49rj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cnnziug1l0835yh4ropyg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cqc7n4gpy0855jt246k68.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1csmlc4ht10799b8ymmghg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6wi3akvn8r0801px8eligc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6wjm81vgsc0987enk9n3pr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cu1u2474n0878tt7v4tdr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cvkfwqrec0993wbp1jlzm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1cyjb5qtie0993njqne9m3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1d31sp4d4k0878r3fr02ul.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1d50a94qf50855wsowacrc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1d96gsv62d09881b3wecw2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1ddr6p4k5z08780uuuzit2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1dfeupuzlw0835gnxip369.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1dg44i4z3w0801nyz4p6zf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1dhfok4mhe0878jlgrag0h.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1dia8hvc6v098827mgffnm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1djtprvd7b0988thwwrg09.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1dnz61vfp40988e78bkjga.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1dq3x1vgx109889c7wyirg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1drnhbrb9409935wi7vkhg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1efbr0rqxz09931z0lf4vf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1egh885m1l0855ci1lt37c.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1egx9pvz2n0988eoy8jp23.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1ejj7dvqfa0835ra184v5m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1erep75us208553i4ofwwe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1euant5l960878iqj5vvto.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1euuc65wm00799m4sjdnnn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1ewnoh5z030855vpex9uzt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1expq45zst0855rjqwwj4m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1f15k3w4ct0835cmde6ypo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1f320ewfyu0988ndz6blh5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1f5x1164xv08555654c24r.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1f79yhsb5w0993txub59ol.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1f8w0t65en0799m9oacq0q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1fb9236a110801yvg0fwju.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1ffnjn6ctm08015perkg37.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1fj6axwfp30835ukhuzhw9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1fjsb4sipq09931lvd8e41.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1fm3id6gl50801r3fok20c.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1fmsyf6gxb0801cimx2gle.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1fr4etsmrr09933u4t4aql.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1ftaji6isw0855108yqcse.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1fuoa4wmc50835qfd11sp9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1fyb1d69et0878muzdak9u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1g20bdwq6u0835e16xugcd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1g4nsb6ngy0799l4ezm8ab.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1gghyjwxt80835vx0wgxw0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1gi7jlwyld0835cdf6g6qz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1gkndf6yi10801o1qnje19.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1gv7106qd008784gk603mg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1h5w4wxajx0835mc954kxy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1h89h6xbnx08352k2790o9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1haab178i70799tk9z8y8x.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6wll7wvo3y08502pagos8m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1hhj6mxfp90835n3wofrap.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1hirfi7ekp0855q0vgm9qq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1hmff8tkp809931jps6fbr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1hp9i2xu8e0988u2dazk7m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1hs0za7jha0855vj0mdrjt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju1hyolc7aqu0878rrkfn1lr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hdr06v2bq0799mbm3bks1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hewssldzx0835ep795xu0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hfqnmhisa0993gpleeldd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hgsptlfam0835o3b59h1o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hjrqcvi2j0801bx1i6gxg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hlm19vjjf0801o69qnber.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hos57llxm08359g92p6jj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hqt33lmra0988fr5ijv8j.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2htabevq9108015qjei0x7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hugv9vget0799hhk7ksvg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hw5gjlr5h0988so2qqres.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2hx006vidl0799igm81vmh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2i03ptvkiu0799xbbd4det.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2i3hzclw3o0988rrgh911i.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2i6acqvo6l0799u20fift8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2i8br1vqtd08784u6vmcjk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2iatlki5u309930zmgkv6h.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2igw4gvxds0878808qj398.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ij9uiic2l09933ljiv6gm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2lberzkdzm09938cl40pog.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2lcyfgkf5809932fn9gucn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2lejzcy4pc0878c9rlonot.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2lyynuymli0855g7fxgbhe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2lz8vqktne0993fuym6drw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2m56cryvqd0801gtn2yp8t.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2m71z2ywwv080131bcrsd3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ma647l0nj0993ot4deq2q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2mfjndoz700988b9lc3zeq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2mh8t6p07008350e01tx2a.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2nbdpmlmcj0993s1cht0dz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2nd7l7z98o0799gfjvyfmw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2nfnvxzdkd0878399axlco.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2nguelpmlj0835rojdn097.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2nnqrqzp580855z8mhzgd6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2np2k9zi3v079992ypxqkn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2nqapmzvk20801f9us40dx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2nsmwjlzyl0993jl80chvz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ntxtdzlvu0799xl3j9pan.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2nyc5f02m40801ojqbtiea.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6wn57mvooj0850rp78hhy7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2oi8sq0i2y0801mektzvw8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2okvco06xc0799kxe5n1qh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2omjpeqj5a0988pjdlb8l1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2oo0wh0bqy0878biujeyhe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2oq5570avm079959o20op1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2osuru0ki00855txo0n3uu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2otvvv0l7z0855x7we8cb0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ouil2mssu0993hvxsed6d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2p0eveqtdc0835gpi3p93i.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2p4ddkmzxj0993p94o62av.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2p91qir00k08350ddfif0w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2pag1f0s4r0878h52uq83s.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2phaksnahz0993yxogjcpv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2pjb9v0ywn0878j5g5n69j.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2pkwt3r8b90988v2ywq1px.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2pmhtr17a00855cvpelzb0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qdj95ru8g09886gfi9rsz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qfie4rvz508357kad9z5o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qh5le1ock0878oahaql7d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qn2fzs1vy0988l243cvzy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qozsk20cq0855ugrg3cri.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qqn5ys4uo0988ewrt2ip2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qs32r1vys07999conmbvx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qtee81yd708787bsjr75d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qu37qobl50993aw7ghcfq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qvuj1s9ok0835tp2k4ozh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qxxko229x08786gvxxhur.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2qz06823a40878ojcz9ccx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2r11x7sdgx0988o8ule0wl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2r2obh2bjm08553kng0rh7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2r6mt2om21099352pny5gw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2r7h21sj9608354gzks3ae.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2r91dg2k090801bh0xzbxk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2raxlosl630988jdbfy9b0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rga4psq9n09881z519xx0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ricdv2iys0878sv1adh0u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rkjfwoxys0993x768l1j2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rlqdnoz9k0993cpjae3x0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rmd2rsw9g09888hh1efu0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rn0hasxri0835nfy3buay.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rnkt22xep0801as160g9t.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ro5jqsy680988pi6qsujw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rpa30t07b0835im0erql0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rqo702wpx0855fn7d5cxh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rxm8rpbaf0993o3qr2oph.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rz4k434s70855wwx3ddtx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2rzpsmtb0f0835jabkbao1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2s16zp317h0799gr67jqc2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2s2527pfyr0993l3h1149a.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2s9g11pnra0993gn4eh793.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2saez63gxl08559ucjq3kt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6wt9jvvn500871hjn3t3g0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2sevf53lkx08558h5bpaig.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2sggy13na70855tbeoqgha.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2spdagu1l50835da1f46fr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2srvy5440s0801y1ba9akr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2sszfq3uye0878sucelzk2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2suk42469908015ngmq6f2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2sxf3iqbpv09937iksn8ep.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2syxa93yw40799x2iuwabz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2t16vuucaq0835xcpsivn2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2t2ivz43i10878zeg8r1br.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2t3ibkuecr0835o7si16zv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2t62nq45jl0799odpufwx6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2t9tdwuk700835kv0ljmtl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ti1du4idn0878giuozonw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2tjrog4jy30878pawyazqc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2top2ruxxy0988p1svx36g.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2tpfa5uyx408359datxqqj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2tqfgw4oat0799rn0g5b2z.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2trbpkv0c00988hxla5dzz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2trtjf4qjd0878a2zle9v9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2tvrvm53ws0801a0jfjdxg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2txjfzv60w098839dcimys.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2tzypl4wss0799ow05oxb9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2u2b9o4zvp08788qb9nqxj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2u4pymvc720988wsxrmi84.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2u73dj53oz0878486k8k4b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ueb6j5ado0878vf5md13o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ulk385h170799rlklxob0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2uokeg5jm20799xwgsyz89.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2upu4evw7g08358guwozxv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2urqpwvxw70835rvndvtsi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2uwz9f5yf1085506cfamfx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2uy8ox62jo0801g88hh42z.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2uzabhs6er0993x3aaf87p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2wtwj87kys0855kx6mddzw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2wve9v7esz0878mxsdcy04.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2wx0gh7fpz0878wwyd9ep8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2wxv0hxs2f09884w48v8fi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2wzu8wxtgu09880ku9x1pg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2x7vw87mu30878hye2ca0m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xa3i4y0160988i679zsqd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xbk0080y80801eghyddi2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xd75m82720801q4s4ik3n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xf8e5y2wm08359vcgk09b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xjz2ju8pe0993ysv9wg17.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xlcqxy9c60988vjacdznb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xs6na81t20878pt6nkfip.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6wuojavt740818b5qcv3iw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xwm1s84l50799i60mq0pu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2xyd9vyi7m098831qcucse.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2y0z6g87p10878fpk5d3rq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2y26c588bo07993ksd8eoz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2y40d8ulqo0993q0adtgtb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2y5zas8m7f0801d34g5owq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2y8s56ymqr083541ggdsml.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2yb31a8e8u0878wdashg7o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ycp1u8g2r0799jslnp7cz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2yg5ht8i4p087800js8hp4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2yi9tz8vky0801yqip0xyl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2yljr0yzhw0988ecf271ly.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2yo1j1v0qz09934o0e683p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2ysg748ru80878sp6j0gm0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2yv4imv6cz099314jveiib.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2yw4s7z7p20988lmf2gdgd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2yyhsp933j0855hp32e012.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2z1nxlzaj40835wj81s1iy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2z2x3nvd3c099350zgty7w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2z45kuzf6d0988nz2c819m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2z6ez69g4u0801qwt088lw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2z9vlp9j0w0801oag91sy9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zblxw9848087853csbrx1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zdhsczmn50988z64qwg2q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zdvjn9h7r08553cp4eed5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zgbj9zmrw0835nnlzxj4c.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zi4l09f5807991s8do2b2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zjcvj9qma0801dk71hhi0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zkpdl9h7t0799ix60teqg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zm0axztpe0988r8s9twjr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zo0fwzv580988qlijd2xa.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zp89k9q1g0855k1x0f1xa.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zpw4q9vzr0801p0lysjdl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zr3c3vwb00993jn06bbaz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zrojo9kcd0878ld2epejq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zwg05a0oy0801yr73ig7g.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zxja9w1eh09933609ho9z.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju2zy1e49pqk0878t6ncqn12.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju300m3s04fg0988uzupuf7z.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju302fqq9spc0878rrygyzzz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju303j5r062k098835zxfds5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30525w04r10835ygp257sb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju306x7w05nb0835cunv799x.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30ajhw09sx0988qyahx9s8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30bmab08bi0835mvlr6e0r.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30df2j09dd08351ayx2t6w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30ftgja7170855xl9bkdm0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30gxjq0djk0988jytm49rs.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30ia8da2bq0799klnehml2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30j1rgadut0801vuyrsnt8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30k2z40ds308353kdew70n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30lncba3ny0878jwnous8n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30mm25a53s0799qa5wiqe8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30nyxe0gfb0835p256yoju.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30ov1oah920801mi8thuyg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30qbm1ad3x0855znuhpz9u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30u1hbakn808019g15nb8b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30xqmh0ni00835ix3batv1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju30ywtc0oar0835bp2en7ec.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju310f6val1v0855xo8tc3gu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3128yi0rpu0988o4oo5n8n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju31rb7vb6110801p9rhacuw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju31t8xd17bk0835rnb893jk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju31ugmfb3dz0855xtqshki6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju31w6goazci0799n014ly1q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju31y80qbawn0801twwm2l5s.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju320gyvbch60801v2amdi2g.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju323ypb1fbb0988gx5rzudb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju324q101fhe08350wae9cif.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju326h4v1gxw08352px40p7r.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3280wv1ir009882jze27tc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32a52lb9rc0799xi40qs00.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32csyfblyh080170aa3x5p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32fhnhbds40799broyoptc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32gzs6xo8x0993r8tedbpb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32jcdabepz0878d0cznmfe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32l161bi1v07990vm376in.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32phw2bv130801yj7bkouq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32pzh9bpw10855q4vaxfhe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32qr9tbvsj08013pkpjenq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32srle1xfq083575i3fl75.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32upim1z7u0988l883nqp6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju32zhbnc1oy0801iyv1ix6p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju330ofbc2l30801th5g3hw6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33231uy4gi0993qc7b1jch.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju334jzo261t0835yqudnfs1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju336l68y7if0993wf092166.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3381d8bz3h07991xtl7ra0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33belnbyhm0878yxl42233.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33eqwbcch208012jikwdky.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33jon3ygbj0993pu22a4k6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33mirdc8mj0799k33wzoes.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33o12x2jm50988944mxq0v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33qpdvc9g0087825jhf3s9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33w4sdcivk0855x879zht7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33x0f22peh0988g0ln7w5v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33yemn2qb20988wfjxximx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju33za6l2qy70988jhrlp2ev.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34aozyyy830993bn16u32n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34c1xfyz920993itxkkfad.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34ds2531520988qjpqt6e3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34eqjpcpm508788b3lhp97.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34fojcctcf0799ebolbvkn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6x0yqbvxqt0755dhxislgb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34i3qvcyog0855qiejxx5w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34m7h536wq0988xz7gx79v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34o6dbd2lo0855aqlcy1hs.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34ouumcznz07996gg1xq7v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34repocy5208780gswillm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34sh43d8zm08019xbwhc0o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34uhepd3dd0799hs8782ad.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34xspwzenf0993cyzajv9n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34ymm8d6700799uop0cw33.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju34zivp3fq80988opxbaqyn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3518w2d838079939fqztbc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3521y5d5mq0878t3ezsu4p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju353d1eda8c07992afde611.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35740hzm0g0993zl5ic246.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju357rxxdaz30878y2esjpjt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju358pwtdby20878cg7nm0np.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35a77vdj4n08556jj2lgmc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35atpxdjot0855q46aqrd0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35c4wzdhow0799h6eq4sgs.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35eg0tdmjt085525sb4bua.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35fxqyzt5p0993vusm54qz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35i2e63uxr0835h7zgkg9k.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35k2fr3vc50988c85qkrwg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35ldepdtlm0801yv79y8vu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35mdz73x890835eynq1h9v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju35oyvd3y850988km12hdz1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3tp94kfstl08181awh6z49.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3tsh4lfsok0987w6x3a0v1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3ttznuftyf09875t11850w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3tvffffx5f0818t5ov22al.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3tx1qyg0c907552fglumhc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3u1c8tfyqx08503iedc3mx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3u39fog1bo0871lxjrabks.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3u4lxmg59o0755rz42b9en.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3u815rg4ek0850vvhtcvcm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3ua8u0g9rg0801uayhdxhu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3uhb79gcgr0871orbrbi3x.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3ul8dogf1z09872y2ecowp.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3umoh1geet0817cmpef5am.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3uwz6ogsp10801h2r3bj5l.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3uz4o6gr9z0850lhxyxvsj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3v0fl3gwce0755qkjhzmd4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3v11mrgwwb0755u242ygye.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3v3ac9gyz30755hfqwyp1i.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3v56bwgy8v0871w14pz8fx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3v664kh0px0818y4y7wolf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3v72v5h1qz0818fggilwtq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3wstckialg0871xs0vevsj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3x2s11ibzi0817kk284k0j.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3x4blzieu30850x10uuvbm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3x5u2tiihx0818914gzxy1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6x35ervu2808015c7eoqe4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3x7xsaijq80818f0psavav.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3x9lttikfb0818a0g104zn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xeexgii1j0817zs68tb4g.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xga12iixg0817dijbvjxw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xhpvvimda0987ygrpzni2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xiic0ilzp0850lusrb42j.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xjqtpikx50817tppy6g84.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xl264ingx0850rcf0rshj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xtufwiv9c0818djsc4cqd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xuj20ivgp0818mij8bjrd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xvoo2iqlc0817eku2r3wl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xwpgviwlx0871rwm15q7v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3xzvnzj0hd0755xprz39nj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3y0pjrj1c30755nxekxccj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3y21quj0ir0818kgjagr15.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3y54kwj3nr0801biidlb4e.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3y79ofj3va0871uqfb1mzo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3y9difj6th0801kd1rqm3w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3ya7goj6at0818v2l5ay7f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3yb47cj1xq0817zfotbni4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3yht87j83m08507yk1u1fg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju3ykamdj9u208503pygyuc8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40jl7skiuo0817p0smlgg8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40m0rjkpw80871z6n6yg1u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40poe4kt9s0755f9cnm3h5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40r6jrksyk0871wg98zgho.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40sdwukv3k0755y99ug1k8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40taxlkrho0987smigg0x0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40u30gkuzc0871rq7t666d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40w3hbkwpn08015rbs3wko.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju40wto5kxwi0755it190f2k.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju410dnfl0960755y8lu8d79.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju412uwlkva50850d1ps1ww7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju414lf2l1lt0801rl3hjllj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju418rckl3ur08012psrx1r1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju41kd7yl4nm0850gil5qqwh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju41lojblbs307555jdci937.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju41nz76lcxu0755cya2qefx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju41p90plcsx08018cnzpndc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju41r6v2lcww0871ps8k8pf5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju41s6nbleqy0755e2mslg0b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju41z76wlgbz0801qdetlvby.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju422cm8lfxn0818ojicxejb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju424hy5lckr085073fva1ok.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju426tomlhll0818fc0i7nvh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju428k5fldt108177s6g6f45.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42dwedlmk60871jbgu4ehi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42g865lorv07552ytz6xxa.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42m60jlpcm08186kqppzqv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42nm68lpyo0818xvvqmupq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6x4t13vyw60755gtcf9ndu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6x97w4vwua0850x0997r0a.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42py9mlqyd0818u3d1d7ga.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42qet0lsq90871e50xbnuv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42romflni20817etb9a0fl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42tauqlo5p08171l3cuo4b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42u5bjlvi10801dc13sskp.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42wamblrqn098798r2yyok.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju42xpi8lw4w0871ve317a1p.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju430pm2lz0y0755jkhcc3d1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju439oazm2fu0871ma0vvrft.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43b8daly4408170e5ev06g.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43c92lm5cj0755lorsorfg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43eigtm6ev0801mv0m96t1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43gfosm63n08714rpih8pe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43h43am1dy08176gwfhmnt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43in5fm22c08175rxziqrk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43jcqim2cp08172dvjvyui.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43kj2pm34f0850l28ahpni.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43lcnum9y10755bjs7z87f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43mkj9m8wb0871qiadahub.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju43o6n7m9nk087191ijwqq9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45jpvfn6c809873pv1i34s.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45lbgznahl08180xz1h7u6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45n0oxn5vu08500yfrt9jn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45ofd9ne1j0801ri8dup7t.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45pm27n80u08174kyow1gj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45qbf3n9sa0987oonbkly9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45rj7ln8980850a7821fov.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45t5ddnbio0987qtqzx762.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45ty6zn9oz0850qy4qnck1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju45v0pungu40871acnwtmu5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5b9oyda4yr0850g9viziyv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5bbtwsa8cl0987wgfsqpao.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5bdwa3aatx0818b79i18zf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5bf6hxa6m50817rbwettgu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5bhv81abur0850ean02atv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5bj926aiec07559rshy4wa.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5bmhdcafs909878qfzrqzi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5boicjagt20871b1fotkh4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5buy2bal250818ipl6fqwv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5bwhapakm90987c1v4z46a.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5bycdkalkb09875f7bfrvx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5c5xc7algd0817pb1ej5yo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5c7oijaqmq09878qwgqv8n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ca9hcatkc0801jzwe7tfx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ccpvqash50850kb4bs22k.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5cetivauok0987ok3e5bre.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5chrxxawka0871qcj171yz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5cjh3xattc0817j2vbulzi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5cky5xb0ay0801oxet697t.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5clr68b48r0755cmuvponm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5cu8qkb84x08186jwo8yin.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6xa0qmvzun0818xjukgncj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6xifswvwbo0987nibtdr50.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6xlygpw7bs0818n691jsq4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ddda9bkkt0850enzwatb1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5eftctcdbj08712gdp989f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ekty5ckzf07550c9u3ckk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5enq1tcn1i0755hnkon787.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5eq8c8ck690850vix98hv3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5es375cnzy0801nkq35ffs.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ew4h9cqaf0818rrczkmqh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5eyfe9cpk90987laa7tsl3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5f0dezct4q08183ydw11dx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5f26ebcuai0818xlwh6116.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5f8hxdcxxn08188obby0ea.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5fb86jd1jp0755b1ukbhq5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5fi0yxd3ei0801v7u0yudn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5fs6j6d8350801vglraq4u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5ft6mcd5q40987rhjgbrr6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5fu081d8gc0818l3yylujk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5fw37edaae0801vkwvocn7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5fydrud94708507vo6oy21.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5g163vd6mt0817uccuga6u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5gucasds9d0801019axylx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju5h57xedz5h0755mjpc8694.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6z1bzbwfq50817b2alatvr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6z2616wqbk07555bvnuyr1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6z600qwh4z081700qimgl9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6z7e4bwgdd0987ogkzq9kt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju6z9a9kwsl007552s49rx6i.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju76erapykj30871x5eaxh4q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju76l27oyrw907551ri2a7fl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju76lsehyia10987u54vn8rb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju76o55nymqd0871h31sph9w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77196iyshb0850ycbto50a.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju772304yw5t0818vbw8kkjf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju773hsyyosz0817pk1e7sjq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju774fmayxif0818u2g79usw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7787c5yy3l080159mwqsnj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77afzlz3kp07550x5nafzs.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77b3wyz4160755qis4ljsb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77bvg0yv4r0987yh60xmjo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77g99iyxc00817zqi2ppor.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77idwfz36d0871tzfzz51i.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77j66ez52p08019xygi0co.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77k828z46w0871r0avuoo9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77q10sz9ug0801449wu1nu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77re6fz5bb0817vp9redjg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77t0razbvm080106o56289.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77u1sjz77b0817ft44r3fk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju77vvcwzcm50850lzoykuva.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju783tmkzkqu081803g7q5vk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju784jpdzeae0987q5ypq883.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju785htizjzo08017tvlhtg4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju787jnjzjuj0871p94nck9g.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7adqyj1jcx08712r1ro5gx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ae7bq1f820987toc8si1d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7aez2x1jtj0871ztezs3oi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7afqon1ip40850ue2308b6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7agj961l2r0818z29iq8yn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ahtkb1jr90801jck4kbds.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7aifyo1p3n07552nxjx51f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ajnbo1gvm098749rdouk0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7aklv31h4309871m29l4e7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7alcgr1lsr0871riqk84z7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7amjna1ly40871ugiokehb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ap09p1kz10850ldccjebj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7apr0c1qqm0755s7msqot4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7aqkue1i2k09879uzcpt8r.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7arvfe1ldu0850erdmphgj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7atnm31if40817pqclnjer.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7avvi51iox0817ym55y6tt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7awzmu1ncs0871hziy65zx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7azuu31mia0801pf9ib5ed.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7b10ce1mnm08011c5bwyr4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7b1ygu1msd0801hywhy0mc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7b2l561oas0871decgslaf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7b3f5h1sm40755i572jden.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7b4mtw1n9n080186209f3d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7b5afm1nfw0801xqm8bf8q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7b9vcs1luz0987ta60j1dy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7bb3ss1uoo0755pmhyco7t.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7bc95p1mdm0817yqj5jc6j.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7bd1qu1mx409877xjxibox.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7bduyq1rjf08719giru9ho.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7bf1lp1shi081835vs84lc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7bfx651qr80801cs7epotb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7bgnvb1sf808717qa799ir.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7bmi1v1pnj0987pa52jjok.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7cl8zm1xcu0817ado0jpas.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7cp6dw244p0818gncdol4m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7cq6su27qv075574dir0r3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7crgxa28550755wbsgqkel.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7csvlb22fr0850lvm45n3x.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ctvqn25dy08186g442m1r.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7cue9b232j0801qdzk1ykj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7cufm7298k0755j09uf3of.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d1tvt25bu08019dvw3uff.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d2q1k27nf08715zshsckt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d3oc82cho0755dajlwldz.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d4jk723eu0817bqz2n39m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d5m0p23kn09871rk7pu3v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d6ux323ze0987xos3srkx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d7aut2a2p0818z4uxc6cd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d7tly27h408016fyp5nr7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d8m3b2e210755l8fj1yph.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dbppn28nx085097654msi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7d9seq29zd0871nzl2uu5m.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7da88w2eod0755wejzynvt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7db7lp2f400755tntd1ohf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dda8w2br20818zhsuz8s7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ddtz729960801uazp1knc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7deifq2fzn0755lc8idyh8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dff9529h208503w60lbil.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dglf226g50987ohbthl19.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dhpsc2dnn0818025m6857.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dizi82h2i0755doucgnt3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dlk532dsh0871zvr6qz0r.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dmlgf2ebw0871ieqas5fh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dn24o296i09871qfxb8s2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7do8c72dbo0801vxfzxdc4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dp3dw2k4n0755zhe003ad.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dqcwi2dz00850gcmr2ert.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7druhp2gp308715i6km7be.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dsrtb2f8i085064kwugfk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dtb1e2j0t0818deq51ib3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dubap2g0w0801fgl42mg9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dvl5m2n4t0755hlnnjjet.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dwe282dc309876rco45ts.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dxffn2eam0817qxosfwch.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dymur2od30755eg8yv2ht.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7dz5yy2i7z0801ausi7rna.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7eea9b2m0z0801ynqv1fqu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ea4om2l910801bohqjccy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ebe962hr409872ovibahw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ecl9i2i060987xawjp4l0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7efffp2ivf0817etg3jehl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ehljc2or70871261br8ai.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ejm2l2ncl0801wq6y84nw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ekbo32pft0871fv7kzwb9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7el6xv2k520817qxx9wdr5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7emdni2py40871ivhxjtut.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7eotqi2qea0871y8yc7tqh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7epwj82koz098713apjnzo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7er4kc2opa0801anuxc0eb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7es23b2vcp0755gpbm9s7v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7et17a2vjk0755e743npl1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7etr3y2p4t0801cdzjj8ab.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7eueum2oqn0850rodmx8zo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ev2b12owa08500bpfpwyw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7evxt12m730987rxivne3x.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ey10f2rvf0871bwbi9x82.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ez7r22qbc08015xfoz2wb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ezs7g2mxm098787atbran.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7f0ec32txj08184asb8w5f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7f4sc62xqj075597xpmuoy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7f5ghb2r5s0801chwkxxh9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7f6cqy2ur20818t1saazbm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7f900s2o0k08175gl1giid.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7f9umg2olj0987fj5y285w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fazv92ywx0755xov2erga.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fbndk2sl608015ravktum.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fcgbe2z3p07550vaflqdb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fd6yt2p740987wkr8exo1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fen322ou10817ziqkob4k.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7ff97z2ow40817u2r83my5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7flevb2wii08188otgs9p2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fmvpk2q170987v6i3ola8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fnfv02tt90801djnix9m8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fob3x301u0755x985pmmq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fpfzq2wyf0818xxd1oziv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7fq7mm2pw508176uk5ugtx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7frtqu2xa20818wq8r9fzf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju7g7ba42z310987bqzbi2bq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83h9ysjwe808716nt35oah.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83ipu3jwpx0801z5pvguf8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83k8fyjsxr0817d6nxs6r4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83kxitjv340987z09m0ezy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83mki1jv5w0817kubxm31r.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83nwu1jxte0987h1krpfmv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83qd0yjyht0817ktkfl268.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83rcnzkbsj0755x5anfrcg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83syhdk6gs0801rf1rekdl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83yddek68q0850d2x7zfkm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8402x1kcy70801t6kz6bdi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83u9ftk3ni0987qnhlcinv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83vvmik9wa08710yeh7cuk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju83wwn1k55e0850kw6i2d81.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8418jhkf7d0818ga2v0xq0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8432cmkgq90871cxe4iptl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju843yjskhq30818qre4rwm2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju846ec0kj7z08012o10klrb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju847pxykriq0755268ktrk2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju849c23kgnk0817cgv2hw1e.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju84aoa3ktwn0755pfl4gfwd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju84dsvaklpx098750hp83x4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju84ffdzkrjn08183jh1fxmb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju84gpefknwm098714oq8q61.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju84hibuktj80871u519o71q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju84ih17kp5l09876bkooocl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju84jdl9kv0i0871eog9b3i9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju84kplnl1y30755ropua1b0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8567gdlcbq0801dwwyo2jt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju857ad0l88m0817qx4cwxnf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju858eswlepn0871pzvdrhj1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85a8h8llwm07559wxg4t5w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85bf1algsq0871y9gtlq97.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85c2d4ln1b0755zz1z3onx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85citjlnfm0755i4rk5tqj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85dx63lic408017f0l0400.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85fc11ljr40818edpb0inh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85hguellg50818kwu3s8d1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85ia1slh220987y7c20sm2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85je7vlht70817c9jcjwi4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85l4yjlops0801fvmnwptf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85mpuglq8k0818d2it6hzb.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85nr8elly209872w9n5m0s.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85omszllp30850b6rm9mi3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85plp7lmkw0850rx42jdpf.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85qefyln6v0850szeb9byi.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju85rkbnlo1c08503uxcpax1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87kbcen2av0987usezo8kn.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87li0zn3yb0817kbwgjiz8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87mrypnb1e0818scv1mxxg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87nkyrnb970801q84m47yt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87ox0kncom0801b98hqnd2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87q6yoneim0871dl4phvkd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87r56lnkyp0755hz30leew.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87tyddnnad0755bj0wxahe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87vqa0ndwg0850onjdz7ol.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87xn2snfmv0987sc3d9xnq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87z6o6nh73085045bzsx6o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju87zv8lni0o0850hbbecbq6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8828oxnool0801qno9luhr.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju884985nlmx0817vzpax3y4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju885ikhnmkn09878s2lqtuh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju886ryxnsl50801r93jai7q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju887ftknop008177nnjt46y.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju888fr7nveu0818r9uwtiit.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88aq6vo1ij0755c2ey7z7n.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88cddensj00987788yotmg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88evxanv9r08176zkeovec.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88fpm4o0tl0871w1i6a4ds.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88gx09o2vk0818610zody3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88itqbny720987hxizbj5y.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88k75inzyb0850ccv5x3vk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88l66no10s0850rsda7ej1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88msmoo3470817m441j4sg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88nroho44508500129f1nh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88oh0po9gq0801nge4tgr1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88q6h6obpd0871ckmiabbo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88rl5eo94l0850kf5wtrm1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88t4fvokxf07558ymyh281.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88trl3ogi208716qvti51b.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88v2f9oi8w0871hx9auh01.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88vx2uoocy075531lc63n3.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88y1mwoln50871emyfny1g.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju88z8bson4h0871nnd7fdxo.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju890guyoiti098753yg6cdu.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8914beokbf0850isxpocrk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju892fesoq2g0801n0e0jyia.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju893jmdompz0817xn3g1w4h.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju89y9h0puti0818i5yw29e6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju89z6pqpqfx0817mfv8ixjc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8a1jtvpt9m081712iwkca7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8a2itsq4dv0755ntlovpxe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8a3nhbpwnb0850d37fo2na.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8a56vxpy780850r45yu4wk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8a84g0q76m0818hwiggkod.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8abobpqbir08189u01huru.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8adb60qbiu080188mxpf8d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8aeei7q8k308173n9y4klv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8aj01yqeqm0850lhdz3xdw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8alhigqn2h0801zksudldd.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8amfdtqi4x09871tygrgqe.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8ando2qqdo0818ck7i1be1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8apjewqrk00801k5d71gky.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8aqq8uqmoq0987hphto9gg.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8arof2qpf20850ifr1bnqj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8ashhnquqr0801rwduzt7d.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8at3s1qqqx0850hcq8nmnq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8auylgqx0z0871u4o4db7o.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8aw9n1qyg10801jkjlmors.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8axq24r4an0755yhv9d4ly.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8ayeq7r1fb0818z1junacy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8azmhcr66e0755t61atz72.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b0jr0r2oi0801jiquetd5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b1v3br45u087189kku66u.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b2rmgr52s0801p54eyflx.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b3ka8r64u0801fh18hk7l.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b4ja9r2s808509d45ma86.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b542nr81x0871uxnkm9ih.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b5p40r2c60987ofa0mu03.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b6rp0r5st0850184f79xt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b7aqtr4a00987coba14b7.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8b8yair65w09878pyqtr96.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bafgqrf4x0818twisk3ea.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bbznkrf5g0871jncffynk.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bff9nrfi10850fmfzbf8v.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bgdmqrksy0801tozdmraa.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bh8surexp0987o5pzklk1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bi8q7rlmn0871abc5ch8k.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bj2ssrmlm0871gc2ug2rs.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bk8oirjhw0817hgkua2w8.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bljw9rqk20801kr54akrl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bm24yrrdp081829mbo8ic.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bn7m2rmm70817hgxpb1uq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bop5jrsid08716i24fqda.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bpctzrqkr0850zeldv9kt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bqxxurs6i0850mu7mtef9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8brv16rx7f0818uf5n89pv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bssulrrcy0987h1vq5060.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8buos5rz9b08715lfr0f4f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bw697rwg308177tg8huas.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bysfgrzkl081786jwac09.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8bzzy2s66m08016z6mouqt.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c1a0ws7o208181c6lbsom.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c2rqzs5t80850d0zky5dy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c3xs7sauj0801ieyzezr5.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c5223s8j80850b4kealt4.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c5mxls96t0850wvkvsity.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c5zcbsdfz0801o5t6jag1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c6hnxsdvr0801wn0vrsa6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c82iosagu0817l74s4m5g.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8c9akjsdjj0850s67uzlxq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8ca4geseia0850i2ru11hw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8cattbsivm0818p446wgel.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8cbsyssiqj0871gr4jedjp.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8cdeazsm8h0801jxifmzur.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8ceacrsqkr0755hdz145es.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8cgi2kspp308011nxdtjp6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8chdlqsu620755azjty1tj.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8chxndsre008015uisl4si.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8cj10qsrau0871o2dr6ai1.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8clorgsuwn08714toqb7v6.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8cwy02t9eq08185qn12c02.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8czvnztbf40871b4m7t78w.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8d2q30tfhs0801n7lx77xl.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8d4jgatgpj0871q2ophhkm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8dic9mtppa0987swn23wbc.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8djdqztu6408506pzhlo18.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8dk7eztzup08182yxko5zh.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8dm2cau2km0818jsv9eeq2.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8dn0c3u2v50801k8rvq02f.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8doa16u5gh0818w1ywda3q.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8dpa89u6l80818dj6lldh9.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cju8dqkrqu83i0818ev74qpxq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzk8qieoboa0848ogj51wwm.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzkmjy8evns070165gf9dmq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzkpsbjdsjq07211dfi4sru.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzl833ndne80838pzuq6ila.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzlw7f9faqr070129au64sq.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyztzaqtrv430848l8xgcerw.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzu3reghjya0794w7pwoi50.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzu9th0qt4r0a46pyl4zik0.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzufihqquiw0a46jatrbwln.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzuio1qgh040763k56deohv.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjyzul1qggwwj07216mhiv5sy.jpg  \n",
            "  inflating: Kvasir-SEG/masks/cjz14qsk2wci60794un9ozwmw.jpg  \n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "url = 'https://drive.google.com/drive/folders/1btVK5NUVFVew4oZ8RGgu0No0jAHivenl'\n",
        "gdown.download_folder(url)\n",
        "!unzip Kvasir-SEG/kvasir-seg.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulsfceBsQU29"
      },
      "outputs": [],
      "source": [
        "route = '/content/Kvasir-SEG'\n",
        "X_path = '/content/Kvasir-SEG/images/'\n",
        "Y_path = '/content/Kvasir-SEG/masks/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "subyaBH5QXjl"
      },
      "outputs": [],
      "source": [
        "X_full = sorted(os.listdir(f'{route}/images'))\n",
        "Y_full = sorted(os.listdir(f'{route}/masks'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9BMXQUKV3Lb"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid = train_test_split(X_full, test_size=0.2, random_state=SEED)\n",
        "Y_train, Y_valid = train_test_split(Y_full, test_size=0.2, random_state=SEED)\n",
        "\n",
        "X_valid, X_test = train_test_split(X_valid, test_size=0.5, random_state=SEED)\n",
        "Y_valid, Y_test = train_test_split(Y_valid, test_size=0.5, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcvHfWr8Y7Oa"
      },
      "outputs": [],
      "source": [
        "X_train = [X_path + x for x in X_train]\n",
        "X_valid = [X_path + x for x in X_valid]\n",
        "X_test = [X_path + x for x in X_test]\n",
        "\n",
        "Y_train = [Y_path + x for x in Y_train]\n",
        "Y_valid = [Y_path + x for x in Y_valid]\n",
        "Y_test = [Y_path + x for x in Y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyiGlK5sZbfA",
        "outputId": "aded7e2b-feb3-4313-ecef-00d224f71133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N Train: 800\n",
            "N Valid: 100\n",
            "N test: 100\n"
          ]
        }
      ],
      "source": [
        "print(\"N Train:\", len(X_train))\n",
        "print(\"N Valid:\", len(X_valid))\n",
        "print(\"N test:\", len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxZ5hB7LZeLj"
      },
      "outputs": [],
      "source": [
        "train_decoder = build_decoder(with_labels=True, target_size=(img_size, img_size), ext='jpg', segment=True, ext2='jpg')\n",
        "train_dataset = build_dataset(X_train, Y_train, bsize=BATCH_SIZE, decode_fn=train_decoder,\n",
        "                            augmentAdv=True, augment=True, augmentAdvSeg=True)\n",
        "\n",
        "\n",
        "valid_decoder = build_decoder(with_labels=True, target_size=(img_size, img_size), ext='jpg', segment=True, ext2='jpg')\n",
        "valid_dataset = build_dataset(X_valid, Y_valid, bsize=BATCH_SIZE, decode_fn=valid_decoder,\n",
        "                            augmentAdv=False, augment=False, repeat=False, shuffle=False,\n",
        "                            augmentAdvSeg=False)\n",
        "\n",
        "\n",
        "test_decoder = build_decoder(with_labels=True, target_size=(img_size, img_size), ext='jpg', segment=True, ext2='jpg')\n",
        "test_dataset = build_dataset(X_test, Y_test, bsize=BATCH_SIZE, decode_fn=test_decoder,\n",
        "                            augmentAdv=False, augment=False, repeat=False, shuffle=False,\n",
        "                            augmentAdvSeg=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_r8W9jYaRJI"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = len(X_train) // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtysQTghaR5I",
        "outputId": "3045bece-495d-47db-c641-bb3356bd6e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trainning"
      ],
      "metadata": {
        "id": "W8mN4s14ZEkv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2N_tb7YviEk"
      },
      "outputs": [],
      "source": [
        "callbacks = get_callbacks(monitor = 'val_IoU', mode = 'max', save_path = save_path, _max_lr = max_lr\n",
        "                        , _min_lr = min_lr , _cos_anne_ep = 1000, save_weights_only = save_weights_only)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(img_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MA3OmJDY5AV",
        "outputId": "95545b2a-d357-4b4b-db46-f730c55ba8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/leondgarse/keras_cv_attention_models/releases/download/caformer/caformer_s18_224_imagenet.h5\n",
            "106298480/106298480 [==============================] - 1s 0us/step\n",
            ">>>> Load pretrained from: /root/.keras/models/caformer_s18_224_imagenet.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = opts,\n",
        "            loss='dice',\n",
        "            metrics=[\"acc\", dice_coeff, IoU, bce_dice_loss])"
      ],
      "metadata": {
        "id": "rRI9wwftYtON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AwdqiuYaf0Y",
        "outputId": "ec6aba08-1051-4095-adf5-65fe676212a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6475 - acc: 0.5502 - dice_coeff: 0.3525 - IoU: 0.2075 - bce_dice_loss: 1.5472\n",
            "Epoch 1: val_IoU improved from -inf to 0.31023, saving model to best_model.h5\n",
            "50/50 [==============================] - 72s 786ms/step - loss: 0.6475 - acc: 0.5502 - dice_coeff: 0.3525 - IoU: 0.2075 - bce_dice_loss: 1.5472 - val_loss: 0.4758 - val_acc: 0.8415 - val_dice_coeff: 0.5145 - val_IoU: 0.3102 - val_bce_dice_loss: 1.5815 - lr: 1.0000e-04\n",
            "Epoch 2/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5056 - acc: 0.8351 - dice_coeff: 0.4944 - IoU: 0.3043 - bce_dice_loss: 1.0844\n",
            "Epoch 2: val_IoU improved from 0.31023 to 0.54624, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 677ms/step - loss: 0.5056 - acc: 0.8351 - dice_coeff: 0.4944 - IoU: 0.3043 - bce_dice_loss: 1.0844 - val_loss: 0.2658 - val_acc: 0.9201 - val_dice_coeff: 0.7387 - val_IoU: 0.5462 - val_bce_dice_loss: 0.8730 - lr: 1.0000e-04\n",
            "Epoch 3/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4243 - acc: 0.9144 - dice_coeff: 0.5757 - IoU: 0.3653 - bce_dice_loss: 0.8284\n",
            "Epoch 3: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 34s 684ms/step - loss: 0.4243 - acc: 0.9144 - dice_coeff: 0.5757 - IoU: 0.3653 - bce_dice_loss: 0.8284 - val_loss: 0.3028 - val_acc: 0.9243 - val_dice_coeff: 0.6923 - val_IoU: 0.4880 - val_bce_dice_loss: 0.8028 - lr: 1.0000e-04\n",
            "Epoch 4/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3775 - acc: 0.9351 - dice_coeff: 0.6225 - IoU: 0.4022 - bce_dice_loss: 0.7024\n",
            "Epoch 4: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 657ms/step - loss: 0.3775 - acc: 0.9351 - dice_coeff: 0.6225 - IoU: 0.4022 - bce_dice_loss: 0.7024 - val_loss: 0.3298 - val_acc: 0.9410 - val_dice_coeff: 0.6670 - val_IoU: 0.4499 - val_bce_dice_loss: 0.6402 - lr: 1.0000e-04\n",
            "Epoch 5/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3521 - acc: 0.9459 - dice_coeff: 0.6479 - IoU: 0.4288 - bce_dice_loss: 0.6310\n",
            "Epoch 5: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 34s 684ms/step - loss: 0.3521 - acc: 0.9459 - dice_coeff: 0.6479 - IoU: 0.4288 - bce_dice_loss: 0.6310 - val_loss: 0.3397 - val_acc: 0.9531 - val_dice_coeff: 0.6594 - val_IoU: 0.4270 - val_bce_dice_loss: 0.5477 - lr: 1.0000e-04\n",
            "Epoch 6/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3234 - acc: 0.9513 - dice_coeff: 0.6766 - IoU: 0.4525 - bce_dice_loss: 0.5720\n",
            "Epoch 6: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.3234 - acc: 0.9513 - dice_coeff: 0.6766 - IoU: 0.4525 - bce_dice_loss: 0.5720 - val_loss: 0.3463 - val_acc: 0.9414 - val_dice_coeff: 0.6511 - val_IoU: 0.4344 - val_bce_dice_loss: 0.6496 - lr: 1.0000e-04\n",
            "Epoch 7/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3064 - acc: 0.9556 - dice_coeff: 0.6936 - IoU: 0.4685 - bce_dice_loss: 0.5294\n",
            "Epoch 7: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.3064 - acc: 0.9556 - dice_coeff: 0.6936 - IoU: 0.4685 - bce_dice_loss: 0.5294 - val_loss: 0.3478 - val_acc: 0.9505 - val_dice_coeff: 0.6530 - val_IoU: 0.4322 - val_bce_dice_loss: 0.5726 - lr: 1.0000e-04\n",
            "Epoch 8/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2861 - acc: 0.9590 - dice_coeff: 0.7139 - IoU: 0.4875 - bce_dice_loss: 0.4947\n",
            "Epoch 8: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 34s 685ms/step - loss: 0.2861 - acc: 0.9590 - dice_coeff: 0.7139 - IoU: 0.4875 - bce_dice_loss: 0.4947 - val_loss: 0.3110 - val_acc: 0.9569 - val_dice_coeff: 0.6900 - val_IoU: 0.4669 - val_bce_dice_loss: 0.4931 - lr: 1.0000e-04\n",
            "Epoch 9/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2749 - acc: 0.9622 - dice_coeff: 0.7251 - IoU: 0.5006 - bce_dice_loss: 0.4601\n",
            "Epoch 9: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.2749 - acc: 0.9622 - dice_coeff: 0.7251 - IoU: 0.5006 - bce_dice_loss: 0.4601 - val_loss: 0.2978 - val_acc: 0.9574 - val_dice_coeff: 0.7027 - val_IoU: 0.4824 - val_bce_dice_loss: 0.4826 - lr: 1.0000e-04\n",
            "Epoch 10/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2606 - acc: 0.9649 - dice_coeff: 0.7394 - IoU: 0.5170 - bce_dice_loss: 0.4308\n",
            "Epoch 10: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.2606 - acc: 0.9649 - dice_coeff: 0.7394 - IoU: 0.5170 - bce_dice_loss: 0.4308 - val_loss: 0.2899 - val_acc: 0.9592 - val_dice_coeff: 0.7123 - val_IoU: 0.4911 - val_bce_dice_loss: 0.4745 - lr: 1.0000e-04\n",
            "Epoch 11/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2437 - acc: 0.9672 - dice_coeff: 0.7563 - IoU: 0.5318 - bce_dice_loss: 0.4006\n",
            "Epoch 11: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.2437 - acc: 0.9672 - dice_coeff: 0.7563 - IoU: 0.5318 - bce_dice_loss: 0.4006 - val_loss: 0.2805 - val_acc: 0.9572 - val_dice_coeff: 0.7214 - val_IoU: 0.5051 - val_bce_dice_loss: 0.4764 - lr: 1.0000e-04\n",
            "Epoch 12/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2399 - acc: 0.9652 - dice_coeff: 0.7601 - IoU: 0.5394 - bce_dice_loss: 0.4068\n",
            "Epoch 12: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.2399 - acc: 0.9652 - dice_coeff: 0.7601 - IoU: 0.5394 - bce_dice_loss: 0.4068 - val_loss: 0.2627 - val_acc: 0.9616 - val_dice_coeff: 0.7395 - val_IoU: 0.5252 - val_bce_dice_loss: 0.4121 - lr: 1.0000e-04\n",
            "Epoch 13/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2252 - acc: 0.9690 - dice_coeff: 0.7748 - IoU: 0.5571 - bce_dice_loss: 0.3711\n",
            "Epoch 13: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.2252 - acc: 0.9690 - dice_coeff: 0.7748 - IoU: 0.5571 - bce_dice_loss: 0.3711 - val_loss: 0.2600 - val_acc: 0.9564 - val_dice_coeff: 0.7425 - val_IoU: 0.5328 - val_bce_dice_loss: 0.4469 - lr: 1.0000e-04\n",
            "Epoch 14/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2160 - acc: 0.9706 - dice_coeff: 0.7840 - IoU: 0.5691 - bce_dice_loss: 0.3522\n",
            "Epoch 14: val_IoU did not improve from 0.54624\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.2160 - acc: 0.9706 - dice_coeff: 0.7840 - IoU: 0.5691 - bce_dice_loss: 0.3522 - val_loss: 0.2634 - val_acc: 0.9594 - val_dice_coeff: 0.7414 - val_IoU: 0.5364 - val_bce_dice_loss: 0.4100 - lr: 1.0000e-04\n",
            "Epoch 15/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2061 - acc: 0.9720 - dice_coeff: 0.7939 - IoU: 0.5811 - bce_dice_loss: 0.3331\n",
            "Epoch 15: val_IoU improved from 0.54624 to 0.55252, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 673ms/step - loss: 0.2061 - acc: 0.9720 - dice_coeff: 0.7939 - IoU: 0.5811 - bce_dice_loss: 0.3331 - val_loss: 0.2416 - val_acc: 0.9601 - val_dice_coeff: 0.7613 - val_IoU: 0.5525 - val_bce_dice_loss: 0.4069 - lr: 1.0000e-04\n",
            "Epoch 16/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1994 - acc: 0.9710 - dice_coeff: 0.8006 - IoU: 0.5908 - bce_dice_loss: 0.3290\n",
            "Epoch 16: val_IoU improved from 0.55252 to 0.55753, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 669ms/step - loss: 0.1994 - acc: 0.9710 - dice_coeff: 0.8006 - IoU: 0.5908 - bce_dice_loss: 0.3290 - val_loss: 0.2327 - val_acc: 0.9591 - val_dice_coeff: 0.7657 - val_IoU: 0.5575 - val_bce_dice_loss: 0.4158 - lr: 1.0000e-04\n",
            "Epoch 17/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1876 - acc: 0.9723 - dice_coeff: 0.8124 - IoU: 0.6038 - bce_dice_loss: 0.3081\n",
            "Epoch 17: val_IoU improved from 0.55753 to 0.57347, saving model to best_model.h5\n",
            "50/50 [==============================] - 35s 697ms/step - loss: 0.1876 - acc: 0.9723 - dice_coeff: 0.8124 - IoU: 0.6038 - bce_dice_loss: 0.3081 - val_loss: 0.2207 - val_acc: 0.9642 - val_dice_coeff: 0.7786 - val_IoU: 0.5735 - val_bce_dice_loss: 0.3549 - lr: 1.0000e-04\n",
            "Epoch 18/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1865 - acc: 0.9711 - dice_coeff: 0.8135 - IoU: 0.6079 - bce_dice_loss: 0.3130\n",
            "Epoch 18: val_IoU improved from 0.57347 to 0.58139, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 671ms/step - loss: 0.1865 - acc: 0.9711 - dice_coeff: 0.8135 - IoU: 0.6079 - bce_dice_loss: 0.3130 - val_loss: 0.2182 - val_acc: 0.9605 - val_dice_coeff: 0.7826 - val_IoU: 0.5814 - val_bce_dice_loss: 0.3741 - lr: 1.0000e-04\n",
            "Epoch 19/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1745 - acc: 0.9736 - dice_coeff: 0.8255 - IoU: 0.6265 - bce_dice_loss: 0.2871\n",
            "Epoch 19: val_IoU improved from 0.58139 to 0.59478, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.1745 - acc: 0.9736 - dice_coeff: 0.8255 - IoU: 0.6265 - bce_dice_loss: 0.2871 - val_loss: 0.2071 - val_acc: 0.9634 - val_dice_coeff: 0.7961 - val_IoU: 0.5948 - val_bce_dice_loss: 0.3404 - lr: 1.0000e-04\n",
            "Epoch 20/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1665 - acc: 0.9726 - dice_coeff: 0.8335 - IoU: 0.6362 - bce_dice_loss: 0.2818\n",
            "Epoch 20: val_IoU improved from 0.59478 to 0.60245, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 673ms/step - loss: 0.1665 - acc: 0.9726 - dice_coeff: 0.8335 - IoU: 0.6362 - bce_dice_loss: 0.2818 - val_loss: 0.2099 - val_acc: 0.9618 - val_dice_coeff: 0.7940 - val_IoU: 0.6025 - val_bce_dice_loss: 0.3458 - lr: 1.0000e-04\n",
            "Epoch 21/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1569 - acc: 0.9756 - dice_coeff: 0.8431 - IoU: 0.6539 - bce_dice_loss: 0.2570\n",
            "Epoch 21: val_IoU improved from 0.60245 to 0.62379, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.1569 - acc: 0.9756 - dice_coeff: 0.8431 - IoU: 0.6539 - bce_dice_loss: 0.2570 - val_loss: 0.1890 - val_acc: 0.9648 - val_dice_coeff: 0.8144 - val_IoU: 0.6238 - val_bce_dice_loss: 0.3245 - lr: 1.0000e-04\n",
            "Epoch 22/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1440 - acc: 0.9772 - dice_coeff: 0.8560 - IoU: 0.6686 - bce_dice_loss: 0.2339\n",
            "Epoch 22: val_IoU improved from 0.62379 to 0.63748, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 674ms/step - loss: 0.1440 - acc: 0.9772 - dice_coeff: 0.8560 - IoU: 0.6686 - bce_dice_loss: 0.2339 - val_loss: 0.1819 - val_acc: 0.9647 - val_dice_coeff: 0.8219 - val_IoU: 0.6375 - val_bce_dice_loss: 0.3073 - lr: 1.0000e-04\n",
            "Epoch 23/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1364 - acc: 0.9779 - dice_coeff: 0.8636 - IoU: 0.6805 - bce_dice_loss: 0.2203\n",
            "Epoch 23: val_IoU improved from 0.63748 to 0.64366, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 670ms/step - loss: 0.1364 - acc: 0.9779 - dice_coeff: 0.8636 - IoU: 0.6805 - bce_dice_loss: 0.2203 - val_loss: 0.1758 - val_acc: 0.9658 - val_dice_coeff: 0.8280 - val_IoU: 0.6437 - val_bce_dice_loss: 0.2984 - lr: 1.0000e-04\n",
            "Epoch 24/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1303 - acc: 0.9778 - dice_coeff: 0.8697 - IoU: 0.6899 - bce_dice_loss: 0.2139\n",
            "Epoch 24: val_IoU improved from 0.64366 to 0.65553, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 670ms/step - loss: 0.1303 - acc: 0.9778 - dice_coeff: 0.8697 - IoU: 0.6899 - bce_dice_loss: 0.2139 - val_loss: 0.1701 - val_acc: 0.9629 - val_dice_coeff: 0.8321 - val_IoU: 0.6555 - val_bce_dice_loss: 0.3287 - lr: 1.0000e-04\n",
            "Epoch 25/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1545 - acc: 0.9685 - dice_coeff: 0.8455 - IoU: 0.6678 - bce_dice_loss: 0.2798\n",
            "Epoch 25: val_IoU did not improve from 0.65553\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.1545 - acc: 0.9685 - dice_coeff: 0.8455 - IoU: 0.6678 - bce_dice_loss: 0.2798 - val_loss: 0.1888 - val_acc: 0.9613 - val_dice_coeff: 0.8143 - val_IoU: 0.6251 - val_bce_dice_loss: 0.3172 - lr: 1.0000e-04\n",
            "Epoch 26/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1435 - acc: 0.9705 - dice_coeff: 0.8565 - IoU: 0.6813 - bce_dice_loss: 0.2592\n",
            "Epoch 26: val_IoU improved from 0.65553 to 0.66899, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 673ms/step - loss: 0.1435 - acc: 0.9705 - dice_coeff: 0.8565 - IoU: 0.6813 - bce_dice_loss: 0.2592 - val_loss: 0.1658 - val_acc: 0.9645 - val_dice_coeff: 0.8392 - val_IoU: 0.6690 - val_bce_dice_loss: 0.2919 - lr: 1.0000e-04\n",
            "Epoch 27/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1340 - acc: 0.9732 - dice_coeff: 0.8660 - IoU: 0.6965 - bce_dice_loss: 0.2356\n",
            "Epoch 27: val_IoU improved from 0.66899 to 0.67062, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 676ms/step - loss: 0.1340 - acc: 0.9732 - dice_coeff: 0.8660 - IoU: 0.6965 - bce_dice_loss: 0.2356 - val_loss: 0.1659 - val_acc: 0.9622 - val_dice_coeff: 0.8382 - val_IoU: 0.6706 - val_bce_dice_loss: 0.3012 - lr: 1.0000e-04\n",
            "Epoch 28/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1189 - acc: 0.9767 - dice_coeff: 0.8811 - IoU: 0.7160 - bce_dice_loss: 0.2027\n",
            "Epoch 28: val_IoU improved from 0.67062 to 0.68825, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 671ms/step - loss: 0.1189 - acc: 0.9767 - dice_coeff: 0.8811 - IoU: 0.7160 - bce_dice_loss: 0.2027 - val_loss: 0.1486 - val_acc: 0.9666 - val_dice_coeff: 0.8548 - val_IoU: 0.6883 - val_bce_dice_loss: 0.2733 - lr: 1.0000e-04\n",
            "Epoch 29/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1084 - acc: 0.9782 - dice_coeff: 0.8916 - IoU: 0.7304 - bce_dice_loss: 0.1837\n",
            "Epoch 29: val_IoU improved from 0.68825 to 0.69690, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 670ms/step - loss: 0.1084 - acc: 0.9782 - dice_coeff: 0.8916 - IoU: 0.7304 - bce_dice_loss: 0.1837 - val_loss: 0.1456 - val_acc: 0.9663 - val_dice_coeff: 0.8579 - val_IoU: 0.6969 - val_bce_dice_loss: 0.2751 - lr: 1.0000e-04\n",
            "Epoch 30/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1056 - acc: 0.9786 - dice_coeff: 0.8944 - IoU: 0.7385 - bce_dice_loss: 0.1807\n",
            "Epoch 30: val_IoU improved from 0.69690 to 0.70092, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 671ms/step - loss: 0.1056 - acc: 0.9786 - dice_coeff: 0.8944 - IoU: 0.7385 - bce_dice_loss: 0.1807 - val_loss: 0.1413 - val_acc: 0.9676 - val_dice_coeff: 0.8624 - val_IoU: 0.7009 - val_bce_dice_loss: 0.2562 - lr: 1.0000e-04\n",
            "Epoch 31/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0997 - acc: 0.9791 - dice_coeff: 0.9003 - IoU: 0.7475 - bce_dice_loss: 0.1703\n",
            "Epoch 31: val_IoU improved from 0.70092 to 0.71131, saving model to best_model.h5\n",
            "50/50 [==============================] - 35s 696ms/step - loss: 0.0997 - acc: 0.9791 - dice_coeff: 0.9003 - IoU: 0.7475 - bce_dice_loss: 0.1703 - val_loss: 0.1375 - val_acc: 0.9673 - val_dice_coeff: 0.8662 - val_IoU: 0.7113 - val_bce_dice_loss: 0.2576 - lr: 1.0000e-04\n",
            "Epoch 32/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0982 - acc: 0.9786 - dice_coeff: 0.9018 - IoU: 0.7534 - bce_dice_loss: 0.1715\n",
            "Epoch 32: val_IoU improved from 0.71131 to 0.71326, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 674ms/step - loss: 0.0982 - acc: 0.9786 - dice_coeff: 0.9018 - IoU: 0.7534 - bce_dice_loss: 0.1715 - val_loss: 0.1344 - val_acc: 0.9672 - val_dice_coeff: 0.8690 - val_IoU: 0.7133 - val_bce_dice_loss: 0.2608 - lr: 1.0000e-04\n",
            "Epoch 33/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0927 - acc: 0.9796 - dice_coeff: 0.9073 - IoU: 0.7621 - bce_dice_loss: 0.1604\n",
            "Epoch 33: val_IoU improved from 0.71326 to 0.72061, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 671ms/step - loss: 0.0927 - acc: 0.9796 - dice_coeff: 0.9073 - IoU: 0.7621 - bce_dice_loss: 0.1604 - val_loss: 0.1346 - val_acc: 0.9667 - val_dice_coeff: 0.8695 - val_IoU: 0.7206 - val_bce_dice_loss: 0.2610 - lr: 1.0000e-04\n",
            "Epoch 34/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0900 - acc: 0.9799 - dice_coeff: 0.9100 - IoU: 0.7691 - bce_dice_loss: 0.1552\n",
            "Epoch 34: val_IoU improved from 0.72061 to 0.72158, saving model to best_model.h5\n",
            "50/50 [==============================] - 35s 694ms/step - loss: 0.0900 - acc: 0.9799 - dice_coeff: 0.9100 - IoU: 0.7691 - bce_dice_loss: 0.1552 - val_loss: 0.1329 - val_acc: 0.9666 - val_dice_coeff: 0.8711 - val_IoU: 0.7216 - val_bce_dice_loss: 0.2563 - lr: 1.0000e-04\n",
            "Epoch 35/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0869 - acc: 0.9802 - dice_coeff: 0.9131 - IoU: 0.7758 - bce_dice_loss: 0.1497\n",
            "Epoch 35: val_IoU improved from 0.72158 to 0.72773, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 677ms/step - loss: 0.0869 - acc: 0.9802 - dice_coeff: 0.9131 - IoU: 0.7758 - bce_dice_loss: 0.1497 - val_loss: 0.1318 - val_acc: 0.9655 - val_dice_coeff: 0.8727 - val_IoU: 0.7277 - val_bce_dice_loss: 0.2718 - lr: 1.0000e-04\n",
            "Epoch 36/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0833 - acc: 0.9802 - dice_coeff: 0.9167 - IoU: 0.7822 - bce_dice_loss: 0.1463\n",
            "Epoch 36: val_IoU improved from 0.72773 to 0.73120, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 673ms/step - loss: 0.0833 - acc: 0.9802 - dice_coeff: 0.9167 - IoU: 0.7822 - bce_dice_loss: 0.1463 - val_loss: 0.1294 - val_acc: 0.9665 - val_dice_coeff: 0.8751 - val_IoU: 0.7312 - val_bce_dice_loss: 0.2525 - lr: 1.0000e-04\n",
            "Epoch 37/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0811 - acc: 0.9803 - dice_coeff: 0.9189 - IoU: 0.7868 - bce_dice_loss: 0.1436\n",
            "Epoch 37: val_IoU improved from 0.73120 to 0.74134, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 670ms/step - loss: 0.0811 - acc: 0.9803 - dice_coeff: 0.9189 - IoU: 0.7868 - bce_dice_loss: 0.1436 - val_loss: 0.1239 - val_acc: 0.9669 - val_dice_coeff: 0.8805 - val_IoU: 0.7413 - val_bce_dice_loss: 0.2491 - lr: 1.0000e-04\n",
            "Epoch 38/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0760 - acc: 0.9807 - dice_coeff: 0.9240 - IoU: 0.7949 - bce_dice_loss: 0.1355\n",
            "Epoch 38: val_IoU improved from 0.74134 to 0.74410, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 673ms/step - loss: 0.0760 - acc: 0.9807 - dice_coeff: 0.9240 - IoU: 0.7949 - bce_dice_loss: 0.1355 - val_loss: 0.1239 - val_acc: 0.9668 - val_dice_coeff: 0.8803 - val_IoU: 0.7441 - val_bce_dice_loss: 0.2500 - lr: 1.0000e-04\n",
            "Epoch 39/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0758 - acc: 0.9807 - dice_coeff: 0.9242 - IoU: 0.7991 - bce_dice_loss: 0.1349\n",
            "Epoch 39: val_IoU improved from 0.74410 to 0.74474, saving model to best_model.h5\n",
            "50/50 [==============================] - 33s 669ms/step - loss: 0.0758 - acc: 0.9807 - dice_coeff: 0.9242 - IoU: 0.7991 - bce_dice_loss: 0.1349 - val_loss: 0.1246 - val_acc: 0.9658 - val_dice_coeff: 0.8800 - val_IoU: 0.7447 - val_bce_dice_loss: 0.2583 - lr: 1.0000e-04\n",
            "Epoch 40/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0729 - acc: 0.9810 - dice_coeff: 0.9271 - IoU: 0.8058 - bce_dice_loss: 0.1316\n",
            "Epoch 40: val_IoU improved from 0.74474 to 0.75216, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0729 - acc: 0.9810 - dice_coeff: 0.9271 - IoU: 0.8058 - bce_dice_loss: 0.1316 - val_loss: 0.1170 - val_acc: 0.9675 - val_dice_coeff: 0.8863 - val_IoU: 0.7522 - val_bce_dice_loss: 0.2475 - lr: 1.0000e-04\n",
            "Epoch 41/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0700 - acc: 0.9809 - dice_coeff: 0.9300 - IoU: 0.8097 - bce_dice_loss: 0.1280\n",
            "Epoch 41: val_IoU did not improve from 0.75216\n",
            "50/50 [==============================] - 33s 659ms/step - loss: 0.0700 - acc: 0.9809 - dice_coeff: 0.9300 - IoU: 0.8097 - bce_dice_loss: 0.1280 - val_loss: 0.1189 - val_acc: 0.9664 - val_dice_coeff: 0.8827 - val_IoU: 0.7488 - val_bce_dice_loss: 0.2564 - lr: 1.0000e-04\n",
            "Epoch 42/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0679 - acc: 0.9814 - dice_coeff: 0.9321 - IoU: 0.8152 - bce_dice_loss: 0.1234\n",
            "Epoch 42: val_IoU improved from 0.75216 to 0.75610, saving model to best_model.h5\n",
            "50/50 [==============================] - 35s 698ms/step - loss: 0.0679 - acc: 0.9814 - dice_coeff: 0.9321 - IoU: 0.8152 - bce_dice_loss: 0.1234 - val_loss: 0.1161 - val_acc: 0.9671 - val_dice_coeff: 0.8879 - val_IoU: 0.7561 - val_bce_dice_loss: 0.2445 - lr: 1.0000e-04\n",
            "Epoch 43/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0651 - acc: 0.9814 - dice_coeff: 0.9349 - IoU: 0.8194 - bce_dice_loss: 0.1212\n",
            "Epoch 43: val_IoU improved from 0.75610 to 0.75876, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0651 - acc: 0.9814 - dice_coeff: 0.9349 - IoU: 0.8194 - bce_dice_loss: 0.1212 - val_loss: 0.1166 - val_acc: 0.9665 - val_dice_coeff: 0.8877 - val_IoU: 0.7588 - val_bce_dice_loss: 0.2504 - lr: 1.0000e-04\n",
            "Epoch 44/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0639 - acc: 0.9819 - dice_coeff: 0.9361 - IoU: 0.8251 - bce_dice_loss: 0.1165\n",
            "Epoch 44: val_IoU improved from 0.75876 to 0.76176, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 676ms/step - loss: 0.0639 - acc: 0.9819 - dice_coeff: 0.9361 - IoU: 0.8251 - bce_dice_loss: 0.1165 - val_loss: 0.1155 - val_acc: 0.9664 - val_dice_coeff: 0.8887 - val_IoU: 0.7618 - val_bce_dice_loss: 0.2529 - lr: 1.0000e-04\n",
            "Epoch 45/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0608 - acc: 0.9821 - dice_coeff: 0.9392 - IoU: 0.8304 - bce_dice_loss: 0.1123\n",
            "Epoch 45: val_IoU improved from 0.76176 to 0.76411, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0608 - acc: 0.9821 - dice_coeff: 0.9392 - IoU: 0.8304 - bce_dice_loss: 0.1123 - val_loss: 0.1154 - val_acc: 0.9660 - val_dice_coeff: 0.8889 - val_IoU: 0.7641 - val_bce_dice_loss: 0.2579 - lr: 1.0000e-04\n",
            "Epoch 46/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0609 - acc: 0.9820 - dice_coeff: 0.9391 - IoU: 0.8321 - bce_dice_loss: 0.1119\n",
            "Epoch 46: val_IoU improved from 0.76411 to 0.76559, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 674ms/step - loss: 0.0609 - acc: 0.9820 - dice_coeff: 0.9391 - IoU: 0.8321 - bce_dice_loss: 0.1119 - val_loss: 0.1156 - val_acc: 0.9659 - val_dice_coeff: 0.8892 - val_IoU: 0.7656 - val_bce_dice_loss: 0.2529 - lr: 1.0000e-04\n",
            "Epoch 47/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0593 - acc: 0.9821 - dice_coeff: 0.9407 - IoU: 0.8351 - bce_dice_loss: 0.1105\n",
            "Epoch 47: val_IoU did not improve from 0.76559\n",
            "50/50 [==============================] - 34s 681ms/step - loss: 0.0593 - acc: 0.9821 - dice_coeff: 0.9407 - IoU: 0.8351 - bce_dice_loss: 0.1105 - val_loss: 0.1140 - val_acc: 0.9661 - val_dice_coeff: 0.8892 - val_IoU: 0.7636 - val_bce_dice_loss: 0.2540 - lr: 1.0000e-04\n",
            "Epoch 48/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0596 - acc: 0.9815 - dice_coeff: 0.9404 - IoU: 0.8366 - bce_dice_loss: 0.1140\n",
            "Epoch 48: val_IoU improved from 0.76559 to 0.77251, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 671ms/step - loss: 0.0596 - acc: 0.9815 - dice_coeff: 0.9404 - IoU: 0.8366 - bce_dice_loss: 0.1140 - val_loss: 0.1122 - val_acc: 0.9662 - val_dice_coeff: 0.8926 - val_IoU: 0.7725 - val_bce_dice_loss: 0.2593 - lr: 1.0000e-04\n",
            "Epoch 49/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0559 - acc: 0.9820 - dice_coeff: 0.9441 - IoU: 0.8438 - bce_dice_loss: 0.1064\n",
            "Epoch 49: val_IoU improved from 0.77251 to 0.77551, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 675ms/step - loss: 0.0559 - acc: 0.9820 - dice_coeff: 0.9441 - IoU: 0.8438 - bce_dice_loss: 0.1064 - val_loss: 0.1112 - val_acc: 0.9659 - val_dice_coeff: 0.8933 - val_IoU: 0.7755 - val_bce_dice_loss: 0.2578 - lr: 1.0000e-04\n",
            "Epoch 50/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0559 - acc: 0.9823 - dice_coeff: 0.9441 - IoU: 0.8465 - bce_dice_loss: 0.1054\n",
            "Epoch 50: val_IoU did not improve from 0.77551\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.0559 - acc: 0.9823 - dice_coeff: 0.9441 - IoU: 0.8465 - bce_dice_loss: 0.1054 - val_loss: 0.1135 - val_acc: 0.9651 - val_dice_coeff: 0.8914 - val_IoU: 0.7726 - val_bce_dice_loss: 0.2677 - lr: 1.0000e-04\n",
            "Epoch 51/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0534 - acc: 0.9823 - dice_coeff: 0.9466 - IoU: 0.8504 - bce_dice_loss: 0.1040\n",
            "Epoch 51: val_IoU improved from 0.77551 to 0.77586, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 675ms/step - loss: 0.0534 - acc: 0.9823 - dice_coeff: 0.9466 - IoU: 0.8504 - bce_dice_loss: 0.1040 - val_loss: 0.1136 - val_acc: 0.9649 - val_dice_coeff: 0.8911 - val_IoU: 0.7759 - val_bce_dice_loss: 0.2676 - lr: 1.0000e-04\n",
            "Epoch 52/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0524 - acc: 0.9826 - dice_coeff: 0.9476 - IoU: 0.8542 - bce_dice_loss: 0.1006\n",
            "Epoch 52: val_IoU improved from 0.77586 to 0.78136, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0524 - acc: 0.9826 - dice_coeff: 0.9476 - IoU: 0.8542 - bce_dice_loss: 0.1006 - val_loss: 0.1099 - val_acc: 0.9659 - val_dice_coeff: 0.8950 - val_IoU: 0.7814 - val_bce_dice_loss: 0.2536 - lr: 1.0000e-04\n",
            "Epoch 53/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0503 - acc: 0.9829 - dice_coeff: 0.9497 - IoU: 0.8585 - bce_dice_loss: 0.0968\n",
            "Epoch 53: val_IoU improved from 0.78136 to 0.78308, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 673ms/step - loss: 0.0503 - acc: 0.9829 - dice_coeff: 0.9497 - IoU: 0.8585 - bce_dice_loss: 0.0968 - val_loss: 0.1071 - val_acc: 0.9664 - val_dice_coeff: 0.8976 - val_IoU: 0.7831 - val_bce_dice_loss: 0.2536 - lr: 1.0000e-04\n",
            "Epoch 54/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0508 - acc: 0.9828 - dice_coeff: 0.9492 - IoU: 0.8601 - bce_dice_loss: 0.0977\n",
            "Epoch 54: val_IoU did not improve from 0.78308\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0508 - acc: 0.9828 - dice_coeff: 0.9492 - IoU: 0.8601 - bce_dice_loss: 0.0977 - val_loss: 0.1070 - val_acc: 0.9662 - val_dice_coeff: 0.8973 - val_IoU: 0.7823 - val_bce_dice_loss: 0.2549 - lr: 1.0000e-04\n",
            "Epoch 55/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0496 - acc: 0.9826 - dice_coeff: 0.9504 - IoU: 0.8609 - bce_dice_loss: 0.0984\n",
            "Epoch 55: val_IoU did not improve from 0.78308\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0496 - acc: 0.9826 - dice_coeff: 0.9504 - IoU: 0.8609 - bce_dice_loss: 0.0984 - val_loss: 0.1100 - val_acc: 0.9656 - val_dice_coeff: 0.8951 - val_IoU: 0.7820 - val_bce_dice_loss: 0.2562 - lr: 1.0000e-04\n",
            "Epoch 56/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0560 - acc: 0.9805 - dice_coeff: 0.9440 - IoU: 0.8558 - bce_dice_loss: 0.1224\n",
            "Epoch 56: val_IoU improved from 0.78308 to 0.78463, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0560 - acc: 0.9805 - dice_coeff: 0.9440 - IoU: 0.8558 - bce_dice_loss: 0.1224 - val_loss: 0.1160 - val_acc: 0.9635 - val_dice_coeff: 0.8903 - val_IoU: 0.7846 - val_bce_dice_loss: 0.2736 - lr: 1.0000e-04\n",
            "Epoch 57/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0586 - acc: 0.9794 - dice_coeff: 0.9414 - IoU: 0.8480 - bce_dice_loss: 0.1292\n",
            "Epoch 57: val_IoU improved from 0.78463 to 0.79247, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0586 - acc: 0.9794 - dice_coeff: 0.9414 - IoU: 0.8480 - bce_dice_loss: 0.1292 - val_loss: 0.1006 - val_acc: 0.9674 - val_dice_coeff: 0.9044 - val_IoU: 0.7925 - val_bce_dice_loss: 0.2415 - lr: 1.0000e-04\n",
            "Epoch 58/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0556 - acc: 0.9803 - dice_coeff: 0.9444 - IoU: 0.8556 - bce_dice_loss: 0.1205\n",
            "Epoch 58: val_IoU improved from 0.79247 to 0.79259, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 670ms/step - loss: 0.0556 - acc: 0.9803 - dice_coeff: 0.9444 - IoU: 0.8556 - bce_dice_loss: 0.1205 - val_loss: 0.1018 - val_acc: 0.9668 - val_dice_coeff: 0.9028 - val_IoU: 0.7926 - val_bce_dice_loss: 0.2486 - lr: 1.0000e-04\n",
            "Epoch 59/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0586 - acc: 0.9793 - dice_coeff: 0.9414 - IoU: 0.8522 - bce_dice_loss: 0.1284\n",
            "Epoch 59: val_IoU did not improve from 0.79259\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0586 - acc: 0.9793 - dice_coeff: 0.9414 - IoU: 0.8522 - bce_dice_loss: 0.1284 - val_loss: 0.1470 - val_acc: 0.9557 - val_dice_coeff: 0.8620 - val_IoU: 0.7550 - val_bce_dice_loss: 0.3436 - lr: 1.0000e-04\n",
            "Epoch 60/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0641 - acc: 0.9775 - dice_coeff: 0.9359 - IoU: 0.8472 - bce_dice_loss: 0.1482\n",
            "Epoch 60: val_IoU did not improve from 0.79259\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.0641 - acc: 0.9775 - dice_coeff: 0.9359 - IoU: 0.8472 - bce_dice_loss: 0.1482 - val_loss: 0.1277 - val_acc: 0.9567 - val_dice_coeff: 0.8720 - val_IoU: 0.7551 - val_bce_dice_loss: 0.3907 - lr: 1.0000e-04\n",
            "Epoch 61/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0569 - acc: 0.9792 - dice_coeff: 0.9431 - IoU: 0.8518 - bce_dice_loss: 0.1299\n",
            "Epoch 61: val_IoU did not improve from 0.79259\n",
            "50/50 [==============================] - 34s 685ms/step - loss: 0.0569 - acc: 0.9792 - dice_coeff: 0.9431 - IoU: 0.8518 - bce_dice_loss: 0.1299 - val_loss: 0.1063 - val_acc: 0.9652 - val_dice_coeff: 0.8991 - val_IoU: 0.7889 - val_bce_dice_loss: 0.2610 - lr: 1.0000e-04\n",
            "Epoch 62/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0503 - acc: 0.9809 - dice_coeff: 0.9497 - IoU: 0.8653 - bce_dice_loss: 0.1123\n",
            "Epoch 62: val_IoU improved from 0.79259 to 0.79809, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 671ms/step - loss: 0.0503 - acc: 0.9809 - dice_coeff: 0.9497 - IoU: 0.8653 - bce_dice_loss: 0.1123 - val_loss: 0.1009 - val_acc: 0.9666 - val_dice_coeff: 0.9038 - val_IoU: 0.7981 - val_bce_dice_loss: 0.2525 - lr: 1.0000e-04\n",
            "Epoch 63/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0465 - acc: 0.9821 - dice_coeff: 0.9535 - IoU: 0.8725 - bce_dice_loss: 0.1001\n",
            "Epoch 63: val_IoU did not improve from 0.79809\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0465 - acc: 0.9821 - dice_coeff: 0.9535 - IoU: 0.8725 - bce_dice_loss: 0.1001 - val_loss: 0.1052 - val_acc: 0.9648 - val_dice_coeff: 0.8996 - val_IoU: 0.7940 - val_bce_dice_loss: 0.2760 - lr: 1.0000e-04\n",
            "Epoch 64/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0484 - acc: 0.9816 - dice_coeff: 0.9516 - IoU: 0.8720 - bce_dice_loss: 0.1057\n",
            "Epoch 64: val_IoU did not improve from 0.79809\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0484 - acc: 0.9816 - dice_coeff: 0.9516 - IoU: 0.8720 - bce_dice_loss: 0.1057 - val_loss: 0.1061 - val_acc: 0.9647 - val_dice_coeff: 0.8989 - val_IoU: 0.7925 - val_bce_dice_loss: 0.2707 - lr: 1.0000e-04\n",
            "Epoch 65/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.9814 - dice_coeff: 0.9514 - IoU: 0.8725 - bce_dice_loss: 0.1072\n",
            "Epoch 65: val_IoU did not improve from 0.79809\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0486 - acc: 0.9814 - dice_coeff: 0.9514 - IoU: 0.8725 - bce_dice_loss: 0.1072 - val_loss: 0.1145 - val_acc: 0.9624 - val_dice_coeff: 0.8908 - val_IoU: 0.7896 - val_bce_dice_loss: 0.2937 - lr: 1.0000e-04\n",
            "Epoch 66/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0462 - acc: 0.9816 - dice_coeff: 0.9538 - IoU: 0.8745 - bce_dice_loss: 0.1053\n",
            "Epoch 66: val_IoU improved from 0.79809 to 0.80086, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0462 - acc: 0.9816 - dice_coeff: 0.9538 - IoU: 0.8745 - bce_dice_loss: 0.1053 - val_loss: 0.1033 - val_acc: 0.9653 - val_dice_coeff: 0.9017 - val_IoU: 0.8009 - val_bce_dice_loss: 0.2767 - lr: 1.0000e-04\n",
            "Epoch 67/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0431 - acc: 0.9824 - dice_coeff: 0.9569 - IoU: 0.8801 - bce_dice_loss: 0.0962\n",
            "Epoch 67: val_IoU improved from 0.80086 to 0.80611, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 674ms/step - loss: 0.0431 - acc: 0.9824 - dice_coeff: 0.9569 - IoU: 0.8801 - bce_dice_loss: 0.0962 - val_loss: 0.1005 - val_acc: 0.9660 - val_dice_coeff: 0.9044 - val_IoU: 0.8061 - val_bce_dice_loss: 0.2675 - lr: 1.0000e-04\n",
            "Epoch 68/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0417 - acc: 0.9829 - dice_coeff: 0.9583 - IoU: 0.8833 - bce_dice_loss: 0.0916\n",
            "Epoch 68: val_IoU did not improve from 0.80611\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0417 - acc: 0.9829 - dice_coeff: 0.9583 - IoU: 0.8833 - bce_dice_loss: 0.0916 - val_loss: 0.0998 - val_acc: 0.9662 - val_dice_coeff: 0.9052 - val_IoU: 0.8047 - val_bce_dice_loss: 0.2633 - lr: 1.0000e-04\n",
            "Epoch 69/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0397 - acc: 0.9832 - dice_coeff: 0.9603 - IoU: 0.8875 - bce_dice_loss: 0.0880\n",
            "Epoch 69: val_IoU improved from 0.80611 to 0.80644, saving model to best_model.h5\n",
            "50/50 [==============================] - 35s 698ms/step - loss: 0.0397 - acc: 0.9832 - dice_coeff: 0.9603 - IoU: 0.8875 - bce_dice_loss: 0.0880 - val_loss: 0.1006 - val_acc: 0.9660 - val_dice_coeff: 0.9046 - val_IoU: 0.8064 - val_bce_dice_loss: 0.2624 - lr: 1.0000e-04\n",
            "Epoch 70/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0395 - acc: 0.9832 - dice_coeff: 0.9605 - IoU: 0.8895 - bce_dice_loss: 0.0886\n",
            "Epoch 70: val_IoU improved from 0.80644 to 0.80889, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 677ms/step - loss: 0.0395 - acc: 0.9832 - dice_coeff: 0.9605 - IoU: 0.8895 - bce_dice_loss: 0.0886 - val_loss: 0.0983 - val_acc: 0.9666 - val_dice_coeff: 0.9065 - val_IoU: 0.8089 - val_bce_dice_loss: 0.2594 - lr: 1.0000e-04\n",
            "Epoch 71/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0396 - acc: 0.9833 - dice_coeff: 0.9604 - IoU: 0.8916 - bce_dice_loss: 0.0871\n",
            "Epoch 71: val_IoU did not improve from 0.80889\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0396 - acc: 0.9833 - dice_coeff: 0.9604 - IoU: 0.8916 - bce_dice_loss: 0.0871 - val_loss: 0.0982 - val_acc: 0.9666 - val_dice_coeff: 0.9066 - val_IoU: 0.8070 - val_bce_dice_loss: 0.2589 - lr: 1.0000e-04\n",
            "Epoch 72/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.9833 - dice_coeff: 0.9615 - IoU: 0.8923 - bce_dice_loss: 0.0870\n",
            "Epoch 72: val_IoU improved from 0.80889 to 0.81403, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 676ms/step - loss: 0.0385 - acc: 0.9833 - dice_coeff: 0.9615 - IoU: 0.8923 - bce_dice_loss: 0.0870 - val_loss: 0.0974 - val_acc: 0.9666 - val_dice_coeff: 0.9076 - val_IoU: 0.8140 - val_bce_dice_loss: 0.2616 - lr: 1.0000e-04\n",
            "Epoch 73/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0381 - acc: 0.9833 - dice_coeff: 0.9619 - IoU: 0.8948 - bce_dice_loss: 0.0867\n",
            "Epoch 73: val_IoU improved from 0.81403 to 0.81557, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 673ms/step - loss: 0.0381 - acc: 0.9833 - dice_coeff: 0.9619 - IoU: 0.8948 - bce_dice_loss: 0.0867 - val_loss: 0.0948 - val_acc: 0.9673 - val_dice_coeff: 0.9096 - val_IoU: 0.8156 - val_bce_dice_loss: 0.2544 - lr: 1.0000e-04\n",
            "Epoch 74/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0365 - acc: 0.9836 - dice_coeff: 0.9635 - IoU: 0.8971 - bce_dice_loss: 0.0828\n",
            "Epoch 74: val_IoU did not improve from 0.81557\n",
            "50/50 [==============================] - 33s 659ms/step - loss: 0.0365 - acc: 0.9836 - dice_coeff: 0.9635 - IoU: 0.8971 - bce_dice_loss: 0.0828 - val_loss: 0.0951 - val_acc: 0.9671 - val_dice_coeff: 0.9094 - val_IoU: 0.8122 - val_bce_dice_loss: 0.2583 - lr: 1.0000e-04\n",
            "Epoch 75/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0362 - acc: 0.9837 - dice_coeff: 0.9638 - IoU: 0.8975 - bce_dice_loss: 0.0824\n",
            "Epoch 75: val_IoU did not improve from 0.81557\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0362 - acc: 0.9837 - dice_coeff: 0.9638 - IoU: 0.8975 - bce_dice_loss: 0.0824 - val_loss: 0.0937 - val_acc: 0.9672 - val_dice_coeff: 0.9108 - val_IoU: 0.8136 - val_bce_dice_loss: 0.2599 - lr: 1.0000e-04\n",
            "Epoch 76/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0366 - acc: 0.9836 - dice_coeff: 0.9634 - IoU: 0.8984 - bce_dice_loss: 0.0834\n",
            "Epoch 76: val_IoU improved from 0.81557 to 0.81680, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 674ms/step - loss: 0.0366 - acc: 0.9836 - dice_coeff: 0.9634 - IoU: 0.8984 - bce_dice_loss: 0.0834 - val_loss: 0.0937 - val_acc: 0.9672 - val_dice_coeff: 0.9108 - val_IoU: 0.8168 - val_bce_dice_loss: 0.2613 - lr: 1.0000e-04\n",
            "Epoch 77/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0352 - acc: 0.9839 - dice_coeff: 0.9648 - IoU: 0.9010 - bce_dice_loss: 0.0804\n",
            "Epoch 77: val_IoU did not improve from 0.81680\n",
            "50/50 [==============================] - 33s 666ms/step - loss: 0.0352 - acc: 0.9839 - dice_coeff: 0.9648 - IoU: 0.9010 - bce_dice_loss: 0.0804 - val_loss: 0.0976 - val_acc: 0.9660 - val_dice_coeff: 0.9073 - val_IoU: 0.8145 - val_bce_dice_loss: 0.2791 - lr: 1.0000e-04\n",
            "Epoch 78/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0345 - acc: 0.9839 - dice_coeff: 0.9655 - IoU: 0.9026 - bce_dice_loss: 0.0796\n",
            "Epoch 78: val_IoU did not improve from 0.81680\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.0345 - acc: 0.9839 - dice_coeff: 0.9655 - IoU: 0.9026 - bce_dice_loss: 0.0796 - val_loss: 0.0944 - val_acc: 0.9669 - val_dice_coeff: 0.9101 - val_IoU: 0.8164 - val_bce_dice_loss: 0.2692 - lr: 1.0000e-04\n",
            "Epoch 79/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.9839 - dice_coeff: 0.9656 - IoU: 0.9038 - bce_dice_loss: 0.0802\n",
            "Epoch 79: val_IoU did not improve from 0.81680\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0344 - acc: 0.9839 - dice_coeff: 0.9656 - IoU: 0.9038 - bce_dice_loss: 0.0802 - val_loss: 0.0960 - val_acc: 0.9664 - val_dice_coeff: 0.9089 - val_IoU: 0.8159 - val_bce_dice_loss: 0.2709 - lr: 1.0000e-04\n",
            "Epoch 80/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0342 - acc: 0.9839 - dice_coeff: 0.9658 - IoU: 0.9045 - bce_dice_loss: 0.0803\n",
            "Epoch 80: val_IoU improved from 0.81680 to 0.81827, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 671ms/step - loss: 0.0342 - acc: 0.9839 - dice_coeff: 0.9658 - IoU: 0.9045 - bce_dice_loss: 0.0803 - val_loss: 0.0946 - val_acc: 0.9666 - val_dice_coeff: 0.9101 - val_IoU: 0.8183 - val_bce_dice_loss: 0.2742 - lr: 1.0000e-04\n",
            "Epoch 81/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0336 - acc: 0.9838 - dice_coeff: 0.9664 - IoU: 0.9060 - bce_dice_loss: 0.0815\n",
            "Epoch 81: val_IoU did not improve from 0.81827\n",
            "50/50 [==============================] - 34s 683ms/step - loss: 0.0336 - acc: 0.9838 - dice_coeff: 0.9664 - IoU: 0.9060 - bce_dice_loss: 0.0815 - val_loss: 0.0940 - val_acc: 0.9669 - val_dice_coeff: 0.9106 - val_IoU: 0.8180 - val_bce_dice_loss: 0.2671 - lr: 1.0000e-04\n",
            "Epoch 82/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0333 - acc: 0.9839 - dice_coeff: 0.9667 - IoU: 0.9074 - bce_dice_loss: 0.0806\n",
            "Epoch 82: val_IoU did not improve from 0.81827\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0333 - acc: 0.9839 - dice_coeff: 0.9667 - IoU: 0.9074 - bce_dice_loss: 0.0806 - val_loss: 0.0963 - val_acc: 0.9662 - val_dice_coeff: 0.9085 - val_IoU: 0.8169 - val_bce_dice_loss: 0.2798 - lr: 1.0000e-04\n",
            "Epoch 83/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0336 - acc: 0.9838 - dice_coeff: 0.9664 - IoU: 0.9067 - bce_dice_loss: 0.0813\n",
            "Epoch 83: val_IoU improved from 0.81827 to 0.82034, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0336 - acc: 0.9838 - dice_coeff: 0.9664 - IoU: 0.9067 - bce_dice_loss: 0.0813 - val_loss: 0.0943 - val_acc: 0.9666 - val_dice_coeff: 0.9105 - val_IoU: 0.8203 - val_bce_dice_loss: 0.2804 - lr: 1.0000e-04\n",
            "Epoch 84/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0330 - acc: 0.9839 - dice_coeff: 0.9670 - IoU: 0.9072 - bce_dice_loss: 0.0798\n",
            "Epoch 84: val_IoU did not improve from 0.82034\n",
            "50/50 [==============================] - 34s 689ms/step - loss: 0.0330 - acc: 0.9839 - dice_coeff: 0.9670 - IoU: 0.9072 - bce_dice_loss: 0.0798 - val_loss: 0.1033 - val_acc: 0.9645 - val_dice_coeff: 0.9008 - val_IoU: 0.8097 - val_bce_dice_loss: 0.2865 - lr: 1.0000e-04\n",
            "Epoch 85/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0507 - acc: 0.9789 - dice_coeff: 0.9493 - IoU: 0.8788 - bce_dice_loss: 0.1374\n",
            "Epoch 85: val_IoU did not improve from 0.82034\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0507 - acc: 0.9789 - dice_coeff: 0.9493 - IoU: 0.8788 - bce_dice_loss: 0.1374 - val_loss: 0.1259 - val_acc: 0.9573 - val_dice_coeff: 0.8722 - val_IoU: 0.7783 - val_bce_dice_loss: 0.4037 - lr: 1.0000e-04\n",
            "Epoch 86/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0932 - acc: 0.9653 - dice_coeff: 0.9068 - IoU: 0.8257 - bce_dice_loss: 0.2910\n",
            "Epoch 86: val_IoU did not improve from 0.82034\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.0932 - acc: 0.9653 - dice_coeff: 0.9068 - IoU: 0.8257 - bce_dice_loss: 0.2910 - val_loss: 0.1120 - val_acc: 0.9612 - val_dice_coeff: 0.8924 - val_IoU: 0.7928 - val_bce_dice_loss: 0.3381 - lr: 1.0000e-04\n",
            "Epoch 87/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0648 - acc: 0.9746 - dice_coeff: 0.9352 - IoU: 0.8548 - bce_dice_loss: 0.1838\n",
            "Epoch 87: val_IoU did not improve from 0.82034\n",
            "50/50 [==============================] - 34s 685ms/step - loss: 0.0648 - acc: 0.9746 - dice_coeff: 0.9352 - IoU: 0.8548 - bce_dice_loss: 0.1838 - val_loss: 0.1037 - val_acc: 0.9633 - val_dice_coeff: 0.9009 - val_IoU: 0.8177 - val_bce_dice_loss: 0.3211 - lr: 1.0000e-04\n",
            "Epoch 88/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0492 - acc: 0.9792 - dice_coeff: 0.9508 - IoU: 0.8809 - bce_dice_loss: 0.1350\n",
            "Epoch 88: val_IoU improved from 0.82034 to 0.82186, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 680ms/step - loss: 0.0492 - acc: 0.9792 - dice_coeff: 0.9508 - IoU: 0.8809 - bce_dice_loss: 0.1350 - val_loss: 0.0969 - val_acc: 0.9656 - val_dice_coeff: 0.9073 - val_IoU: 0.8219 - val_bce_dice_loss: 0.2787 - lr: 1.0000e-04\n",
            "Epoch 89/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.9805 - dice_coeff: 0.9567 - IoU: 0.8912 - bce_dice_loss: 0.1164\n",
            "Epoch 89: val_IoU did not improve from 0.82186\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0433 - acc: 0.9805 - dice_coeff: 0.9567 - IoU: 0.8912 - bce_dice_loss: 0.1164 - val_loss: 0.0958 - val_acc: 0.9656 - val_dice_coeff: 0.9050 - val_IoU: 0.8115 - val_bce_dice_loss: 0.2808 - lr: 1.0000e-04\n",
            "Epoch 90/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0415 - acc: 0.9811 - dice_coeff: 0.9585 - IoU: 0.8938 - bce_dice_loss: 0.1131\n",
            "Epoch 90: val_IoU improved from 0.82186 to 0.83698, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0415 - acc: 0.9811 - dice_coeff: 0.9585 - IoU: 0.8938 - bce_dice_loss: 0.1131 - val_loss: 0.0835 - val_acc: 0.9693 - val_dice_coeff: 0.9207 - val_IoU: 0.8370 - val_bce_dice_loss: 0.2427 - lr: 1.0000e-04\n",
            "Epoch 91/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0374 - acc: 0.9823 - dice_coeff: 0.9626 - IoU: 0.9017 - bce_dice_loss: 0.0992\n",
            "Epoch 91: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 34s 683ms/step - loss: 0.0374 - acc: 0.9823 - dice_coeff: 0.9626 - IoU: 0.9017 - bce_dice_loss: 0.0992 - val_loss: 0.0842 - val_acc: 0.9691 - val_dice_coeff: 0.9198 - val_IoU: 0.8330 - val_bce_dice_loss: 0.2454 - lr: 1.0000e-04\n",
            "Epoch 92/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0358 - acc: 0.9826 - dice_coeff: 0.9642 - IoU: 0.9047 - bce_dice_loss: 0.0949\n",
            "Epoch 92: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0358 - acc: 0.9826 - dice_coeff: 0.9642 - IoU: 0.9047 - bce_dice_loss: 0.0949 - val_loss: 0.0831 - val_acc: 0.9691 - val_dice_coeff: 0.9200 - val_IoU: 0.8290 - val_bce_dice_loss: 0.2506 - lr: 1.0000e-04\n",
            "Epoch 93/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0339 - acc: 0.9833 - dice_coeff: 0.9661 - IoU: 0.9081 - bce_dice_loss: 0.0887\n",
            "Epoch 93: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0339 - acc: 0.9833 - dice_coeff: 0.9661 - IoU: 0.9081 - bce_dice_loss: 0.0887 - val_loss: 0.0843 - val_acc: 0.9687 - val_dice_coeff: 0.9185 - val_IoU: 0.8268 - val_bce_dice_loss: 0.2636 - lr: 1.0000e-04\n",
            "Epoch 94/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0336 - acc: 0.9832 - dice_coeff: 0.9664 - IoU: 0.9097 - bce_dice_loss: 0.0892\n",
            "Epoch 94: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 34s 682ms/step - loss: 0.0336 - acc: 0.9832 - dice_coeff: 0.9664 - IoU: 0.9097 - bce_dice_loss: 0.0892 - val_loss: 0.0918 - val_acc: 0.9671 - val_dice_coeff: 0.9118 - val_IoU: 0.8290 - val_bce_dice_loss: 0.2677 - lr: 1.0000e-04\n",
            "Epoch 95/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0333 - acc: 0.9832 - dice_coeff: 0.9667 - IoU: 0.9105 - bce_dice_loss: 0.0885\n",
            "Epoch 95: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 33s 659ms/step - loss: 0.0333 - acc: 0.9832 - dice_coeff: 0.9667 - IoU: 0.9105 - bce_dice_loss: 0.0885 - val_loss: 0.0889 - val_acc: 0.9676 - val_dice_coeff: 0.9143 - val_IoU: 0.8278 - val_bce_dice_loss: 0.2669 - lr: 1.0000e-04\n",
            "Epoch 96/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0329 - acc: 0.9834 - dice_coeff: 0.9671 - IoU: 0.9117 - bce_dice_loss: 0.0865\n",
            "Epoch 96: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 34s 685ms/step - loss: 0.0329 - acc: 0.9834 - dice_coeff: 0.9671 - IoU: 0.9117 - bce_dice_loss: 0.0865 - val_loss: 0.0869 - val_acc: 0.9683 - val_dice_coeff: 0.9167 - val_IoU: 0.8329 - val_bce_dice_loss: 0.2617 - lr: 1.0000e-04\n",
            "Epoch 97/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0313 - acc: 0.9838 - dice_coeff: 0.9687 - IoU: 0.9138 - bce_dice_loss: 0.0832\n",
            "Epoch 97: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.0313 - acc: 0.9838 - dice_coeff: 0.9687 - IoU: 0.9138 - bce_dice_loss: 0.0832 - val_loss: 0.0823 - val_acc: 0.9693 - val_dice_coeff: 0.9204 - val_IoU: 0.8351 - val_bce_dice_loss: 0.2577 - lr: 1.0000e-04\n",
            "Epoch 98/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0311 - acc: 0.9837 - dice_coeff: 0.9689 - IoU: 0.9153 - bce_dice_loss: 0.0837\n",
            "Epoch 98: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0311 - acc: 0.9837 - dice_coeff: 0.9689 - IoU: 0.9153 - bce_dice_loss: 0.0837 - val_loss: 0.0825 - val_acc: 0.9693 - val_dice_coeff: 0.9200 - val_IoU: 0.8345 - val_bce_dice_loss: 0.2564 - lr: 1.0000e-04\n",
            "Epoch 99/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0306 - acc: 0.9839 - dice_coeff: 0.9694 - IoU: 0.9158 - bce_dice_loss: 0.0825\n",
            "Epoch 99: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.0306 - acc: 0.9839 - dice_coeff: 0.9694 - IoU: 0.9158 - bce_dice_loss: 0.0825 - val_loss: 0.0814 - val_acc: 0.9696 - val_dice_coeff: 0.9214 - val_IoU: 0.8362 - val_bce_dice_loss: 0.2524 - lr: 1.0000e-04\n",
            "Epoch 100/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0304 - acc: 0.9839 - dice_coeff: 0.9696 - IoU: 0.9171 - bce_dice_loss: 0.0825\n",
            "Epoch 100: val_IoU did not improve from 0.83698\n",
            "50/50 [==============================] - 33s 657ms/step - loss: 0.0304 - acc: 0.9839 - dice_coeff: 0.9696 - IoU: 0.9171 - bce_dice_loss: 0.0825 - val_loss: 0.0831 - val_acc: 0.9691 - val_dice_coeff: 0.9199 - val_IoU: 0.8364 - val_bce_dice_loss: 0.2566 - lr: 1.0000e-04\n",
            "Epoch 101/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0296 - acc: 0.9841 - dice_coeff: 0.9704 - IoU: 0.9182 - bce_dice_loss: 0.0794\n",
            "Epoch 101: val_IoU improved from 0.83698 to 0.83897, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 678ms/step - loss: 0.0296 - acc: 0.9841 - dice_coeff: 0.9704 - IoU: 0.9182 - bce_dice_loss: 0.0794 - val_loss: 0.0807 - val_acc: 0.9698 - val_dice_coeff: 0.9222 - val_IoU: 0.8390 - val_bce_dice_loss: 0.2508 - lr: 1.0000e-04\n",
            "Epoch 102/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0289 - acc: 0.9842 - dice_coeff: 0.9711 - IoU: 0.9195 - bce_dice_loss: 0.0783\n",
            "Epoch 102: val_IoU did not improve from 0.83897\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.0289 - acc: 0.9842 - dice_coeff: 0.9711 - IoU: 0.9195 - bce_dice_loss: 0.0783 - val_loss: 0.0832 - val_acc: 0.9690 - val_dice_coeff: 0.9198 - val_IoU: 0.8365 - val_bce_dice_loss: 0.2618 - lr: 1.0000e-04\n",
            "Epoch 103/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0297 - acc: 0.9840 - dice_coeff: 0.9703 - IoU: 0.9199 - bce_dice_loss: 0.0818\n",
            "Epoch 103: val_IoU improved from 0.83897 to 0.84092, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0297 - acc: 0.9840 - dice_coeff: 0.9703 - IoU: 0.9199 - bce_dice_loss: 0.0818 - val_loss: 0.0806 - val_acc: 0.9698 - val_dice_coeff: 0.9225 - val_IoU: 0.8409 - val_bce_dice_loss: 0.2502 - lr: 1.0000e-04\n",
            "Epoch 104/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0292 - acc: 0.9841 - dice_coeff: 0.9708 - IoU: 0.9196 - bce_dice_loss: 0.0799\n",
            "Epoch 104: val_IoU did not improve from 0.84092\n",
            "50/50 [==============================] - 33s 659ms/step - loss: 0.0292 - acc: 0.9841 - dice_coeff: 0.9708 - IoU: 0.9196 - bce_dice_loss: 0.0799 - val_loss: 0.0797 - val_acc: 0.9698 - val_dice_coeff: 0.9229 - val_IoU: 0.8397 - val_bce_dice_loss: 0.2571 - lr: 1.0000e-04\n",
            "Epoch 105/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0284 - acc: 0.9842 - dice_coeff: 0.9716 - IoU: 0.9207 - bce_dice_loss: 0.0787\n",
            "Epoch 105: val_IoU did not improve from 0.84092\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0284 - acc: 0.9842 - dice_coeff: 0.9716 - IoU: 0.9207 - bce_dice_loss: 0.0787 - val_loss: 0.0788 - val_acc: 0.9700 - val_dice_coeff: 0.9240 - val_IoU: 0.8404 - val_bce_dice_loss: 0.2536 - lr: 1.0000e-04\n",
            "Epoch 106/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9844 - dice_coeff: 0.9723 - IoU: 0.9231 - bce_dice_loss: 0.0766\n",
            "Epoch 106: val_IoU did not improve from 0.84092\n",
            "50/50 [==============================] - 33s 664ms/step - loss: 0.0277 - acc: 0.9844 - dice_coeff: 0.9723 - IoU: 0.9231 - bce_dice_loss: 0.0766 - val_loss: 0.0806 - val_acc: 0.9696 - val_dice_coeff: 0.9228 - val_IoU: 0.8399 - val_bce_dice_loss: 0.2595 - lr: 1.0000e-04\n",
            "Epoch 107/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9844 - dice_coeff: 0.9723 - IoU: 0.9233 - bce_dice_loss: 0.0767\n",
            "Epoch 107: val_IoU did not improve from 0.84092\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.0277 - acc: 0.9844 - dice_coeff: 0.9723 - IoU: 0.9233 - bce_dice_loss: 0.0767 - val_loss: 0.0823 - val_acc: 0.9693 - val_dice_coeff: 0.9213 - val_IoU: 0.8400 - val_bce_dice_loss: 0.2574 - lr: 1.0000e-04\n",
            "Epoch 108/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0274 - acc: 0.9845 - dice_coeff: 0.9726 - IoU: 0.9242 - bce_dice_loss: 0.0763\n",
            "Epoch 108: val_IoU did not improve from 0.84092\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0274 - acc: 0.9845 - dice_coeff: 0.9726 - IoU: 0.9242 - bce_dice_loss: 0.0763 - val_loss: 0.0823 - val_acc: 0.9691 - val_dice_coeff: 0.9212 - val_IoU: 0.8397 - val_bce_dice_loss: 0.2621 - lr: 1.0000e-04\n",
            "Epoch 109/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.9842 - dice_coeff: 0.9717 - IoU: 0.9237 - bce_dice_loss: 0.0812\n",
            "Epoch 109: val_IoU did not improve from 0.84092\n",
            "50/50 [==============================] - 33s 659ms/step - loss: 0.0283 - acc: 0.9842 - dice_coeff: 0.9717 - IoU: 0.9237 - bce_dice_loss: 0.0812 - val_loss: 0.0837 - val_acc: 0.9688 - val_dice_coeff: 0.9197 - val_IoU: 0.8385 - val_bce_dice_loss: 0.2609 - lr: 1.0000e-04\n",
            "Epoch 110/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0274 - acc: 0.9844 - dice_coeff: 0.9726 - IoU: 0.9249 - bce_dice_loss: 0.0778\n",
            "Epoch 110: val_IoU improved from 0.84092 to 0.84109, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 674ms/step - loss: 0.0274 - acc: 0.9844 - dice_coeff: 0.9726 - IoU: 0.9249 - bce_dice_loss: 0.0778 - val_loss: 0.0789 - val_acc: 0.9699 - val_dice_coeff: 0.9234 - val_IoU: 0.8411 - val_bce_dice_loss: 0.2605 - lr: 1.0000e-04\n",
            "Epoch 111/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0273 - acc: 0.9844 - dice_coeff: 0.9727 - IoU: 0.9238 - bce_dice_loss: 0.0784\n",
            "Epoch 111: val_IoU improved from 0.84109 to 0.84238, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 675ms/step - loss: 0.0273 - acc: 0.9844 - dice_coeff: 0.9727 - IoU: 0.9238 - bce_dice_loss: 0.0784 - val_loss: 0.0799 - val_acc: 0.9698 - val_dice_coeff: 0.9229 - val_IoU: 0.8424 - val_bce_dice_loss: 0.2568 - lr: 1.0000e-04\n",
            "Epoch 112/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0271 - acc: 0.9845 - dice_coeff: 0.9729 - IoU: 0.9261 - bce_dice_loss: 0.0783\n",
            "Epoch 112: val_IoU did not improve from 0.84238\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0271 - acc: 0.9845 - dice_coeff: 0.9729 - IoU: 0.9261 - bce_dice_loss: 0.0783 - val_loss: 0.0804 - val_acc: 0.9696 - val_dice_coeff: 0.9223 - val_IoU: 0.8402 - val_bce_dice_loss: 0.2619 - lr: 1.0000e-04\n",
            "Epoch 113/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0265 - acc: 0.9846 - dice_coeff: 0.9735 - IoU: 0.9261 - bce_dice_loss: 0.0764\n",
            "Epoch 113: val_IoU did not improve from 0.84238\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0265 - acc: 0.9846 - dice_coeff: 0.9735 - IoU: 0.9261 - bce_dice_loss: 0.0764 - val_loss: 0.0800 - val_acc: 0.9697 - val_dice_coeff: 0.9227 - val_IoU: 0.8419 - val_bce_dice_loss: 0.2581 - lr: 1.0000e-04\n",
            "Epoch 114/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0265 - acc: 0.9845 - dice_coeff: 0.9735 - IoU: 0.9269 - bce_dice_loss: 0.0779\n",
            "Epoch 114: val_IoU improved from 0.84238 to 0.84241, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 670ms/step - loss: 0.0265 - acc: 0.9845 - dice_coeff: 0.9735 - IoU: 0.9269 - bce_dice_loss: 0.0779 - val_loss: 0.0789 - val_acc: 0.9699 - val_dice_coeff: 0.9239 - val_IoU: 0.8424 - val_bce_dice_loss: 0.2611 - lr: 1.0000e-04\n",
            "Epoch 115/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0265 - acc: 0.9845 - dice_coeff: 0.9735 - IoU: 0.9270 - bce_dice_loss: 0.0777\n",
            "Epoch 115: val_IoU did not improve from 0.84241\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0265 - acc: 0.9845 - dice_coeff: 0.9735 - IoU: 0.9270 - bce_dice_loss: 0.0777 - val_loss: 0.0817 - val_acc: 0.9691 - val_dice_coeff: 0.9211 - val_IoU: 0.8407 - val_bce_dice_loss: 0.2728 - lr: 1.0000e-04\n",
            "Epoch 116/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0263 - acc: 0.9846 - dice_coeff: 0.9737 - IoU: 0.9273 - bce_dice_loss: 0.0777\n",
            "Epoch 116: val_IoU did not improve from 0.84241\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0263 - acc: 0.9846 - dice_coeff: 0.9737 - IoU: 0.9273 - bce_dice_loss: 0.0777 - val_loss: 0.0829 - val_acc: 0.9688 - val_dice_coeff: 0.9205 - val_IoU: 0.8408 - val_bce_dice_loss: 0.2763 - lr: 1.0000e-04\n",
            "Epoch 117/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0262 - acc: 0.9846 - dice_coeff: 0.9738 - IoU: 0.9276 - bce_dice_loss: 0.0776\n",
            "Epoch 117: val_IoU did not improve from 0.84241\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0262 - acc: 0.9846 - dice_coeff: 0.9738 - IoU: 0.9276 - bce_dice_loss: 0.0776 - val_loss: 0.0825 - val_acc: 0.9690 - val_dice_coeff: 0.9208 - val_IoU: 0.8405 - val_bce_dice_loss: 0.2721 - lr: 1.0000e-04\n",
            "Epoch 118/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9846 - dice_coeff: 0.9742 - IoU: 0.9288 - bce_dice_loss: 0.0765\n",
            "Epoch 118: val_IoU did not improve from 0.84241\n",
            "50/50 [==============================] - 34s 686ms/step - loss: 0.0258 - acc: 0.9846 - dice_coeff: 0.9742 - IoU: 0.9288 - bce_dice_loss: 0.0765 - val_loss: 0.0841 - val_acc: 0.9685 - val_dice_coeff: 0.9197 - val_IoU: 0.8419 - val_bce_dice_loss: 0.2767 - lr: 1.0000e-04\n",
            "Epoch 119/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0262 - acc: 0.9845 - dice_coeff: 0.9738 - IoU: 0.9294 - bce_dice_loss: 0.0795\n",
            "Epoch 119: val_IoU did not improve from 0.84241\n",
            "50/50 [==============================] - 33s 664ms/step - loss: 0.0262 - acc: 0.9845 - dice_coeff: 0.9738 - IoU: 0.9294 - bce_dice_loss: 0.0795 - val_loss: 0.0806 - val_acc: 0.9694 - val_dice_coeff: 0.9225 - val_IoU: 0.8421 - val_bce_dice_loss: 0.2720 - lr: 1.0000e-04\n",
            "Epoch 120/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0255 - acc: 0.9847 - dice_coeff: 0.9745 - IoU: 0.9296 - bce_dice_loss: 0.0759\n",
            "Epoch 120: val_IoU improved from 0.84241 to 0.84321, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 674ms/step - loss: 0.0255 - acc: 0.9847 - dice_coeff: 0.9745 - IoU: 0.9296 - bce_dice_loss: 0.0759 - val_loss: 0.0786 - val_acc: 0.9699 - val_dice_coeff: 0.9243 - val_IoU: 0.8432 - val_bce_dice_loss: 0.2729 - lr: 1.0000e-04\n",
            "Epoch 121/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0259 - acc: 0.9847 - dice_coeff: 0.9741 - IoU: 0.9292 - bce_dice_loss: 0.0771\n",
            "Epoch 121: val_IoU did not improve from 0.84321\n",
            "50/50 [==============================] - 34s 687ms/step - loss: 0.0259 - acc: 0.9847 - dice_coeff: 0.9741 - IoU: 0.9292 - bce_dice_loss: 0.0771 - val_loss: 0.0796 - val_acc: 0.9696 - val_dice_coeff: 0.9234 - val_IoU: 0.8427 - val_bce_dice_loss: 0.2731 - lr: 1.0000e-04\n",
            "Epoch 122/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0256 - acc: 0.9847 - dice_coeff: 0.9744 - IoU: 0.9294 - bce_dice_loss: 0.0769\n",
            "Epoch 122: val_IoU improved from 0.84321 to 0.84444, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 676ms/step - loss: 0.0256 - acc: 0.9847 - dice_coeff: 0.9744 - IoU: 0.9294 - bce_dice_loss: 0.0769 - val_loss: 0.0784 - val_acc: 0.9700 - val_dice_coeff: 0.9247 - val_IoU: 0.8444 - val_bce_dice_loss: 0.2658 - lr: 1.0000e-04\n",
            "Epoch 123/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9847 - dice_coeff: 0.9747 - IoU: 0.9297 - bce_dice_loss: 0.0775\n",
            "Epoch 123: val_IoU did not improve from 0.84444\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.0253 - acc: 0.9847 - dice_coeff: 0.9747 - IoU: 0.9297 - bce_dice_loss: 0.0775 - val_loss: 0.0809 - val_acc: 0.9694 - val_dice_coeff: 0.9225 - val_IoU: 0.8435 - val_bce_dice_loss: 0.2684 - lr: 1.0000e-04\n",
            "Epoch 124/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0255 - acc: 0.9847 - dice_coeff: 0.9745 - IoU: 0.9300 - bce_dice_loss: 0.0775\n",
            "Epoch 124: val_IoU did not improve from 0.84444\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0255 - acc: 0.9847 - dice_coeff: 0.9745 - IoU: 0.9300 - bce_dice_loss: 0.0775 - val_loss: 0.0771 - val_acc: 0.9702 - val_dice_coeff: 0.9258 - val_IoU: 0.8430 - val_bce_dice_loss: 0.2672 - lr: 1.0000e-04\n",
            "Epoch 125/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0250 - acc: 0.9848 - dice_coeff: 0.9750 - IoU: 0.9310 - bce_dice_loss: 0.0763\n",
            "Epoch 125: val_IoU did not improve from 0.84444\n",
            "50/50 [==============================] - 34s 686ms/step - loss: 0.0250 - acc: 0.9848 - dice_coeff: 0.9750 - IoU: 0.9310 - bce_dice_loss: 0.0763 - val_loss: 0.0781 - val_acc: 0.9700 - val_dice_coeff: 0.9249 - val_IoU: 0.8438 - val_bce_dice_loss: 0.2741 - lr: 1.0000e-04\n",
            "Epoch 126/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0248 - acc: 0.9848 - dice_coeff: 0.9752 - IoU: 0.9318 - bce_dice_loss: 0.0758\n",
            "Epoch 126: val_IoU did not improve from 0.84444\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0248 - acc: 0.9848 - dice_coeff: 0.9752 - IoU: 0.9318 - bce_dice_loss: 0.0758 - val_loss: 0.0785 - val_acc: 0.9699 - val_dice_coeff: 0.9243 - val_IoU: 0.8435 - val_bce_dice_loss: 0.2740 - lr: 1.0000e-04\n",
            "Epoch 127/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0250 - acc: 0.9848 - dice_coeff: 0.9750 - IoU: 0.9318 - bce_dice_loss: 0.0766\n",
            "Epoch 127: val_IoU did not improve from 0.84444\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0250 - acc: 0.9848 - dice_coeff: 0.9750 - IoU: 0.9318 - bce_dice_loss: 0.0766 - val_loss: 0.0787 - val_acc: 0.9699 - val_dice_coeff: 0.9242 - val_IoU: 0.8443 - val_bce_dice_loss: 0.2680 - lr: 1.0000e-04\n",
            "Epoch 128/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0249 - acc: 0.9848 - dice_coeff: 0.9751 - IoU: 0.9318 - bce_dice_loss: 0.0769\n",
            "Epoch 128: val_IoU improved from 0.84444 to 0.84462, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 672ms/step - loss: 0.0249 - acc: 0.9848 - dice_coeff: 0.9751 - IoU: 0.9318 - bce_dice_loss: 0.0769 - val_loss: 0.0785 - val_acc: 0.9701 - val_dice_coeff: 0.9248 - val_IoU: 0.8446 - val_bce_dice_loss: 0.2649 - lr: 1.0000e-04\n",
            "Epoch 129/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0248 - acc: 0.9848 - dice_coeff: 0.9752 - IoU: 0.9320 - bce_dice_loss: 0.0774\n",
            "Epoch 129: val_IoU improved from 0.84462 to 0.84617, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 682ms/step - loss: 0.0248 - acc: 0.9848 - dice_coeff: 0.9752 - IoU: 0.9320 - bce_dice_loss: 0.0774 - val_loss: 0.0765 - val_acc: 0.9704 - val_dice_coeff: 0.9263 - val_IoU: 0.8462 - val_bce_dice_loss: 0.2735 - lr: 1.0000e-04\n",
            "Epoch 130/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0243 - acc: 0.9849 - dice_coeff: 0.9757 - IoU: 0.9327 - bce_dice_loss: 0.0769\n",
            "Epoch 130: val_IoU did not improve from 0.84617\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0243 - acc: 0.9849 - dice_coeff: 0.9757 - IoU: 0.9327 - bce_dice_loss: 0.0769 - val_loss: 0.0773 - val_acc: 0.9703 - val_dice_coeff: 0.9255 - val_IoU: 0.8451 - val_bce_dice_loss: 0.2719 - lr: 1.0000e-04\n",
            "Epoch 131/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0240 - acc: 0.9850 - dice_coeff: 0.9760 - IoU: 0.9340 - bce_dice_loss: 0.0760\n",
            "Epoch 131: val_IoU did not improve from 0.84617\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0240 - acc: 0.9850 - dice_coeff: 0.9760 - IoU: 0.9340 - bce_dice_loss: 0.0760 - val_loss: 0.0777 - val_acc: 0.9701 - val_dice_coeff: 0.9250 - val_IoU: 0.8447 - val_bce_dice_loss: 0.2706 - lr: 1.0000e-04\n",
            "Epoch 132/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0243 - acc: 0.9849 - dice_coeff: 0.9757 - IoU: 0.9338 - bce_dice_loss: 0.0775\n",
            "Epoch 132: val_IoU did not improve from 0.84617\n",
            "50/50 [==============================] - 33s 665ms/step - loss: 0.0243 - acc: 0.9849 - dice_coeff: 0.9757 - IoU: 0.9338 - bce_dice_loss: 0.0775 - val_loss: 0.0779 - val_acc: 0.9700 - val_dice_coeff: 0.9249 - val_IoU: 0.8455 - val_bce_dice_loss: 0.2761 - lr: 1.0000e-04\n",
            "Epoch 133/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0242 - acc: 0.9849 - dice_coeff: 0.9758 - IoU: 0.9337 - bce_dice_loss: 0.0769\n",
            "Epoch 133: val_IoU improved from 0.84617 to 0.84639, saving model to best_model.h5\n",
            "50/50 [==============================] - 34s 675ms/step - loss: 0.0242 - acc: 0.9849 - dice_coeff: 0.9758 - IoU: 0.9337 - bce_dice_loss: 0.0769 - val_loss: 0.0782 - val_acc: 0.9700 - val_dice_coeff: 0.9248 - val_IoU: 0.8464 - val_bce_dice_loss: 0.2732 - lr: 1.0000e-04\n",
            "Epoch 134/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0239 - acc: 0.9849 - dice_coeff: 0.9761 - IoU: 0.9344 - bce_dice_loss: 0.0775\n",
            "Epoch 134: val_IoU did not improve from 0.84639\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0239 - acc: 0.9849 - dice_coeff: 0.9761 - IoU: 0.9344 - bce_dice_loss: 0.0775 - val_loss: 0.0772 - val_acc: 0.9701 - val_dice_coeff: 0.9256 - val_IoU: 0.8460 - val_bce_dice_loss: 0.2784 - lr: 1.0000e-04\n",
            "Epoch 135/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0237 - acc: 0.9850 - dice_coeff: 0.9763 - IoU: 0.9351 - bce_dice_loss: 0.0764\n",
            "Epoch 135: val_IoU did not improve from 0.84639\n",
            "50/50 [==============================] - 33s 659ms/step - loss: 0.0237 - acc: 0.9850 - dice_coeff: 0.9763 - IoU: 0.9351 - bce_dice_loss: 0.0764 - val_loss: 0.0769 - val_acc: 0.9703 - val_dice_coeff: 0.9263 - val_IoU: 0.8458 - val_bce_dice_loss: 0.2737 - lr: 1.0000e-04\n",
            "Epoch 136/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.9850 - dice_coeff: 0.9764 - IoU: 0.9353 - bce_dice_loss: 0.0765\n",
            "Epoch 136: val_IoU did not improve from 0.84639\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.0236 - acc: 0.9850 - dice_coeff: 0.9764 - IoU: 0.9353 - bce_dice_loss: 0.0765 - val_loss: 0.0769 - val_acc: 0.9702 - val_dice_coeff: 0.9259 - val_IoU: 0.8444 - val_bce_dice_loss: 0.2823 - lr: 1.0000e-04\n",
            "Epoch 137/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.9850 - dice_coeff: 0.9764 - IoU: 0.9350 - bce_dice_loss: 0.0776\n",
            "Epoch 137: val_IoU did not improve from 0.84639\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.0236 - acc: 0.9850 - dice_coeff: 0.9764 - IoU: 0.9350 - bce_dice_loss: 0.0776 - val_loss: 0.0767 - val_acc: 0.9702 - val_dice_coeff: 0.9262 - val_IoU: 0.8463 - val_bce_dice_loss: 0.2811 - lr: 1.0000e-04\n",
            "Epoch 138/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0235 - acc: 0.9850 - dice_coeff: 0.9765 - IoU: 0.9355 - bce_dice_loss: 0.0776\n",
            "Epoch 138: val_IoU improved from 0.84639 to 0.84654, saving model to best_model.h5\n",
            "50/50 [==============================] - 35s 697ms/step - loss: 0.0235 - acc: 0.9850 - dice_coeff: 0.9765 - IoU: 0.9355 - bce_dice_loss: 0.0776 - val_loss: 0.0775 - val_acc: 0.9701 - val_dice_coeff: 0.9254 - val_IoU: 0.8465 - val_bce_dice_loss: 0.2810 - lr: 1.0000e-04\n",
            "Epoch 139/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0232 - acc: 0.9850 - dice_coeff: 0.9768 - IoU: 0.9361 - bce_dice_loss: 0.0768\n",
            "Epoch 139: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0232 - acc: 0.9850 - dice_coeff: 0.9768 - IoU: 0.9361 - bce_dice_loss: 0.0768 - val_loss: 0.0778 - val_acc: 0.9699 - val_dice_coeff: 0.9250 - val_IoU: 0.8443 - val_bce_dice_loss: 0.2876 - lr: 1.0000e-04\n",
            "Epoch 140/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0233 - acc: 0.9850 - dice_coeff: 0.9767 - IoU: 0.9363 - bce_dice_loss: 0.0775\n",
            "Epoch 140: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0233 - acc: 0.9850 - dice_coeff: 0.9767 - IoU: 0.9363 - bce_dice_loss: 0.0775 - val_loss: 0.0890 - val_acc: 0.9667 - val_dice_coeff: 0.9152 - val_IoU: 0.8401 - val_bce_dice_loss: 0.3148 - lr: 1.0000e-04\n",
            "Epoch 141/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0236 - acc: 0.9849 - dice_coeff: 0.9764 - IoU: 0.9355 - bce_dice_loss: 0.0791\n",
            "Epoch 141: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.0236 - acc: 0.9849 - dice_coeff: 0.9764 - IoU: 0.9355 - bce_dice_loss: 0.0791 - val_loss: 0.0810 - val_acc: 0.9690 - val_dice_coeff: 0.9198 - val_IoU: 0.8376 - val_bce_dice_loss: 0.2992 - lr: 1.0000e-04\n",
            "Epoch 142/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0235 - acc: 0.9850 - dice_coeff: 0.9765 - IoU: 0.9360 - bce_dice_loss: 0.0791\n",
            "Epoch 142: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 664ms/step - loss: 0.0235 - acc: 0.9850 - dice_coeff: 0.9765 - IoU: 0.9360 - bce_dice_loss: 0.0791 - val_loss: 0.0807 - val_acc: 0.9692 - val_dice_coeff: 0.9220 - val_IoU: 0.8421 - val_bce_dice_loss: 0.2941 - lr: 1.0000e-04\n",
            "Epoch 143/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0230 - acc: 0.9851 - dice_coeff: 0.9770 - IoU: 0.9365 - bce_dice_loss: 0.0782\n",
            "Epoch 143: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 664ms/step - loss: 0.0230 - acc: 0.9851 - dice_coeff: 0.9770 - IoU: 0.9365 - bce_dice_loss: 0.0782 - val_loss: 0.0799 - val_acc: 0.9695 - val_dice_coeff: 0.9231 - val_IoU: 0.8424 - val_bce_dice_loss: 0.2883 - lr: 1.0000e-04\n",
            "Epoch 144/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0233 - acc: 0.9850 - dice_coeff: 0.9767 - IoU: 0.9361 - bce_dice_loss: 0.0799\n",
            "Epoch 144: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.0233 - acc: 0.9850 - dice_coeff: 0.9767 - IoU: 0.9361 - bce_dice_loss: 0.0799 - val_loss: 0.0824 - val_acc: 0.9690 - val_dice_coeff: 0.9212 - val_IoU: 0.8422 - val_bce_dice_loss: 0.2941 - lr: 1.0000e-04\n",
            "Epoch 145/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0232 - acc: 0.9850 - dice_coeff: 0.9768 - IoU: 0.9364 - bce_dice_loss: 0.0798\n",
            "Epoch 145: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 34s 685ms/step - loss: 0.0232 - acc: 0.9850 - dice_coeff: 0.9768 - IoU: 0.9364 - bce_dice_loss: 0.0798 - val_loss: 0.0813 - val_acc: 0.9690 - val_dice_coeff: 0.9219 - val_IoU: 0.8424 - val_bce_dice_loss: 0.2968 - lr: 1.0000e-04\n",
            "Epoch 146/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0230 - acc: 0.9851 - dice_coeff: 0.9770 - IoU: 0.9371 - bce_dice_loss: 0.0788\n",
            "Epoch 146: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 0.0230 - acc: 0.9851 - dice_coeff: 0.9770 - IoU: 0.9371 - bce_dice_loss: 0.0788 - val_loss: 0.0790 - val_acc: 0.9697 - val_dice_coeff: 0.9241 - val_IoU: 0.8433 - val_bce_dice_loss: 0.2932 - lr: 1.0000e-04\n",
            "Epoch 147/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9850 - dice_coeff: 0.9769 - IoU: 0.9368 - bce_dice_loss: 0.0789\n",
            "Epoch 147: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.0231 - acc: 0.9850 - dice_coeff: 0.9769 - IoU: 0.9368 - bce_dice_loss: 0.0789 - val_loss: 0.0786 - val_acc: 0.9695 - val_dice_coeff: 0.9246 - val_IoU: 0.8444 - val_bce_dice_loss: 0.3079 - lr: 1.0000e-04\n",
            "Epoch 148/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9850 - dice_coeff: 0.9769 - IoU: 0.9369 - bce_dice_loss: 0.0792\n",
            "Epoch 148: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.0231 - acc: 0.9850 - dice_coeff: 0.9769 - IoU: 0.9369 - bce_dice_loss: 0.0792 - val_loss: 0.0809 - val_acc: 0.9692 - val_dice_coeff: 0.9225 - val_IoU: 0.8421 - val_bce_dice_loss: 0.3049 - lr: 1.0000e-04\n",
            "Epoch 149/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0230 - acc: 0.9850 - dice_coeff: 0.9770 - IoU: 0.9373 - bce_dice_loss: 0.0799\n",
            "Epoch 149: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 664ms/step - loss: 0.0230 - acc: 0.9850 - dice_coeff: 0.9770 - IoU: 0.9373 - bce_dice_loss: 0.0799 - val_loss: 0.0806 - val_acc: 0.9692 - val_dice_coeff: 0.9224 - val_IoU: 0.8436 - val_bce_dice_loss: 0.2979 - lr: 1.0000e-04\n",
            "Epoch 150/150\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9851 - dice_coeff: 0.9769 - IoU: 0.9374 - bce_dice_loss: 0.0798\n",
            "Epoch 150: val_IoU did not improve from 0.84654\n",
            "50/50 [==============================] - 33s 658ms/step - loss: 0.0231 - acc: 0.9851 - dice_coeff: 0.9769 - IoU: 0.9374 - bce_dice_loss: 0.0798 - val_loss: 0.0802 - val_acc: 0.9693 - val_dice_coeff: 0.9229 - val_IoU: 0.8449 - val_bce_dice_loss: 0.2990 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "his = model.fit(train_dataset,\n",
        "            epochs=150,\n",
        "            callbacks=callbacks,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            validation_data=valid_dataset)\n",
        "MetaPloyp_computational = time.time()-start_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_dict = his.history\n",
        "\n",
        "train_loss = hist_dict[\"loss\"]\n",
        "val_loss = hist_dict[\"val_loss\"]\n",
        "\n",
        "train_iou = hist_dict[\"IoU\"]\n",
        "val_iou = hist_dict[\"val_IoU\"]\n",
        "\n",
        "## Get number of epochs\n",
        "epochs = range(1, len(train_loss)+1)"
      ],
      "metadata": {
        "id": "knxepCNzGbVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, label = \"Validation Loss\")\n",
        "plt.title('Meta Polyp Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "2ssYBfHzxcQ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "23938c01-f69b-474d-a003-a210a6396f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d23a35729e0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, train_iou, label=\"Training IOU\")\n",
        "plt.plot(epochs, val_iou, label = \"Validation IOU\")\n",
        "plt.title('Meta-Polyp Training and Validation IOU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IOU')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "06CfnRESxiRH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "8fb6b157-b4aa-4032-f9c5-9013d7ed9d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d23a35e6470>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzYJqWevptcB"
      },
      "source": [
        "#Test Time Augmentation (TTA) and CRF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUBgHy5Gpv_w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def horizontal_flip(image):\n",
        "    image = image[:, ::-1, :]\n",
        "    return image\n",
        "\n",
        "def vertical_flip(image):\n",
        "    image = image[::-1, :, :]\n",
        "    return image\n",
        "\n",
        "def tta_model(model, image):\n",
        "    n_image = image\n",
        "    h_image = horizontal_flip(image)\n",
        "    v_image = vertical_flip(image)\n",
        "\n",
        "    n_mask = model.predict(np.expand_dims(n_image, axis=0))[0]\n",
        "    h_mask = model.predict(np.expand_dims(h_image, axis=0))[0]\n",
        "    v_mask = model.predict(np.expand_dims(v_image, axis=0))[0]\n",
        "\n",
        "    n_mask = n_mask\n",
        "    h_mask = horizontal_flip(h_mask)\n",
        "    v_mask = vertical_flip(v_mask)\n",
        "\n",
        "    mean_mask = (n_mask + h_mask + v_mask) / 3.0\n",
        "    return mean_mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral\n",
        "\n",
        "def apply_crf(ori_image, mask):\n",
        "    \"\"\" Conditional Random Field\n",
        "    ori_image: np.array with value between 0-255\n",
        "    mask: np.array with value between 0-1\n",
        "    \"\"\"\n",
        "\n",
        "    ## Grayscale to RGB\n",
        "    # if len(mask.shape) < 3:\n",
        "    #     mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    ## Converting the anotations RGB to single 32  bit color\n",
        "    annotated_label = mask.astype(np.int32)\n",
        "    # annotated_label = mask[:,:,0] + (mask[:,:,1]<<8) + (mask[:,:,2]<<16)\n",
        "\n",
        "    ## Convert the 32bit integer color to 0,1, 2, ... labels.\n",
        "    colors, labels = np.unique(annotated_label, return_inverse=True)\n",
        "    n_labels = 2\n",
        "\n",
        "    ## Setting up the CRF model\n",
        "    d = dcrf.DenseCRF2D(ori_image.shape[1], ori_image.shape[0], n_labels)\n",
        "\n",
        "    ## Get unary potentials (neg log probability)\n",
        "    U = unary_from_labels(labels, n_labels, gt_prob=0.7, zero_unsure=False)\n",
        "    d.setUnaryEnergy(U)\n",
        "\n",
        "    ## This adds the color-independent term, features are the locations only.\n",
        "    d.addPairwiseGaussian(sxy=(3, 3), compat=3, kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
        "\n",
        "    ## Run Inference for 10 steps\n",
        "    Q = d.inference(10)\n",
        "\n",
        "    ## Find out the most probable class for each pixel.\n",
        "    MAP = np.argmax(Q, axis=0)\n",
        "\n",
        "    return MAP.reshape((ori_image.shape[0], ori_image.shape[1]))"
      ],
      "metadata": {
        "id": "82HcBvRfiZH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fucntion evaluation"
      ],
      "metadata": {
        "id": "pZLDVIdxU-FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_steps = (len(X_test)//16)\n",
        "\n",
        "if len(X_test) % 16 != 0:\n",
        "  test_steps += 1"
      ],
      "metadata": {
        "id": "8za0Yvk_tkTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(img_size)\n",
        "model.load_weights('/content/best_model.h5')\n",
        "\n",
        "model.compile(optimizer = opts,\n",
        "            loss='dice',\n",
        "            metrics=[\"acc\", dice_coeff, IoU, bce_dice_loss])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASw-CJTmGzRe",
        "outputId": "f15f65aa-a9a0-4756-d178-db0b478b0f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Load pretrained from: /root/.keras/models/caformer_s18_224_imagenet.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#evaluate function"
      ],
      "metadata": {
        "id": "zgXZWTyVqcZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smooth=0.1"
      ],
      "metadata": {
        "id": "hCUJAM_5abQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    x = np.expand_dims(img, axis=0)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (256, 256))\n",
        "    x = x/255.0\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "XzqVZM08sZGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dice_coef(y_true, y_pred):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n",
        "\n",
        "def IoU(y_true, y_pred, eps=1e-6):\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    y_true = y_true.astype(np.int32)\n",
        "    m = tf.keras.metrics.MeanIoU(num_classes=2)\n",
        "    m.update_state(y_true, y_pred)\n",
        "    r = m.result().numpy()\n",
        "    m.reset_states()\n",
        "    return r\n"
      ],
      "metadata": {
        "id": "SbFKhc2PWg2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(y_true, y_pred):\n",
        "  y_pred = y_pred > 0.5\n",
        "  y_pred = y_pred.astype(np.int32)\n",
        "  m = tf.keras.metrics.Accuracy()\n",
        "  m.update_state(y_true, y_pred)\n",
        "  r = m.result().numpy()\n",
        "  m.reset_states()\n",
        "  return r"
      ],
      "metadata": {
        "id": "AxizBwCLr0qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(y_true, y_pred):\n",
        "    y_pred = y_pred.flatten()\n",
        "    y_true = y_true.flatten()\n",
        "\n",
        "    dice_coef_val = dice_coeff(y_true, y_pred)\n",
        "    mean_iou_val = IoU(y_true, y_pred)\n",
        "\n",
        "    y_true = y_true.astype(np.int32)\n",
        "    # recall_value = recall_score(y_pred, y_true, average='micro')\n",
        "    # precision_value = precision_score(y_pred, y_true, average='micro')\n",
        "\n",
        "    accuracy_val = acc(y_true, y_pred)\n",
        "\n",
        "    return [dice_coef_val, mean_iou_val, accuracy_val]"
      ],
      "metadata": {
        "id": "Zu8b1HB2qbqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_normal(model, x_data, y_data):\n",
        "    total = []\n",
        "    for x, y in tqdm(zip(x_data, y_data), total=len(x_data)):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        y_pred = model.predict(x)[0] > 0.5\n",
        "        y_pred = y_pred.astype(np.float32)\n",
        "\n",
        "        value = get_metrics(y, y_pred)\n",
        "        total.append(value)\n",
        "\n",
        "    mean_value = np.mean(total, axis=0)\n",
        "    print(mean_value)"
      ],
      "metadata": {
        "id": "3eU-BRCYW2uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_tta(model, x_data, y_data):\n",
        "    total = []\n",
        "    for x, y in tqdm(zip(x_data, y_data), total=len(x_data)):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        y_pred = tta_model(model, x[0])\n",
        "        y_pred = y_pred > 0.5\n",
        "        y_pred = y_pred.astype(np.float32)\n",
        "\n",
        "        value = get_metrics(y, y_pred)\n",
        "        total.append(value)\n",
        "\n",
        "    mean_value = np.mean(total, axis=0)\n",
        "    print(mean_value)"
      ],
      "metadata": {
        "id": "pSsn5c7pZq2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_crf(model, x_data, y_data):\n",
        "    total = []\n",
        "    for x, y in tqdm(zip(x_data, y_data), total=len(x_data)):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        y_pred = model.predict(x)[0] > 0.5\n",
        "        y_pred = y_pred.astype(np.float32)\n",
        "        y_pred = apply_crf(x[0]*255, y_pred)\n",
        "\n",
        "        value = get_metrics(y, y_pred)\n",
        "        total.append(value)\n",
        "\n",
        "    mean_value = np.mean(total, axis=0)\n",
        "    print(mean_value)"
      ],
      "metadata": {
        "id": "6uxz_dkniMqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_crf_tta(model, x_data, y_data):\n",
        "    total = []\n",
        "    for x, y in tqdm(zip(x_data, y_data), total=len(x_data)):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        y_pred = tta_model(model, x[0])\n",
        "        y_pred = y_pred > 0.5\n",
        "        y_pred = y_pred.astype(np.float32)\n",
        "        y_pred = apply_crf(x[0]*255, y_pred)\n",
        "\n",
        "        value = get_metrics(y, y_pred)\n",
        "        total.append(value)\n",
        "\n",
        "    mean_value = np.mean(total, axis=0)\n",
        "    print(mean_value)"
      ],
      "metadata": {
        "id": "NnN5ZYY-iOzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#evaluate"
      ],
      "metadata": {
        "id": "LyMYnXdQcz3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "evaluate_normal(model, X_test, Y_test)\n",
        "Segmentation_Time = time.time()-start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj42HJVUW5X8",
        "outputId": "b3d77c8b-aa25-4c94-aaa7-c02aff7aa6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:00<00:14,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:00<00:13,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:00<00:13,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:00<00:13,  7.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:00<00:13,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:00<00:13,  7.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 109ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:01<00:15,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:01<00:16,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:01<00:16,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:01<00:16,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:01<00:16,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:02<00:16,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 91ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:02<00:16,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 112ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:02<00:16,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:02<00:16,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:02<00:16,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:03<00:16,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:03<00:16,  5.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:03<00:16,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:03<00:15,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 102ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:03<00:15,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:03<00:15,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 99ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:04<00:16,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:04<00:15,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [00:04<00:14,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [00:04<00:12,  5.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [00:04<00:11,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [00:04<00:10,  6.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [00:05<00:10,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [00:05<00:10,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [00:05<00:09,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [00:05<00:09,  7.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:05<00:09,  7.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [00:05<00:10,  6.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [00:06<00:10,  6.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [00:06<00:09,  6.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [00:06<00:09,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [00:06<00:08,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:06<00:08,  6.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [00:06<00:08,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [00:06<00:09,  6.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:07<00:09,  6.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [00:07<00:08,  6.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [00:07<00:08,  6.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [00:07<00:08,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [00:07<00:07,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [00:07<00:07,  6.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [00:07<00:07,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [00:08<00:07,  6.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [00:08<00:07,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:08<00:06,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [00:08<00:06,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [00:08<00:06,  7.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:08<00:06,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:08<00:06,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [00:09<00:06,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:09<00:06,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:09<00:05,  7.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [00:09<00:05,  7.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:09<00:05,  7.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [00:09<00:05,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 78ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:09<00:05,  7.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [00:10<00:05,  7.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:10<00:05,  7.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:10<00:05,  6.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:10<00:04,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [00:10<00:04,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [00:10<00:04,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:11<00:05,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [00:11<00:04,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [00:11<00:04,  6.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [00:11<00:04,  6.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [00:11<00:04,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [00:11<00:04,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [00:11<00:03,  6.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:12<00:03,  6.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:12<00:03,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [00:12<00:03,  6.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [00:12<00:03,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [00:12<00:03,  5.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [00:12<00:03,  6.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [00:13<00:02,  6.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [00:13<00:02,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [00:13<00:02,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [00:13<00:02,  6.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [00:13<00:02,  6.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [00:13<00:01,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [00:13<00:01,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [00:14<00:01,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [00:14<00:01,  6.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [00:14<00:01,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [00:14<00:01,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [00:14<00:01,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [00:14<00:01,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [00:15<00:01,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [00:15<00:00,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 90ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [00:15<00:00,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [00:15<00:00,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 90ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [00:15<00:00,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:16<00:00,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91589876 0.9030726  0.97374207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Segmentation_Time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzc4oVM7yuWS",
        "outputId": "41e9b8a9-2686-4f23-c367-e0502c9912c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.117273330688477"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "evaluate_tta(model, X_test, Y_test)\n",
        "tta_seg = time.time()-start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9zzeojvbN8D",
        "outputId": "29b3bc19-7db0-4c61-f315-67aa40633ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:00<00:54,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:01<00:59,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:01<00:57,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:02<00:51,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:02<00:48,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:03<00:47,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:03<00:44,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:03<00:41,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:04<00:41,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:04<00:38,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:05<00:36,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:05<00:35,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:05<00:34,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:06<00:36,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:06<00:34,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:07<00:33,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:07<00:33,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:08<00:34,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:08<00:33,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:08<00:31,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:09<00:32,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:09<00:31,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:10<00:30,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:10<00:35,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [00:11<00:32,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [00:11<00:31,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [00:11<00:30,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [00:12<00:34,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [00:13<00:37,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [00:13<00:37,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [00:14<00:36,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [00:14<00:36,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:15<00:35,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [00:15<00:31,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [00:15<00:29,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [00:16<00:27,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [00:16<00:27,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [00:17<00:26,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:17<00:24,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [00:17<00:23,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [00:18<00:24,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:18<00:23,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [00:19<00:22,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [00:19<00:21,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [00:19<00:22,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [00:20<00:21,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [00:20<00:22,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [00:21<00:21,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [00:21<00:20,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [00:21<00:19,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:22<00:18,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [00:22<00:18,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [00:23<00:17,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:23<00:17,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:23<00:17,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [00:24<00:16,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:24<00:16,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:24<00:15,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [00:25<00:17,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:26<00:19,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [00:26<00:20,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:27<00:20,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [00:27<00:20,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:28<00:19,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:28<00:17,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:29<00:15,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [00:29<00:14,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [00:29<00:13,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:30<00:13,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [00:30<00:13,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [00:31<00:12,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [00:31<00:11,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [00:32<00:10,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [00:32<00:10,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [00:32<00:09,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:33<00:09,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:33<00:09,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [00:33<00:08,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [00:34<00:07,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [00:34<00:07,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [00:35<00:07,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [00:35<00:07,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [00:35<00:06,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [00:36<00:06,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [00:36<00:06,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [00:37<00:05,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [00:37<00:05,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [00:37<00:04,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [00:38<00:04,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [00:38<00:04,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [00:39<00:04,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [00:40<00:04,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [00:40<00:03,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [00:41<00:03,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [00:41<00:02,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [00:42<00:01,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [00:42<00:01,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [00:42<00:00,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [00:43<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:43<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.92151284 0.90633545 0.97420654]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tta_seg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx677aLHzMLj",
        "outputId": "5bec53f7-4004-477e-b5c5-4cf51b5fc293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41.064568519592285"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "evaluate_crf(model, X_test, Y_test)\n",
        "crf_seg = time.time()-start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1rp0nTrjZuP",
        "outputId": "2dd4d797-d7c7-4eda-d8cd-6adf44a8528d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:00<00:29,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:00<00:23,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:00<00:21,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:00<00:20,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:01<00:20,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:01<00:19,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:01<00:19,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:01<00:21,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:02<00:20,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:02<00:19,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:02<00:19,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:02<00:18,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:02<00:17,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:03<00:17,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:03<00:17,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:03<00:17,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:03<00:16,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:03<00:16,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:04<00:16,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:04<00:16,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:04<00:16,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:04<00:15,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:04<00:15,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:05<00:15,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [00:05<00:14,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [00:05<00:14,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [00:05<00:14,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [00:05<00:14,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [00:06<00:14,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [00:06<00:13,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [00:06<00:13,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [00:06<00:13,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:06<00:13,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 111ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [00:07<00:16,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [00:07<00:18,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 99ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [00:07<00:18,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [00:08<00:20,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [00:08<00:19,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:08<00:18,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [00:09<00:18,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [00:09<00:17,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:09<00:17,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [00:10<00:18,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 106ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [00:10<00:17,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [00:10<00:14,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [00:10<00:13,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [00:10<00:12,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 86ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [00:11<00:12,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [00:11<00:11,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [00:11<00:11,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:11<00:10,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [00:12<00:10,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [00:12<00:09,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:12<00:09,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:12<00:09,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [00:12<00:08,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:13<00:08,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:13<00:09,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [00:13<00:10,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:13<00:09,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [00:14<00:08,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:14<00:08,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [00:14<00:07,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:14<00:07,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:14<00:07,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:15<00:07,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [00:15<00:06,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [00:15<00:06,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:15<00:06,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [00:15<00:06,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [00:16<00:05,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [00:16<00:05,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [00:16<00:05,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [00:16<00:05,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [00:16<00:05,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:17<00:04,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:17<00:05,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [00:17<00:04,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [00:17<00:04,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [00:17<00:04,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [00:18<00:03,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [00:18<00:03,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [00:18<00:03,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [00:18<00:03,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [00:18<00:03,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [00:19<00:02,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [00:19<00:02,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [00:19<00:02,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [00:19<00:02,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [00:19<00:02,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [00:20<00:01,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [00:20<00:01,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [00:20<00:01,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [00:21<00:01,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 92ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [00:21<00:01,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 92ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [00:21<00:01,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [00:22<00:00,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [00:22<00:00,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 91ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [00:22<00:00,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 92ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:23<00:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91650808 0.90390151 0.97394089]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crf_seg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ribTxvovzzIZ",
        "outputId": "91874bd6-896f-4ee5-e67c-aabaacac3e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.066582441329956"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "evaluate_crf_tta(model, X_test, Y_test)\n",
        "crf_tta_seg = time.time()-start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYESn6i0kXBG",
        "outputId": "86ce9f34-b051-436d-8920-e6238750f074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:05<09:43,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:06<04:21,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:06<02:38,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:07<01:51,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:07<01:24,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:08<01:11,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:08<01:01,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:08<00:54,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:09<00:49,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:09<00:45,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:10<00:43,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:10<00:40,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:11<00:39,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:11<00:37,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:11<00:37,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:12<00:36,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:12<00:36,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:13<00:35,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:13<00:37,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:14<00:35,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:14<00:35,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:15<00:39,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:16<00:44,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:16<00:46,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [00:17<00:45,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [00:17<00:46,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [00:18<00:42,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [00:19<00:42,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [00:19<00:40,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [00:20<00:36,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [00:20<00:35,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [00:20<00:33,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:21<00:31,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [00:21<00:29,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [00:22<00:28,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [00:22<00:27,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [00:23<00:27,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [00:23<00:28,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:23<00:26,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [00:24<00:26,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [00:24<00:25,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:25<00:24,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [00:25<00:25,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [00:26<00:24,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [00:26<00:23,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [00:26<00:23,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [00:27<00:22,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [00:27<00:22,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [00:28<00:22,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [00:28<00:25,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:29<00:27,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [00:30<00:29,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [00:31<00:30,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:31<00:29,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:32<00:26,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [00:32<00:24,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:33<00:22,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:33<00:20,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [00:33<00:19,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:34<00:18,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [00:34<00:17,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:35<00:17,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [00:35<00:16,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:36<00:15,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:36<00:15,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:37<00:15,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [00:37<00:15,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [00:37<00:14,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [00:38<00:14,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [00:38<00:13,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [00:39<00:13,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [00:39<00:12,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [00:40<00:11,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [00:40<00:11,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [00:41<00:10,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [00:41<00:11,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [00:42<00:13,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [00:43<00:12,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [00:43<00:12,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [00:44<00:12,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [00:45<00:12,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [00:45<00:10,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [00:45<00:08,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [00:46<00:07,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [00:46<00:07,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [00:47<00:06,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [00:47<00:06,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [00:48<00:05,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [00:48<00:05,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [00:49<00:04,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [00:49<00:04,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [00:50<00:03,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [00:50<00:03,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [00:51<00:02,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [00:51<00:02,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [00:51<00:01,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [00:52<00:01,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [00:52<00:00,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [00:53<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9221008  0.90712561 0.97438904]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crf_tta_seg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLEj_Vlyz-Ks",
        "outputId": "7acd0dd5-03fa-410e-d6da-796374e61a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46.63215923309326"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#visualize single"
      ],
      "metadata": {
        "id": "Of5dFk8raH3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "def predict_single(model, imgPath):\n",
        "    img = cv2.imread(imgPath)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "    # img = img / 255.\n",
        "    result = model.predict(img)\n",
        "    return result\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.squeeze(mask)\n",
        "    mask = [mask, mask, mask]\n",
        "    mask = np.transpose(mask, (1, 2, 0))\n",
        "    return mask*255"
      ],
      "metadata": {
        "id": "nbsqjnTraL2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single(model, imgPath):\n",
        "    img = cv2.imread(imgPath)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # img = img / 255.\n",
        "\n",
        "    n_image = img\n",
        "    h_image = horizontal_flip(img)\n",
        "    v_image = vertical_flip(img)\n",
        "\n",
        "    n_mask = model.predict(np.expand_dims(n_image, axis=0))[0]\n",
        "    h_mask = model.predict(np.expand_dims(h_image, axis=0))[0]\n",
        "    v_mask = model.predict(np.expand_dims(v_image, axis=0))[0]\n",
        "\n",
        "    n_mask = n_mask\n",
        "    h_mask = horizontal_flip(h_mask)\n",
        "    v_mask = vertical_flip(v_mask)\n",
        "\n",
        "    mean_mask = (n_mask + h_mask + v_mask) / 3.0\n",
        "    tta = mean_mask >0.5\n",
        "\n",
        "    return n_mask, h_mask, v_mask, mean_mask, tta\n"
      ],
      "metadata": {
        "id": "DVhbD8BVWLEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_in = X_test[67]\n",
        "img_out = \"out1.jpg\"\n",
        "\n",
        "n_mask, h_mask, v_mask, mean_mask, tta = predict_single(model, img_in)\n",
        "\n",
        "out1 = mask_parse(n_mask)\n",
        "out2 = mask_parse(h_mask)\n",
        "out3 = mask_parse(v_mask)\n",
        "out4 = mask_parse(mean_mask)\n",
        "out5 = mask_parse(tta)\n",
        "\n",
        "\n",
        "cv2.imwrite(\"1.jpg\", out1)\n",
        "cv2.imwrite(\"2.jpg\", out2)\n",
        "cv2.imwrite(\"3.jpg\", out3)\n",
        "cv2.imwrite(\"4.jpg\", out4)\n",
        "cv2.imwrite(\"5.jpg\", out5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mjTprttXZgl",
        "outputId": "0bd9938e-8376-4194-cea4-81eae5e9a44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 973ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[67]"
      ],
      "metadata": {
        "id": "X8lnRTymUc0O",
        "outputId": "b305c573-c3f1-4b80-9820-257a2896a951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Kvasir-SEG/images/cju7dn24o296i09871qfxb8s2.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JKuNDcFVISeI",
        "nKrsF-nsIVR5",
        "O61uMWIOJidB",
        "X76K_LhNJsXY",
        "M6jKeXTstuNi"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}